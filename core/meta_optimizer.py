"""ë©”íƒ€ ìµœì í™” ì—”ì§„ - íŒŒë¼ë¯¸í„° ë²”ìœ„ ìë™ íƒìƒ‰

ì´ ëª¨ë“ˆì€ ë©”íƒ€ ìµœì í™” (Meta-Optimization) ì‹œìŠ¤í…œì„ êµ¬í˜„í•©ë‹ˆë‹¤.
ëœë¤ ìƒ˜í”Œë§ + ë°±ë¶„ìœ„ìˆ˜ ê¸°ë°˜ ë²”ìœ„ ì¶”ì¶œë¡œ ìµœì  íŒŒë¼ë¯¸í„° ë²”ìœ„ë¥¼ ìë™ íƒìƒ‰í•©ë‹ˆë‹¤.

Architecture:
    Level 1: ë„“ì€ ë²”ìœ„ ëœë¤ ìƒ˜í”Œë§ (1,000ê°œ ì¡°í•©)
    Level 2: ìƒìœ„ 10% ê²°ê³¼ ë¶„ì„ (ë°±ë¶„ìœ„ìˆ˜ 10~90%)
    Level 3: ë²”ìœ„ ì¶•ì†Œ + ë°˜ë³µ (ìˆ˜ë ´ ì¡°ê±´ ì¶©ì¡±ì‹œ ì¢…ë£Œ)

Author: Claude Sonnet 4.5
Version: 1.0.0
Date: 2026-01-17
"""

import time
import random
import itertools
import numpy as np
import pandas as pd
from typing import Dict, List, Optional, Callable, Union
from collections import Counter
from datetime import datetime
import json
import os

from utils.logger import get_module_logger

logger = get_module_logger(__name__)


class MetaOptimizer:
    """ë©”íƒ€ ìµœì í™” ì—”ì§„ - íŒŒë¼ë¯¸í„° ë²”ìœ„ ìë™ íƒìƒ‰

    ëœë¤ ìƒ˜í”Œë§ê³¼ ë°±ë¶„ìœ„ìˆ˜ ê¸°ë°˜ ë²”ìœ„ ì¶”ì¶œì„ ì‚¬ìš©í•˜ì—¬ ìµœì  íŒŒë¼ë¯¸í„° ë²”ìœ„ë¥¼ ìë™ìœ¼ë¡œ íƒìƒ‰í•©ë‹ˆë‹¤.

    Attributes:
        base_optimizer: ê¸°ì¡´ BacktestOptimizer ì¸ìŠ¤í„´ìŠ¤
        meta_ranges: ë©”íƒ€ ë²”ìœ„ (META_PARAM_RANGES)
        sample_size: ë°˜ë³µë‹¹ ìƒ˜í”Œ ìˆ˜ (ê¸°ë³¸ 1,000ê°œ)
        min_improvement: ìˆ˜ë ´ ê¸°ì¤€ (ê¸°ë³¸ 5%)
        max_iterations: ìµœëŒ€ ë°˜ë³µ íšŸìˆ˜ (ê¸°ë³¸ 3íšŒ)
        iteration_results: ë°˜ë³µë³„ ìµœê³  ì ìˆ˜ ë¦¬ìŠ¤íŠ¸
        extracted_ranges: ì¶”ì¶œëœ ë²”ìœ„

    Example:
        >>> from core.optimizer import BacktestOptimizer
        >>> from core.meta_optimizer import MetaOptimizer
        >>> from core.strategy_core import AlphaX7Core
        >>>
        >>> # ê¸°ì¡´ Optimizer ìƒì„±
        >>> base_optimizer = BacktestOptimizer(AlphaX7Core, df)
        >>>
        >>> # Meta Optimizer ìƒì„±
        >>> meta = MetaOptimizer(
        ...     base_optimizer=base_optimizer,
        ...     sample_size=1000,
        ...     max_iterations=3
        ... )
        >>>
        >>> # ë©”íƒ€ ìµœì í™” ì‹¤í–‰
        >>> result = meta.run_meta_optimization(df, metric='sharpe_ratio')
        >>>
        >>> # ì¶”ì¶œëœ ë²”ìœ„ í™•ì¸
        >>> print(result['extracted_ranges'])
        >>> # {'atr_mult': {'quick': [1.2, 2.4], 'standard': [1.2, 1.8, 2.4], ...}}
    """

    def __init__(
        self,
        base_optimizer,  # BacktestOptimizer ì¸ìŠ¤í„´ìŠ¤
        meta_ranges: Optional[Dict[str, List]] = None,
        sample_size: int = 1000,
        min_improvement: float = 0.05,
        max_iterations: int = 3
    ):
        """MetaOptimizer ì´ˆê¸°í™”

        Args:
            base_optimizer: ê¸°ì¡´ BacktestOptimizer ì¸ìŠ¤í„´ìŠ¤ (ì¬ì‚¬ìš©)
            meta_ranges: META_PARAM_RANGES (ê¸°ë³¸ê°’: config.meta_ranges ì‚¬ìš©)
            sample_size: ë°˜ë³µë‹¹ ëœë¤ ìƒ˜í”Œ ìˆ˜ (ê¸°ë³¸ 1,000ê°œ)
            min_improvement: ìˆ˜ë ´ ê¸°ì¤€ (ê¸°ë³¸ 5%)
            max_iterations: ìµœëŒ€ ë°˜ë³µ íšŸìˆ˜ (ê¸°ë³¸ 3íšŒ)
        """
        self.base_optimizer = base_optimizer

        # META_PARAM_RANGES ë¡œë“œ
        if meta_ranges is None:
            from config.meta_ranges import load_meta_param_ranges
            meta_ranges = load_meta_param_ranges()
        self.meta_ranges = meta_ranges

        self.sample_size = sample_size
        self.min_improvement = min_improvement
        self.max_iterations = max_iterations

        # ìƒíƒœ ë³€ìˆ˜
        self.iteration_results: List[float] = []  # ë°˜ë³µë³„ ìµœê³  ì ìˆ˜
        self.extracted_ranges: Optional[Dict[str, List]] = None  # ì¶”ì¶œëœ ë²”ìœ„

    def run_meta_optimization(
        self,
        df: pd.DataFrame,
        trend_tf: str = '1h',
        metric: str = 'sharpe_ratio',
        callback: Optional[Callable] = None
    ) -> Dict:
        """ë©”íƒ€ ìµœì í™” ë©”ì¸ ë£¨í”„

        Args:
            df: OHLCV ë°ì´í„°í”„ë ˆì„
            trend_tf: ì¶”ì„¸ íƒ€ì„í”„ë ˆì„ (ê¸°ë³¸ '1h')
            metric: ìµœì í™” ëª©í‘œ ì§€í‘œ ('sharpe_ratio', 'win_rate', 'profit_factor' ë“±)
            callback: ì§„í–‰ ìƒí™© ì½œë°± í•¨ìˆ˜ (event: str, *args)

        Returns:
            {
                'extracted_ranges': {...},  # PARAM_RANGES_BY_MODE í˜•ì‹
                'best_result': OptimizationResult,
                'iterations': int,
                'convergence_reason': str,
                'statistics': {
                    'total_combinations_tested': int,
                    'time_elapsed_seconds': float,
                    'convergence_iterations': int,
                    'top_score_history': List[float]
                }
            }

        Raises:
            ValueError: ë°ì´í„°ê°€ ë¹„ì–´ìˆê±°ë‚˜ ìœ íš¨í•˜ì§€ ì•Šì„ ë•Œ
        """
        if df is None or df.empty:
            raise ValueError("ë°ì´í„°ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤")

        logger.info(
            f"ğŸ” Meta-Optimization Started: {self.sample_size} samples Ã— {self.max_iterations} iterations"
        )
        start_time = time.time()
        iteration = 0
        convergence_reason = 'max_iterations_reached'

        while iteration < self.max_iterations:
            iteration += 1

            if callback:
                callback('iteration_started', iteration, self.sample_size)

            logger.info(f"  Iteration {iteration}/{self.max_iterations} started")

            # 1. ëœë¤ ìƒ˜í”Œë§ ê·¸ë¦¬ë“œ ìƒì„±
            if iteration == 1:
                # ì²« ë°˜ë³µ: META_PARAM_RANGES ì‚¬ìš©
                grid = self._generate_random_sample(self.meta_ranges)
            else:
                # ì´í›„ ë°˜ë³µ: ì¶”ì¶œëœ ë²”ìœ„ ì‚¬ìš©
                if self.extracted_ranges is None:
                    logger.warning("  ì¶”ì¶œëœ ë²”ìœ„ê°€ ì—†ìŠµë‹ˆë‹¤. ì²« ë°˜ë³µ ë²”ìœ„ ì¬ì‚¬ìš©.")
                    grid = self._generate_random_sample(self.meta_ranges)
                else:
                    grid = self._generate_random_sample(self.extracted_ranges)

            # 2. ë°±í…ŒìŠ¤íŠ¸ ì‹¤í–‰ (ê¸°ì¡´ Optimizer ì¬ì‚¬ìš©)
            logger.info(f"  Running backtest: {len(grid[list(grid.keys())[0]])} unique combos")

            results = self.base_optimizer.run_optimization(
                df=df,
                grid=grid,
                metric=metric,
                mode='custom'
            )

            if not results:
                logger.warning(f"  Iteration {iteration}: No valid results")
                break

            # 3. ìµœê³  ì ìˆ˜ ê¸°ë¡
            best_score = getattr(results[0], metric)
            self.iteration_results.append(best_score)

            if callback:
                callback('iteration_finished', iteration, len(results), best_score)

            logger.info(
                f"  Iteration {iteration} finished: {len(results)} results, "
                f"best {metric}={best_score:.2f}"
            )

            # 4. ë²”ìœ„ ì¶”ì¶œ (ìƒìœ„ 10%)
            top_count = max(1, len(results) // 10)
            top_results = results[:top_count]
            self.extracted_ranges = self._extract_ranges_from_top_results(top_results)

            logger.info(f"  Extracted ranges from top {top_count} results")

            # 5. ìˆ˜ë ´ ì²´í¬
            if self._check_convergence():
                convergence_reason = 'improvement_below_threshold'
                logger.info(f"  âœ… Converged at iteration {iteration} (improvement < {self.min_improvement * 100}%)")
                break

        # 6. PARAM_RANGES_BY_MODE ë³€í™˜
        if self.extracted_ranges is None:
            logger.error("  ë©”íƒ€ ìµœì í™” ì‹¤íŒ¨: ì¶”ì¶œëœ ë²”ìœ„ê°€ ì—†ìŠµë‹ˆë‹¤")
            raise RuntimeError("Meta-optimization failed: No extracted ranges")

        final_ranges = self._convert_to_param_ranges_by_mode(self.extracted_ranges)

        elapsed = time.time() - start_time

        logger.info(
            f"ğŸ‰ Meta-Optimization Completed: {iteration} iterations, "
            f"{elapsed:.1f}s, reason={convergence_reason}"
        )

        return {
            'extracted_ranges': final_ranges,
            'best_result': results[0] if results else None,
            'iterations': iteration,
            'convergence_reason': convergence_reason,
            'statistics': {
                'total_combinations_tested': iteration * self.sample_size,
                'time_elapsed_seconds': elapsed,
                'convergence_iterations': iteration,
                'top_score_history': self.iteration_results
            }
        }

    def _generate_random_sample(
        self,
        ranges: Dict[str, List]
    ) -> Dict[str, List]:
        """ëœë¤ ìƒ˜í”Œë§ìœ¼ë¡œ ê·¸ë¦¬ë“œ ìƒì„±

        ì „ì²´ ì¡°í•©ì—ì„œ sample_size ê°œë§Œí¼ ëœë¤ ìƒ˜í”Œë§í•˜ì—¬ ê·¸ë¦¬ë“œë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

        Args:
            ranges: íŒŒë¼ë¯¸í„° ë²”ìœ„ (META_PARAM_RANGES ë˜ëŠ” extracted_ranges)

        Returns:
            ìƒ˜í”Œë§ëœ ê·¸ë¦¬ë“œ (Dict[íŒŒë¼ë¯¸í„°ëª…, List[ê°’]])

        Example:
            >>> ranges = {'atr_mult': [1.0, 1.5, 2.0], 'filter_tf': ['4h', '6h']}
            >>> grid = self._generate_random_sample(ranges)
            >>> # ì „ì²´ 6ê°œ ì¡°í•© ì¤‘ min(sample_size, 6)ê°œ ìƒ˜í”Œë§
        """
        # ì „ì²´ ì¡°í•© ìƒì„±
        all_combinations = list(itertools.product(*ranges.values()))

        # ìƒ˜í”Œ ìˆ˜ ê²°ì • (ì „ì²´ ì¡°í•© ìˆ˜ì™€ sample_size ì¤‘ ì‘ì€ ê°’)
        actual_sample_size = min(self.sample_size, len(all_combinations))

        # ëœë¤ ìƒ˜í”Œë§
        sampled_combos = random.sample(all_combinations, actual_sample_size)

        # Dict í˜•ì‹ìœ¼ë¡œ ë³€í™˜ (ê° íŒŒë¼ë¯¸í„°ë³„ ê³ ìœ  ê°’ë§Œ ì¶”ì¶œ)
        param_names = list(ranges.keys())
        grid = {name: [] for name in param_names}

        for combo in sampled_combos:
            for i, name in enumerate(param_names):
                if combo[i] not in grid[name]:
                    grid[name].append(combo[i])

        logger.info(f"    Sampled {actual_sample_size} combinations from {len(all_combinations)} total")

        return grid

    def _extract_ranges_from_top_results(
        self,
        top_results  # List[OptimizationResult]
    ) -> Dict[str, List]:
        """ë°±ë¶„ìœ„ìˆ˜ ê¸°ë°˜ ë²”ìœ„ ì¶”ì¶œ

        ìƒìœ„ ê²°ê³¼ì˜ íŒŒë¼ë¯¸í„° ë¶„í¬ë¥¼ ë¶„ì„í•˜ì—¬ ìƒˆë¡œìš´ ë²”ìœ„ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.

        Args:
            top_results: ìƒìœ„ 10% ìµœì í™” ê²°ê³¼ ë¦¬ìŠ¤íŠ¸

        Returns:
            ì¶”ì¶œëœ ë²”ìœ„ (Dict[íŒŒë¼ë¯¸í„°ëª…, List[ê°’]])

        Algorithm:
            - ìˆ˜ì¹˜í˜•: 10~90% ë°±ë¶„ìœ„ìˆ˜ ê¸°ë°˜ 5ê°œ ê· ë“± ìƒ˜í”Œë§
            - ì¹´í…Œê³ ë¦¬í˜•: ë¹ˆë„ ìƒìœ„ 5ê°œ ì„ íƒ

        Example:
            >>> top_results = [...]  # 100ê°œ ê²°ê³¼
            >>> ranges = self._extract_ranges_from_top_results(top_results)
            >>> # {'atr_mult': [1.2, 1.5, 1.8, 2.1, 2.4], 'filter_tf': ['4h', '6h', '12h']}
        """
        new_ranges = {}

        for param in self.meta_ranges.keys():
            # ìƒìœ„ ê²°ê³¼ì—ì„œ íŒŒë¼ë¯¸í„° ê°’ ì¶”ì¶œ
            values = [r.params[param] for r in top_results]

            if isinstance(values[0], str):
                # ì¹´í…Œê³ ë¦¬í˜• (filter_tf)
                counts = Counter(values)
                new_ranges[param] = [v for v, c in counts.most_common(5)]
                logger.info(f"    {param} (categorical): {new_ranges[param]}")
            else:
                # ìˆ˜ì¹˜í˜• (atr_mult, trail_start_r, trail_dist_r, entry_validity_hours)
                p10 = np.percentile(values, 10)  # í•˜ìœ„ 10% ì œê±°
                p90 = np.percentile(values, 90)  # ìƒìœ„ 10% ì œê±°
                new_ranges[param] = np.linspace(p10, p90, 5).tolist()  # 5ê°œ ê· ë“± ìƒ˜í”Œë§
                logger.info(f"    {param} (numeric): [{p10:.2f}, ..., {p90:.2f}]")

        return new_ranges

    def _convert_to_param_ranges_by_mode(
        self,
        ranges: Dict[str, List]
    ) -> Dict:
        """PARAM_RANGES_BY_MODE í˜•ì‹ìœ¼ë¡œ ë³€í™˜

        ì¶”ì¶œëœ ë²”ìœ„ë¥¼ Quick/Standard/Deep ëª¨ë“œë³„ ë²”ìœ„ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.

        Args:
            ranges: ì¶”ì¶œëœ ë²”ìœ„ (5ê°œ ê°’)

        Returns:
            PARAM_RANGES_BY_MODE í˜•ì‹
            {
                'atr_mult': {
                    'quick': [1.2, 2.4],               # ì–‘ ë
                    'standard': [1.2, 1.8, 2.4],       # ì‹œì‘/ì¤‘ê°„/ë
                    'deep': [1.2, 1.5, 1.8, 2.1, 2.4]  # ì „ì²´
                }
            }

        Algorithm:
            - Quick: 2ê°œ (ì–‘ ë)
            - Standard: 3ê°œ (ì‹œì‘, ì¤‘ê°„, ë)
            - Deep: 5ê°œ (ì „ì²´)
        """
        result = {}

        for param, values in ranges.items():
            if isinstance(values[0], str):
                # ì¹´í…Œê³ ë¦¬í˜•
                n = len(values)
                result[param] = {
                    'quick': values[:2] if n >= 2 else values,
                    'standard': values[:3] if n >= 3 else values,
                    'deep': values
                }
            else:
                # ìˆ˜ì¹˜í˜•
                n = len(values)
                result[param] = {
                    'quick': [values[0], values[-1]],  # ì–‘ ë
                    'standard': [values[0], values[n//2], values[-1]],  # ì‹œì‘/ì¤‘ê°„/ë
                    'deep': values  # ì „ì²´
                }

        return result

    def _check_convergence(self) -> bool:
        """ìˆ˜ë ´ ì¡°ê±´ ì²´í¬

        ìµœê·¼ 2íšŒ ë°˜ë³µì˜ ê°œì„ ìœ¨ì´ ëª¨ë‘ min_improvement (ê¸°ë³¸ 5%) ë¯¸ë§Œì´ë©´ ìˆ˜ë ´ìœ¼ë¡œ íŒë‹¨í•©ë‹ˆë‹¤.

        Returns:
            True: ìˆ˜ë ´ ì™„ë£Œ
            False: ì¶”ê°€ ë°˜ë³µ í•„ìš”

        Algorithm:
            1. ìµœì†Œ 2íšŒ ë°˜ë³µ ì™„ë£Œ í•„ìš”
            2. ìµœê·¼ 2íšŒ ê°œì„ ìœ¨ ê³„ì‚°
            3. ëª¨ë‘ < min_improvementì´ë©´ ìˆ˜ë ´

        Example:
            >>> self.iteration_results = [18.0, 18.72, 19.09]
            >>> # ê°œì„ ìœ¨: +4.0%, +2.0% â†’ ìˆ˜ë ´!
        """
        if len(self.iteration_results) < 2:
            return False

        improvements = []
        for i in range(-2, 0):  # ìµœê·¼ 2íšŒ
            prev = self.iteration_results[i - 1]
            curr = self.iteration_results[i]

            if prev == 0:
                improvement = 0
            else:
                improvement = (curr - prev) / prev

            improvements.append(improvement)

        # ëª¨ë‘ min_improvement ë¯¸ë§Œì´ë©´ ìˆ˜ë ´
        return all(imp < self.min_improvement for imp in improvements)

    def save_meta_ranges(
        self,
        exchange: str,
        symbol: str,
        timeframe: str,
        output_dir: str = 'presets/meta_ranges'
    ) -> str:
        """ë©”íƒ€ ë²”ìœ„ë¥¼ JSONìœ¼ë¡œ ì €ì¥

        Args:
            exchange: ê±°ë˜ì†Œëª… (ì˜ˆ: 'bybit')
            symbol: ì‹¬ë³¼ëª… (ì˜ˆ: 'BTCUSDT')
            timeframe: íƒ€ì„í”„ë ˆì„ (ì˜ˆ: '1h')
            output_dir: ì €ì¥ ë””ë ‰í† ë¦¬ (ê¸°ë³¸: 'presets/meta_ranges')

        Returns:
            ì €ì¥ëœ íŒŒì¼ ê²½ë¡œ

        Example:
            >>> meta.save_meta_ranges('bybit', 'BTCUSDT', '1h')
            'presets/meta_ranges/bybit_BTCUSDT_1h_meta_20260117_180000.json'
        """
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        filename = f"{exchange}_{symbol}_{timeframe}_meta_{timestamp}.json"
        filepath = os.path.join(output_dir, filename)

        data = {
            'meta_optimization_id': f"{exchange}_{symbol}_{timeframe}_meta_{timestamp}",
            'created_at': datetime.now().isoformat(),
            'meta_method': 'random_sampling_percentile',
            'exchange': exchange,
            'symbol': symbol,
            'timeframe': timeframe,
            'iterations': len(self.iteration_results),
            'convergence_reason': 'improvement_below_threshold' if self._check_convergence() else 'max_iterations_reached',
            'extracted_ranges': self.extracted_ranges,
            'param_ranges_by_mode': self._convert_to_param_ranges_by_mode(self.extracted_ranges) if self.extracted_ranges else {},
            'statistics': {
                'total_combinations_tested': len(self.iteration_results) * self.sample_size,
                'time_elapsed_seconds': 0,  # í˜¸ì¶œ ì‹œì ì—ì„œëŠ” ê³„ì‚° ë¶ˆê°€
                'convergence_iterations': len(self.iteration_results),
                'top_score_history': self.iteration_results,
                'sample_size': self.sample_size,
                'min_improvement': self.min_improvement,
                'max_iterations': self.max_iterations
            }
        }

        # ë””ë ‰í† ë¦¬ ìƒì„±
        os.makedirs(output_dir, exist_ok=True)

        # JSON ì €ì¥
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(data, f, indent=2, ensure_ascii=False)

        logger.info(f"âœ… Meta ranges saved: {filepath}")

        return filepath


if __name__ == '__main__':
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    print("=== MetaOptimizer Test ===")
    print("This module requires BacktestOptimizer instance.")
    print("Usage:")
    print("  from core.meta_optimizer import MetaOptimizer")
    print("  meta = MetaOptimizer(base_optimizer)")
    print("  result = meta.run_meta_optimization(df)")
