"""ë©”íƒ€ ìµœì í™” ì—”ì§„ - íŒŒë¼ë¯¸í„° ë²”ìœ„ ìë™ íƒìƒ‰

ì´ ëª¨ë“ˆì€ ë©”íƒ€ ìµœì í™” (Meta-Optimization) ì‹œìŠ¤í…œì„ êµ¬í˜„í•©ë‹ˆë‹¤.
ëœë¤ ìƒ˜í”Œë§ + ë°±ë¶„ìœ„ìˆ˜ ê¸°ë°˜ ë²”ìœ„ ì¶”ì¶œë¡œ ìµœì  íŒŒë¼ë¯¸í„° ë²”ìœ„ë¥¼ ìë™ íƒìƒ‰í•©ë‹ˆë‹¤.

Architecture:
    Level 1: ë„“ì€ ë²”ìœ„ ëœë¤ ìƒ˜í”Œë§ (1,000ê°œ ì¡°í•©)
    Level 2: ìƒìœ„ 10% ê²°ê³¼ ë¶„ì„ (ë°±ë¶„ìœ„ìˆ˜ 10~90%)
    Level 3: ë²”ìœ„ ì¶•ì†Œ + ë°˜ë³µ (ìˆ˜ë ´ ì¡°ê±´ ì¶©ì¡±ì‹œ ì¢…ë£Œ)

Author: Claude Sonnet 4.5
Version: 1.0.0
Date: 2026-01-17
"""

import time
import random
import itertools
import numpy as np
import pandas as pd
from typing import Dict, List, Optional, Callable, Union
from collections import Counter
from datetime import datetime
import json
import os

from utils.logger import get_module_logger

logger = get_module_logger(__name__)


class MetaOptimizer:
    """ë©”íƒ€ ìµœì í™” ì—”ì§„ - íŒŒë¼ë¯¸í„° ë²”ìœ„ ìë™ íƒìƒ‰

    ëœë¤ ìƒ˜í”Œë§ê³¼ ë°±ë¶„ìœ„ìˆ˜ ê¸°ë°˜ ë²”ìœ„ ì¶”ì¶œì„ ì‚¬ìš©í•˜ì—¬ ìµœì  íŒŒë¼ë¯¸í„° ë²”ìœ„ë¥¼ ìë™ìœ¼ë¡œ íƒìƒ‰í•©ë‹ˆë‹¤.

    Attributes:
        base_optimizer: ê¸°ì¡´ BacktestOptimizer ì¸ìŠ¤í„´ìŠ¤
        meta_ranges: ë©”íƒ€ ë²”ìœ„ (META_PARAM_RANGES)
        sample_size: ë°˜ë³µë‹¹ ìƒ˜í”Œ ìˆ˜ (ê¸°ë³¸ 1,000ê°œ)
        min_improvement: ìˆ˜ë ´ ê¸°ì¤€ (ê¸°ë³¸ 5%)
        max_iterations: ìµœëŒ€ ë°˜ë³µ íšŸìˆ˜ (ê¸°ë³¸ 3íšŒ)
        iteration_results: ë°˜ë³µë³„ ìµœê³  ì ìˆ˜ ë¦¬ìŠ¤íŠ¸
        extracted_ranges: ì¶”ì¶œëœ ë²”ìœ„

    Example:
        >>> from core.optimizer import BacktestOptimizer
        >>> from core.meta_optimizer import MetaOptimizer
        >>> from core.strategy_core import AlphaX7Core
        >>>
        >>> # ê¸°ì¡´ Optimizer ìƒì„±
        >>> base_optimizer = BacktestOptimizer(AlphaX7Core, df)
        >>>
        >>> # Meta Optimizer ìƒì„±
        >>> meta = MetaOptimizer(
        ...     base_optimizer=base_optimizer,
        ...     sample_size=1000,
        ...     max_iterations=3
        ... )
        >>>
        >>> # ë©”íƒ€ ìµœì í™” ì‹¤í–‰
        >>> result = meta.run_meta_optimization(df, metric='sharpe_ratio')
        >>>
        >>> # ì¶”ì¶œëœ ë²”ìœ„ í™•ì¸
        >>> print(result['extracted_ranges'])
        >>> # {'atr_mult': {'quick': [1.2, 2.4], 'standard': [1.2, 1.8, 2.4], ...}}
    """

    def __init__(
        self,
        base_optimizer,  # BacktestOptimizer ì¸ìŠ¤í„´ìŠ¤
        meta_ranges: Optional[Dict[str, List]] = None,
        sample_size: int = 1000,
        min_improvement: float = 0.05,
        max_iterations: int = 3
    ):
        """MetaOptimizer ì´ˆê¸°í™”

        Args:
            base_optimizer: ê¸°ì¡´ BacktestOptimizer ì¸ìŠ¤í„´ìŠ¤ (ì¬ì‚¬ìš©)
            meta_ranges: META_PARAM_RANGES (ê¸°ë³¸ê°’: config.meta_ranges ì‚¬ìš©)
            sample_size: ë°˜ë³µë‹¹ ëœë¤ ìƒ˜í”Œ ìˆ˜ (ê¸°ë³¸ 1,000ê°œ)
            min_improvement: ìˆ˜ë ´ ê¸°ì¤€ (ê¸°ë³¸ 5%)
            max_iterations: ìµœëŒ€ ë°˜ë³µ íšŸìˆ˜ (ê¸°ë³¸ 3íšŒ)
        """
        self.base_optimizer = base_optimizer

        # META_PARAM_RANGES ë¡œë“œ
        if meta_ranges is None:
            from config.meta_ranges import load_meta_param_ranges
            meta_ranges = load_meta_param_ranges()
        self.meta_ranges = meta_ranges

        self.sample_size = sample_size
        self.min_improvement = min_improvement
        self.max_iterations = max_iterations

        # ìƒíƒœ ë³€ìˆ˜
        self.iteration_results: List[float] = []  # ë°˜ë³µë³„ ìµœê³  ì ìˆ˜
        self.extracted_ranges: Optional[Dict[str, List]] = None  # ì¶”ì¶œëœ ë²”ìœ„

    def run_meta_optimization(
        self,
        df: pd.DataFrame,
        trend_tf: str = '1h',
        metric: str = 'sharpe_ratio',
        callback: Optional[Callable] = None,
        progress_callback: Optional[Callable] = None
    ) -> Dict:
        """ë©”íƒ€ ìµœì í™” ë©”ì¸ ë£¨í”„

        Args:
            df: OHLCV ë°ì´í„°í”„ë ˆì„
            trend_tf: ì¶”ì„¸ íƒ€ì„í”„ë ˆì„ (ê¸°ë³¸ '1h')
            metric: ìµœì í™” ëª©í‘œ ì§€í‘œ ('sharpe_ratio', 'win_rate', 'profit_factor' ë“±)
            callback: ì§„í–‰ ìƒí™© ì½œë°± í•¨ìˆ˜ (event: str, *args)

        Returns:
            {
                'extracted_ranges': {...},  # PARAM_RANGES_BY_MODE í˜•ì‹
                'best_result': OptimizationResult,
                'iterations': int,
                'convergence_reason': str,
                'statistics': {
                    'total_combinations_tested': int,
                    'time_elapsed_seconds': float,
                    'convergence_iterations': int,
                    'top_score_history': List[float]
                }
            }

        Raises:
            ValueError: ë°ì´í„°ê°€ ë¹„ì–´ìˆê±°ë‚˜ ìœ íš¨í•˜ì§€ ì•Šì„ ë•Œ
        """
        if df is None or df.empty:
            raise ValueError("ë°ì´í„°ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤")

        logger.info(
            f"ğŸ” Meta-Optimization Started: {self.sample_size} samples Ã— {self.max_iterations} iterations"
        )
        start_time = time.time()
        iteration = 0
        convergence_reason = 'max_iterations_reached'

        while iteration < self.max_iterations:
            iteration += 1

            if callback:
                callback('iteration_started', iteration, self.sample_size)

            logger.info(f"  Iteration {iteration}/{self.max_iterations} started")

            # 1. ê·¸ë¦¬ë“œ ì¤€ë¹„
            if iteration == 1:
                # ì²« ë°˜ë³µ: META_PARAM_RANGES ì‚¬ìš©
                grid = self.meta_ranges
            else:
                # ì´í›„ ë°˜ë³µ: ì¶”ì¶œëœ ë²”ìœ„ ì‚¬ìš©
                if self.extracted_ranges is None:
                    logger.warning("  ì¶”ì¶œëœ ë²”ìœ„ê°€ ì—†ìŠµë‹ˆë‹¤. ì²« ë°˜ë³µ ë²”ìœ„ ì¬ì‚¬ìš©.")
                    grid = self.meta_ranges
                else:
                    grid = self.extracted_ranges

            # 2. ëœë¤ ìƒ˜í”Œë§ (ì „ì²´ ì¡°í•© ì¤‘ ì¼ë¶€ë§Œ ì„ íƒ)
            sampled_combos = self._generate_random_sample_combos(grid)
            logger.info(f"  Sampled {len(sampled_combos)} combinations")

            # 3. ë°±í…ŒìŠ¤íŠ¸ ì‹¤í–‰ (ìƒ˜í”Œë§ëœ ì¡°í•©ë§Œ)
            results = self._run_backtest_on_samples(
                df, grid, sampled_combos, metric,
                iteration=iteration,
                progress_callback=progress_callback
            )

            if not results:
                logger.warning(f"  Iteration {iteration}: No valid results")
                break

            # 3. ìµœê³  ì ìˆ˜ ê¸°ë¡
            best_score = getattr(results[0], metric)
            self.iteration_results.append(best_score)

            if callback:
                callback('iteration_finished', iteration, len(results), best_score)

            logger.info(
                f"  Iteration {iteration} finished: {len(results)} results, "
                f"best {metric}={best_score:.2f}"
            )

            # 4. ë²”ìœ„ ì¶”ì¶œ (ìƒìœ„ 10%)
            top_count = max(1, len(results) // 10)
            top_results = results[:top_count]
            self.extracted_ranges = self._extract_ranges_from_top_results(top_results)

            logger.info(f"  Extracted ranges from top {top_count} results")

            # 5. ìˆ˜ë ´ ì²´í¬
            if self._check_convergence():
                convergence_reason = 'improvement_below_threshold'
                logger.info(f"  âœ… Converged at iteration {iteration} (improvement < {self.min_improvement * 100}%)")
                break

        # 6. PARAM_RANGES_BY_MODE ë³€í™˜
        if self.extracted_ranges is None:
            logger.error("  ë©”íƒ€ ìµœì í™” ì‹¤íŒ¨: ì¶”ì¶œëœ ë²”ìœ„ê°€ ì—†ìŠµë‹ˆë‹¤")
            raise RuntimeError("Meta-optimization failed: No extracted ranges")

        final_ranges = self._convert_to_param_ranges_by_mode(self.extracted_ranges)

        elapsed = time.time() - start_time

        logger.info(
            f"ğŸ‰ Meta-Optimization Completed: {iteration} iterations, "
            f"{elapsed:.1f}s, reason={convergence_reason}"
        )

        return {
            'extracted_ranges': final_ranges,
            'best_result': results[0] if results else None,
            'iterations': iteration,
            'convergence_reason': convergence_reason,
            'statistics': {
                'total_combinations_tested': iteration * self.sample_size,
                'time_elapsed_seconds': elapsed,
                'convergence_iterations': iteration,
                'top_score_history': self.iteration_results
            }
        }

    def _generate_random_sample_combos(
        self,
        ranges: Dict[str, List]
    ) -> List[tuple]:
        """ëœë¤ ìƒ˜í”Œë§ìœ¼ë¡œ ì¡°í•© ìƒì„±

        ì „ì²´ ì¡°í•©ì—ì„œ sample_size ê°œë§Œí¼ ëœë¤ ìƒ˜í”Œë§í•©ë‹ˆë‹¤.

        Args:
            ranges: íŒŒë¼ë¯¸í„° ë²”ìœ„

        Returns:
            ìƒ˜í”Œë§ëœ ì¡°í•© ë¦¬ìŠ¤íŠ¸
        """
        # ì „ì²´ ì¡°í•© ìƒì„±
        all_combinations = list(itertools.product(*ranges.values()))

        # ìƒ˜í”Œ ìˆ˜ ê²°ì •
        actual_sample_size = min(self.sample_size, len(all_combinations))

        # ëœë¤ ìƒ˜í”Œë§
        sampled_combos = random.sample(all_combinations, actual_sample_size)

        return sampled_combos

    def _run_backtest_on_samples(
        self,
        df,
        grid: Dict[str, List],
        sampled_combos: List[tuple],
        metric: str,
        iteration: int = 1,
        progress_callback: Optional[Callable] = None
    ) -> List:
        """ìƒ˜í”Œë§ëœ ì¡°í•©ë§Œ ë°±í…ŒìŠ¤íŠ¸ ì‹¤í–‰

        Args:
            df: ë°ì´í„°í”„ë ˆì„
            grid: íŒŒë¼ë¯¸í„° ê·¸ë¦¬ë“œ (í‚¤ ìˆœì„œ ì°¸ì¡°ìš©)
            sampled_combos: ìƒ˜í”Œë§ëœ ì¡°í•©
            metric: ìµœì í™” ì§€í‘œ

        Returns:
            ìµœì í™” ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        """
        from concurrent.futures import ProcessPoolExecutor, as_completed
        from core.optimizer import OptimizationResult
        import multiprocessing

        param_names = list(grid.keys())
        results = []
        total_combos = len(sampled_combos)

        # CPU ì½”ì–´ ìˆ˜
        n_cores = max(1, multiprocessing.cpu_count() - 1)

        # ë³‘ë ¬ ë°±í…ŒìŠ¤íŠ¸ ì‹¤í–‰
        with ProcessPoolExecutor(max_workers=n_cores) as executor:
            futures = {}

            for combo in sampled_combos:
                # ì¡°í•©ì„ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
                params = dict(zip(param_names, combo))

                # ë°±í…ŒìŠ¤íŠ¸ ì‘ì—… ì œì¶œ
                future = executor.submit(self._single_backtest, params, df)
                futures[future] = params

            # ê²°ê³¼ ìˆ˜ì§‘
            completed_count = 0
            for future in as_completed(futures):
                try:
                    result = future.result()
                    if result:
                        results.append(result)
                except Exception as e:
                    logger.debug(f"Backtest failed: {e}")

                # ì§„í–‰ë„ ì½œë°±
                completed_count += 1
                if progress_callback:
                    progress_callback(
                        'backtest_progress',
                        iteration,
                        completed_count,
                        total_combos
                    )

        # ì§€í‘œ ê¸°ì¤€ ì •ë ¬
        if results:
            results.sort(key=lambda r: getattr(r, metric), reverse=True)

        logger.info(f"  Completed {len(results)}/{len(sampled_combos)} backtests")

        return results

    @staticmethod
    def _single_backtest(params: Dict, df):
        """ë‹¨ì¼ ë°±í…ŒìŠ¤íŠ¸ ì‹¤í–‰ (ProcessPoolìš© ì •ì  ë©”ì„œë“œ)

        Args:
            params: íŒŒë¼ë¯¸í„° ë”•ì…”ë„ˆë¦¬
            df: ë°ì´í„°í”„ë ˆì„

        Returns:
            OptimizationResult ë˜ëŠ” None
        """
        from core.strategy_core import AlphaX7Core
        from core.optimizer import OptimizationResult
        from config.parameters import DEFAULT_PARAMS

        try:
            # ì „ëµ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
            strategy = AlphaX7Core(use_mtf=True)

            # ë°±í…ŒìŠ¤íŠ¸ ì‹¤í–‰ (_worker_run_single íŒ¨í„´ ì‚¬ìš©)
            trades = strategy.run_backtest(
                df_pattern=df,  # 15m ë°ì´í„°
                df_entry=df,     # 15m ë°ì´í„°
                slippage=0.0005,  # ìŠ¬ë¦¬í”¼ì§€
                atr_mult=params.get('atr_mult', DEFAULT_PARAMS.get('atr_mult', 1.5)),
                trail_start_r=params.get('trail_start_r', DEFAULT_PARAMS.get('trail_start_r', 0.8)),
                trail_dist_r=params.get('trail_dist_r', DEFAULT_PARAMS.get('trail_dist_r', 0.02)),
                pattern_tolerance=params.get('pattern_tolerance', DEFAULT_PARAMS.get('pattern_tolerance', 0.03)),
                entry_validity_hours=params.get('entry_validity_hours', DEFAULT_PARAMS.get('entry_validity_hours', 24.0)),
                pullback_rsi_long=params.get('pullback_rsi_long', DEFAULT_PARAMS.get('pullback_rsi_long', 35)),
                pullback_rsi_short=params.get('pullback_rsi_short', DEFAULT_PARAMS.get('pullback_rsi_short', 65)),
                max_adds=params.get('max_adds', DEFAULT_PARAMS.get('max_adds', 1)),
                filter_tf=params.get('filter_tf', '4h'),
                rsi_period=params.get('rsi_period', DEFAULT_PARAMS.get('rsi_period', 14)),
                atr_period=params.get('atr_period', DEFAULT_PARAMS.get('atr_period', 14)),
                macd_fast=params.get('macd_fast', DEFAULT_PARAMS.get('macd_fast', 12)),
                macd_slow=params.get('macd_slow', DEFAULT_PARAMS.get('macd_slow', 26)),
                macd_signal=params.get('macd_signal', DEFAULT_PARAMS.get('macd_signal', 9)),
                ema_period=params.get('ema_period', DEFAULT_PARAMS.get('ema_period', 20)),
                enable_pullback=params.get('enable_pullback', False)
            )

            if not trades or len(trades) == 0:
                return None

            # ë©”íŠ¸ë¦­ ê³„ì‚°
            from utils.metrics import calculate_backtest_metrics

            bt_metrics = calculate_backtest_metrics(
                trades=trades,
                leverage=params.get('leverage', 1),
                capital=100.0
            )

            # OptimizationResult ìƒì„±
            result = OptimizationResult(
                params=params,
                trades=bt_metrics.get('total_trades', 0),
                win_rate=bt_metrics.get('win_rate', 0),
                total_return=bt_metrics.get('total_pnl', 0),
                simple_return=bt_metrics.get('total_pnl', 0),
                compound_return=bt_metrics.get('total_pnl', 0),
                max_drawdown=bt_metrics.get('mdd', 0),
                sharpe_ratio=bt_metrics.get('sharpe_ratio', 0),
                profit_factor=bt_metrics.get('profit_factor', 0)
            )

            return result

        except Exception:
            return None

    def _generate_random_sample(
        self,
        ranges: Dict[str, List]
    ) -> Dict[str, List]:
        """ëœë¤ ìƒ˜í”Œë§ìœ¼ë¡œ ê·¸ë¦¬ë“œ ìƒì„±

        ì „ì²´ ì¡°í•©ì—ì„œ sample_size ê°œë§Œí¼ ëœë¤ ìƒ˜í”Œë§í•˜ì—¬ ê·¸ë¦¬ë“œë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

        Args:
            ranges: íŒŒë¼ë¯¸í„° ë²”ìœ„ (META_PARAM_RANGES ë˜ëŠ” extracted_ranges)

        Returns:
            ìƒ˜í”Œë§ëœ ê·¸ë¦¬ë“œ (Dict[íŒŒë¼ë¯¸í„°ëª…, List[ê°’]])

        Example:
            >>> ranges = {'atr_mult': [1.0, 1.5, 2.0], 'filter_tf': ['4h', '6h']}
            >>> grid = self._generate_random_sample(ranges)
            >>> # ì „ì²´ 6ê°œ ì¡°í•© ì¤‘ min(sample_size, 6)ê°œ ìƒ˜í”Œë§
        """
        # ì „ì²´ ì¡°í•© ìƒì„±
        all_combinations = list(itertools.product(*ranges.values()))

        # ìƒ˜í”Œ ìˆ˜ ê²°ì • (ì „ì²´ ì¡°í•© ìˆ˜ì™€ sample_size ì¤‘ ì‘ì€ ê°’)
        actual_sample_size = min(self.sample_size, len(all_combinations))

        # ëœë¤ ìƒ˜í”Œë§
        sampled_combos = random.sample(all_combinations, actual_sample_size)

        # Dict í˜•ì‹ìœ¼ë¡œ ë³€í™˜ (ê° íŒŒë¼ë¯¸í„°ë³„ ê³ ìœ  ê°’ë§Œ ì¶”ì¶œ)
        param_names = list(ranges.keys())
        grid = {name: [] for name in param_names}

        for combo in sampled_combos:
            for i, name in enumerate(param_names):
                if combo[i] not in grid[name]:
                    grid[name].append(combo[i])

        logger.info(f"    Sampled {actual_sample_size} combinations from {len(all_combinations)} total")

        return grid

    def _extract_ranges_from_top_results(
        self,
        top_results  # List[OptimizationResult]
    ) -> Dict[str, List]:
        """ë°±ë¶„ìœ„ìˆ˜ ê¸°ë°˜ ë²”ìœ„ ì¶”ì¶œ

        ìƒìœ„ ê²°ê³¼ì˜ íŒŒë¼ë¯¸í„° ë¶„í¬ë¥¼ ë¶„ì„í•˜ì—¬ ìƒˆë¡œìš´ ë²”ìœ„ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.

        Args:
            top_results: ìƒìœ„ 10% ìµœì í™” ê²°ê³¼ ë¦¬ìŠ¤íŠ¸

        Returns:
            ì¶”ì¶œëœ ë²”ìœ„ (Dict[íŒŒë¼ë¯¸í„°ëª…, List[ê°’]])

        Algorithm:
            - ìˆ˜ì¹˜í˜•: 10~90% ë°±ë¶„ìœ„ìˆ˜ ê¸°ë°˜ 5ê°œ ê· ë“± ìƒ˜í”Œë§
            - ì¹´í…Œê³ ë¦¬í˜•: ë¹ˆë„ ìƒìœ„ 5ê°œ ì„ íƒ

        Example:
            >>> top_results = [...]  # 100ê°œ ê²°ê³¼
            >>> ranges = self._extract_ranges_from_top_results(top_results)
            >>> # {'atr_mult': [1.2, 1.5, 1.8, 2.1, 2.4], 'filter_tf': ['4h', '6h', '12h']}
        """
        new_ranges = {}

        for param in self.meta_ranges.keys():
            # ìƒìœ„ ê²°ê³¼ì—ì„œ íŒŒë¼ë¯¸í„° ê°’ ì¶”ì¶œ
            values = [r.params[param] for r in top_results]

            if isinstance(values[0], str):
                # ì¹´í…Œê³ ë¦¬í˜• (filter_tf)
                counts = Counter(values)
                new_ranges[param] = [v for v, c in counts.most_common(5)]
                logger.info(f"    {param} (categorical): {new_ranges[param]}")
            else:
                # ìˆ˜ì¹˜í˜• (atr_mult, trail_start_r, trail_dist_r, entry_validity_hours)
                p10 = np.percentile(values, 10)  # í•˜ìœ„ 10% ì œê±°
                p90 = np.percentile(values, 90)  # ìƒìœ„ 10% ì œê±°
                new_ranges[param] = np.linspace(p10, p90, 5).tolist()  # 5ê°œ ê· ë“± ìƒ˜í”Œë§
                logger.info(f"    {param} (numeric): [{p10:.2f}, ..., {p90:.2f}]")

        return new_ranges

    def _convert_to_param_ranges_by_mode(
        self,
        ranges: Dict[str, List]
    ) -> Dict:
        """PARAM_RANGES_BY_MODE í˜•ì‹ìœ¼ë¡œ ë³€í™˜

        ì¶”ì¶œëœ ë²”ìœ„ë¥¼ Quick/Standard/Deep ëª¨ë“œë³„ ë²”ìœ„ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.

        Args:
            ranges: ì¶”ì¶œëœ ë²”ìœ„ (5ê°œ ê°’)

        Returns:
            PARAM_RANGES_BY_MODE í˜•ì‹
            {
                'atr_mult': {
                    'quick': [1.2, 2.4],               # ì–‘ ë
                    'standard': [1.2, 1.8, 2.4],       # ì‹œì‘/ì¤‘ê°„/ë
                    'deep': [1.2, 1.5, 1.8, 2.1, 2.4]  # ì „ì²´
                }
            }

        Algorithm:
            - Quick: 2ê°œ (ì–‘ ë)
            - Standard: 3ê°œ (ì‹œì‘, ì¤‘ê°„, ë)
            - Deep: 5ê°œ (ì „ì²´)
        """
        result = {}

        for param, values in ranges.items():
            if isinstance(values[0], str):
                # ì¹´í…Œê³ ë¦¬í˜•
                n = len(values)
                result[param] = {
                    'quick': values[:2] if n >= 2 else values,
                    'standard': values[:3] if n >= 3 else values,
                    'deep': values
                }
            else:
                # ìˆ˜ì¹˜í˜•
                n = len(values)
                result[param] = {
                    'quick': [values[0], values[-1]],  # ì–‘ ë
                    'standard': [values[0], values[n//2], values[-1]],  # ì‹œì‘/ì¤‘ê°„/ë
                    'deep': values  # ì „ì²´
                }

        return result

    def _check_convergence(self) -> bool:
        """ìˆ˜ë ´ ì¡°ê±´ ì²´í¬

        ìµœê·¼ 2íšŒ ë°˜ë³µì˜ ê°œì„ ìœ¨ì´ ëª¨ë‘ min_improvement (ê¸°ë³¸ 5%) ë¯¸ë§Œì´ë©´ ìˆ˜ë ´ìœ¼ë¡œ íŒë‹¨í•©ë‹ˆë‹¤.

        Returns:
            True: ìˆ˜ë ´ ì™„ë£Œ
            False: ì¶”ê°€ ë°˜ë³µ í•„ìš”

        Algorithm:
            1. ìµœì†Œ 2íšŒ ë°˜ë³µ ì™„ë£Œ í•„ìš”
            2. ìµœê·¼ 2íšŒ ê°œì„ ìœ¨ ê³„ì‚°
            3. ëª¨ë‘ < min_improvementì´ë©´ ìˆ˜ë ´

        Example:
            >>> self.iteration_results = [18.0, 18.72, 19.09]
            >>> # ê°œì„ ìœ¨: +4.0%, +2.0% â†’ ìˆ˜ë ´!
        """
        if len(self.iteration_results) < 2:
            return False

        # ìµœê·¼ 2íšŒ ê°œì„ ìœ¨ ê³„ì‚° (ì˜¬ë°”ë¥¸ ì¸ë±ì‹±)
        prev = self.iteration_results[-2]  # ì´ì „ ë°˜ë³µ
        curr = self.iteration_results[-1]  # í˜„ì¬ ë°˜ë³µ

        if prev == 0:
            improvement = 0
        else:
            improvement = (curr - prev) / prev

        # ê°œì„ ìœ¨ì´ min_improvement ë¯¸ë§Œì´ë©´ ìˆ˜ë ´
        return improvement < self.min_improvement

    def save_meta_ranges(
        self,
        exchange: str,
        symbol: str,
        timeframe: str,
        output_dir: str = 'presets/meta_ranges'
    ) -> str:
        """ë©”íƒ€ ë²”ìœ„ë¥¼ JSONìœ¼ë¡œ ì €ì¥

        Args:
            exchange: ê±°ë˜ì†Œëª… (ì˜ˆ: 'bybit')
            symbol: ì‹¬ë³¼ëª… (ì˜ˆ: 'BTCUSDT')
            timeframe: íƒ€ì„í”„ë ˆì„ (ì˜ˆ: '1h')
            output_dir: ì €ì¥ ë””ë ‰í† ë¦¬ (ê¸°ë³¸: 'presets/meta_ranges')

        Returns:
            ì €ì¥ëœ íŒŒì¼ ê²½ë¡œ

        Example:
            >>> meta.save_meta_ranges('bybit', 'BTCUSDT', '1h')
            'presets/meta_ranges/bybit_BTCUSDT_1h_meta_20260117_180000.json'
        """
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        filename = f"{exchange}_{symbol}_{timeframe}_meta_{timestamp}.json"
        filepath = os.path.join(output_dir, filename)

        data = {
            'meta_optimization_id': f"{exchange}_{symbol}_{timeframe}_meta_{timestamp}",
            'created_at': datetime.now().isoformat(),
            'meta_method': 'random_sampling_percentile',
            'exchange': exchange,
            'symbol': symbol,
            'timeframe': timeframe,
            'iterations': len(self.iteration_results),
            'convergence_reason': 'improvement_below_threshold' if self._check_convergence() else 'max_iterations_reached',
            'extracted_ranges': self.extracted_ranges,
            'param_ranges_by_mode': self._convert_to_param_ranges_by_mode(self.extracted_ranges) if self.extracted_ranges else {},
            'statistics': {
                'total_combinations_tested': len(self.iteration_results) * self.sample_size,
                'time_elapsed_seconds': 0,  # í˜¸ì¶œ ì‹œì ì—ì„œëŠ” ê³„ì‚° ë¶ˆê°€
                'convergence_iterations': len(self.iteration_results),
                'top_score_history': self.iteration_results,
                'sample_size': self.sample_size,
                'min_improvement': self.min_improvement,
                'max_iterations': self.max_iterations
            }
        }

        # ë””ë ‰í† ë¦¬ ìƒì„±
        os.makedirs(output_dir, exist_ok=True)

        # JSON ì €ì¥
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(data, f, indent=2, ensure_ascii=False)

        logger.info(f"âœ… Meta ranges saved: {filepath}")

        return filepath


if __name__ == '__main__':
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    print("=== MetaOptimizer Test ===")
    print("This module requires BacktestOptimizer instance.")
    print("Usage:")
    print("  from core.meta_optimizer import MetaOptimizer")
    print("  meta = MetaOptimizer(base_optimizer)")
    print("  result = meta.run_meta_optimization(df)")
