# optimizer.py
"""
STAR-U Bot ìµœì í™” ì—”ì§„
- íŒŒë¼ë¯¸í„° ê·¸ë¦¬ë“œ ì„œì¹˜
- ê²°ê³¼ ì •ë ¬ ë° ë­í‚¹
- ìµœì ê°’ ë°˜í™˜
"""
import logging
logger = logging.getLogger(__name__)


import itertools
import pandas as pd
import numpy as np
from typing import Dict, List, Optional, Callable, Any, cast
from dataclasses import dataclass
from pathlib import Path
import multiprocessing as mp

# ë©”íŠ¸ë¦­ ê³„ì‚° (SSOT)
from utils.metrics import (
    calculate_win_rate,
    calculate_mdd,
    calculate_profit_factor,
    calculate_sharpe_ratio,
    assign_grade_by_preset
)

def optimize_strategy(symbol: str, timeframe: str, exchange: str = 'bybit') -> Optional[dict]:
    """ë°°ì¹˜ ìµœì í™”ì—ì„œ ì‚¬ìš©í•˜ëŠ” ë˜í¼ í•¨ìˆ˜ (BatchOptimizer í˜¸í™˜)"""
    # Circular import ë°©ì§€ë¥¼ ìœ„í•´ ë‚´ë¶€ì—ì„œ ì„í¬íŠ¸
    from core.strategy_core import AlphaX7Core
    from core.data_manager import BotDataManager
    
    dm = BotDataManager(exchange, symbol, {'entry_tf': timeframe})
    if dm.load_historical() and dm.df_entry_full is not None:
        opt = BacktestOptimizer(AlphaX7Core, dm.df_entry_full)
        grid = generate_fast_grid(timeframe)
        results = opt.run_optimization(dm.df_entry_full, grid)
        if results:
            best = results[0]
            return {
                'win_rate': best.win_rate,
                'profit_factor': best.profit_factor,
                'max_drawdown': best.max_drawdown,
                'total_trades': best.trades,
                'best_params': best.params
            }
    return None

import sys
import os

# Logging
from utils.logger import get_module_logger
logger = get_module_logger(__name__)

# TF_MAPPING, TF_RESAMPLE_MAP import
# ìƒìˆ˜ ë° ìœ í‹¸ë¦¬í‹° ì„í¬íŠ¸ (Phase 3 SSOT)
from config.constants.timeframes import TF_MAPPING, TF_RESAMPLE_MAP
from config.parameters import DEFAULT_PARAMS
from utils.data_utils import resample_data as shared_resample


# ==================== CPU ì›Œì»¤ ìë™ ê³„ì‚° ====================

def get_optimal_workers(mode: str = 'standard') -> int:
    """
    ìµœì  ì›Œì»¤ ìˆ˜ ìë™ ê³„ì‚° (í™˜ê²½ ë…ë¦½ì )

    Args:
        mode: 'quick', 'standard', 'deep'

    Returns:
        ì›Œì»¤ ìˆ˜ (1 ~ cpu_count)
    """
    total_cores = mp.cpu_count()

    if total_cores is None or total_cores <= 0:
        return 1

    if mode == 'quick':
        return max(1, total_cores // 2)
    elif mode == 'deep':
        return max(1, total_cores - 1)
    else:  # standard
        return max(1, int(total_cores * 0.75))


def get_worker_info(mode: str = 'standard') -> dict:
    """
    ì›Œì»¤ ì •ë³´ ë°˜í™˜ (ë¡œê¹…/GUI í‘œì‹œìš©)

    Returns:
        {
            'total_cores': int,
            'workers': int,
            'usage_percent': float,
            'description': str,
            'free_cores': int
        }
    """
    total = mp.cpu_count() or 1
    workers = get_optimal_workers(mode)
    usage = (workers / total) * 100

    descriptions = {
        'quick': f'ë¹ ë¥¸ ëª¨ë“œ (ì½”ì–´ {usage:.0f}% ì‚¬ìš©)',
        'standard': f'í‘œì¤€ ëª¨ë“œ (ì½”ì–´ {usage:.0f}% ì‚¬ìš©)',
        'deep': f'ë”¥ ëª¨ë“œ (ì½”ì–´ {usage:.0f}% ì‚¬ìš©, ìµœëŒ€ ì„±ëŠ¥)',
    }

    return {
        'total_cores': total,
        'workers': workers,
        'usage_percent': usage,
        'description': descriptions.get(mode, 'ì•Œ ìˆ˜ ì—†ìŒ'),
        'free_cores': total - workers,
    }


# ==================== ìµœì í™” ìƒìˆ˜ ====================

# ë¦¬ìƒ˜í”Œë§ ê°€ëŠ¥í•œ TF
AVAILABLE_TF = ['15m', '30m', '45m', '1h', '2h', '3h', '4h', '6h', '12h', '1d', '1w']

# ì¶”ì„¸ TFë³„ ìë™ íƒìƒ‰ ë²”ìœ„ (v2.0 - í•„í„° ê°•í™”)
TF_AUTO_RANGE = {
    '1h': {
        'filter_tf': ['4h', '6h', '12h', '1d'],  # 2h ì œê±° (ë„ˆë¬´ ì•½í•¨)
        'entry_tf': ['15m', '30m', '45m']
    },
    '4h': {
        'filter_tf': ['1d', '1w'],  # 6h, 12h ì œê±° (í•„í„° ê°•í™”)
        'entry_tf': ['15m', '30m', '1h', '2h']
    },
    '1d': {
        'filter_tf': ['1w'],
        'entry_tf': ['1h', '2h', '4h', '6h', '12h']
    },
    '1w': {
        'filter_tf': ['1d'],
        'entry_tf': ['4h', '6h', '12h', '1d']
    }
}

# ë°°ìœ¨ ë²”ìœ„
LEVERAGE_RANGE = [1, 2, 3, 5, 7, 10, 15, 20]

# ë°©í–¥ ë²”ìœ„
DIRECTION_RANGE = ['Both', 'Long', 'Short']

# ì§€í‘œ ë²”ìœ„ ì„¤ì • (Standard ëª¨ë“œ ê¸°ë³¸ê°’, í•˜ìœ„ í˜¸í™˜ì„±)
INDICATOR_RANGE = {
    'macd_fast': [6, 8, 10, 12],
    'macd_slow': [18, 20, 24, 26, 32],
    'macd_signal': [7, 9, 12],
    'ema_period': [10, 20, 50],

    # ê¸°ì¡´ ìœ ì§€ ë° ìµœì í™”
    'atr_mult': [1.0, 1.5, 2.0, 2.2],
    'atr_period': [7, 14, 21],
    'rsi_period': [7, 14, 21],
    'trail_start_r': [0.5, 0.7, 1.0],
    'trail_dist_r': [0.2, 0.35, 0.5],
    'pullback_rsi_long': [35, 40, 45],
    'pullback_rsi_short': [55, 60, 65],
    'pattern_tolerance': [0.03, 0.04, 0.05],
    'entry_validity_hours': [12, 24, 48],
    'max_adds': [0, 1, 2],
}

# ==================== ëª¨ë“œë³„ ì§€í‘œ ë²”ìœ„ ====================

# Quick ëª¨ë“œ (ìµœì†Œ ì¡°í•©, 4ê°œ) - ìŠ¹ë¥  80%+ & ë§¤ë§¤ë¹ˆë„ 0.5íšŒ/ì¼ ëª©í‘œ
# âœ… DEFAULT_PARAMS í¬í•¨: atr_mult=1.25, rsi_period=14, entry_validity_hours=6
INDICATOR_RANGE_QUICK = {
    'macd_fast': [8, 12],
    'macd_slow': [20, 26],
    'macd_signal': [9],
    'ema_period': [20, 50],
    'atr_mult': [1.25, 2.5],             # 2ê°œ - ìµœì ê°’(1.25) + ë³´ìˆ˜ê°’(2.5)
    'atr_period': [14],
    'rsi_period': [14],                  # 1ê°œ - í‘œì¤€ê°’ (ê³ ì •)
    'trail_start_r': [0.7, 1.0],
    'trail_dist_r': [0.35, 0.5],
    'pullback_rsi_long': [40],
    'pullback_rsi_short': [60],
    'pattern_tolerance': [0.05],
    'entry_validity_hours': [6, 48],     # 2ê°œ - ìµœì ê°’(6) + ì €ë¹ˆë„(48)
    'max_adds': [0, 1],
}
# í•µì‹¬ ì¡°í•©: 2 (atr_mult) Ã— 1 (rsi_period) Ã— 2 (entry_validity_hours) = 4ê°œ

# Standard ëª¨ë“œ (ê· í˜•, 36ê°œ) - ìŠ¹ë¥  75%+ & ë§¤ë§¤ë¹ˆë„ 1-2íšŒ/ì¼ ëª©í‘œ
# âœ… DEFAULT_PARAMS í¬í•¨: atr_mult=1.25, rsi_period=14, entry_validity_hours=6
INDICATOR_RANGE_STANDARD = {
    'macd_fast': [6, 8, 10, 12],
    'macd_slow': [18, 20, 24, 26],
    'macd_signal': [7, 9, 12],
    'ema_period': [10, 20, 30, 50],
    'atr_mult': [1.25, 1.5, 2.0, 2.5],       # 4ê°œ - ìµœì ê°’(1.25) í¬í•¨
    'atr_period': [7, 14, 21],
    'rsi_period': [7, 14, 21],               # 3ê°œ - ë‹¨ê¸°/í‘œì¤€/ì¥ê¸° ê· í˜•
    'trail_start_r': [0.5, 0.7, 1.0, 1.2],
    'trail_dist_r': [0.2, 0.35, 0.5, 0.7],
    'pullback_rsi_long': [35, 40, 45],
    'pullback_rsi_short': [55, 60, 65],
    'pattern_tolerance': [0.03, 0.04, 0.05],
    'entry_validity_hours': [6, 12, 24],     # 3ê°œ - ìµœì ê°’(6) í¬í•¨
    'max_adds': [0, 1, 2],
}
# í•µì‹¬ ì¡°í•©: 4 (atr_mult) Ã— 3 (rsi_period) Ã— 3 (entry_validity_hours) = 36ê°œ

# Deep ëª¨ë“œ (ì™„ì „ íƒìƒ‰, 252ê°œ) - ë‹¤ì–‘í•œ ìŠ¤íƒ€ì¼ íƒìƒ‰ (ê³µê²©Ã—3, ê· í˜•, ë³´ìˆ˜, ê³ ìŠ¹ë¥ , ì €ë¹ˆë„)
# âœ… DEFAULT_PARAMS í¬í•¨: atr_mult=1.25, rsi_period=14, entry_validity_hours=6
INDICATOR_RANGE_DEEP = {
    'atr_mult': [1.0, 1.25, 1.5, 2.0, 2.5, 3.0],  # 6ê°œ - ìµœì ê°’(1.25) í¬í•¨, 3.5 ì œê±°
    'rsi_period': [5, 7, 11, 14, 21, 25, 30],     # 7ê°œ - ì „ì²´ ë²”ìœ„
    'entry_validity_hours': [6, 12, 24, 36, 48, 72],  # 6ê°œ - ìµœì ê°’(6) í¬í•¨
}
# í•µì‹¬ ì¡°í•©: 6 (atr_mult) Ã— 7 (rsi_period) Ã— 6 (entry_validity_hours) = 252ê°œ


def get_indicator_range(mode: str = 'standard') -> Dict:
    """
    ëª¨ë“œì— ë”°ë¥¸ ì§€í‘œ ë²”ìœ„ ë°˜í™˜

    Args:
        mode: 'quick', 'standard', 'deep'

    Returns:
        ì§€í‘œ ë²”ìœ„ ë”•ì…”ë„ˆë¦¬
    """
    mode = mode.lower()

    if mode == 'quick':
        return INDICATOR_RANGE_QUICK.copy()
    elif mode == 'deep':
        return INDICATOR_RANGE_DEEP.copy()
    else:
        return INDICATOR_RANGE_STANDARD.copy()





# ==================== Grid ìƒì„± í•¨ìˆ˜ ====================

def generate_full_grid(trend_tf: str, max_mdd: float = 20.0) -> Dict:
    """
    Standard ëª¨ë“œìš© Grid (~60ê°œ) - ìŠ¹ë¥  & ë§¤ë§¤ë¹ˆë„ ìµœì í™”
    """
    from config.parameters import get_param_range_by_mode, DEFAULT_PARAMS

    tf_range = TF_AUTO_RANGE.get(trend_tf, TF_AUTO_RANGE['1h'])

    # None ë°©ì–´: get_param_range_by_mode() ë°˜í™˜ê°’ None ì²´í¬ + ê¸°ë³¸ê°’ í´ë°±
    filter_tf = get_param_range_by_mode('filter_tf', 'standard') or [DEFAULT_PARAMS.get('filter_tf', '4h')]
    atr_mult = get_param_range_by_mode('atr_mult', 'standard') or [DEFAULT_PARAMS.get('atr_mult', 1.5)]
    trail_start_r = get_param_range_by_mode('trail_start_r', 'standard') or [DEFAULT_PARAMS.get('trail_start_r', 0.8)]
    trail_dist_r = get_param_range_by_mode('trail_dist_r', 'standard') or [DEFAULT_PARAMS.get('trail_dist_r', 0.1)]
    entry_validity_hours = get_param_range_by_mode('entry_validity_hours', 'standard') or [DEFAULT_PARAMS.get('entry_validity_hours', 6.0)]

    return {
        'trend_interval': [trend_tf],
        'filter_tf': filter_tf,                                              # 3ê°œ ['4h', '6h', '12h']
        'entry_tf': [tf_range['entry_tf'][0]],                               # 1ê°œ (15m)
        'leverage': [1],                                                      # 1ê°œ (ê³ ì •)
        'direction': ['Both'],                                                # 1ê°œ (ê³ ì •)
        'max_mdd': [max_mdd],                                                 # 1ê°œ (ê³ ì •)
        'atr_mult': atr_mult,                                                 # 4ê°œ [1.25, 1.5, 2.0, 2.5]
        'trail_start_r': trail_start_r,                                       # 4ê°œ [1.0, 1.5, 2.0, 2.5]
        'trail_dist_r': trail_dist_r,                                         # 2ê°œ [0.2, 0.3]
        'pattern_tolerance': [0.05],                                          # 1ê°œ (ê³ ì •)
        'entry_validity_hours': entry_validity_hours,                         # 5ê°œ [6, 12, 24, 48, 72]
        'pullback_rsi_long': [40],                                            # 1ê°œ (ê³ ì •)
        'pullback_rsi_short': [60],                                           # 1ê°œ (ê³ ì •)
        # Total: 3Ã—1Ã—1Ã—1Ã—1Ã—4Ã—4Ã—2Ã—1Ã—5Ã—1Ã—1 = 120ê°œ âœ…
    }



def generate_quick_grid(trend_tf: str, max_mdd: float = 20.0) -> Dict:
    """Quick ëª¨ë“œìš© ìµœì†Œ Grid (~8ê°œ) - ìŠ¹ë¥  80% & ë§¤ë§¤ë¹ˆë„ 0.5íšŒ/ì¼ ëª©í‘œ"""
    from config.parameters import get_param_range_by_mode, DEFAULT_PARAMS

    tf_range = TF_AUTO_RANGE.get(trend_tf, TF_AUTO_RANGE['1h'])

    # None ë°©ì–´: get_param_range_by_mode() ë°˜í™˜ê°’ None ì²´í¬ + ê¸°ë³¸ê°’ í´ë°±
    filter_tf = get_param_range_by_mode('filter_tf', 'quick') or [DEFAULT_PARAMS.get('filter_tf', '4h')]
    atr_mult = get_param_range_by_mode('atr_mult', 'quick') or [DEFAULT_PARAMS.get('atr_mult', 1.5)]
    trail_start_r = get_param_range_by_mode('trail_start_r', 'quick') or [DEFAULT_PARAMS.get('trail_start_r', 0.8)]
    trail_dist_r = get_param_range_by_mode('trail_dist_r', 'quick') or [DEFAULT_PARAMS.get('trail_dist_r', 0.1)]
    entry_validity_hours = get_param_range_by_mode('entry_validity_hours', 'quick') or [DEFAULT_PARAMS.get('entry_validity_hours', 6.0)]

    return {
        'trend_interval': [trend_tf],
        'filter_tf': filter_tf,                                                # 2ê°œ ['12h', '1d']
        'entry_tf': [tf_range['entry_tf'][0]],                                # 1ê°œ (15m ê³ ì •)
        'leverage': [1],                                                       # 1ê°œ (ê³ ì •)
        'direction': ['Both'],                                                 # 1ê°œ (ê³ ì •)
        'max_mdd': [max_mdd],                                                  # 1ê°œ (ê³ ì •)
        'atr_mult': atr_mult,                                                  # 2ê°œ [1.25, 2.0]
        'trail_start_r': trail_start_r,                                        # 2ê°œ [1.0, 1.5]
        'trail_dist_r': trail_dist_r,                                          # 1ê°œ [0.2]
        'pattern_tolerance': [0.05],                                           # 1ê°œ (ê³ ì •)
        'entry_validity_hours': entry_validity_hours,                          # 2ê°œ [48, 72]
        'pullback_rsi_long': [40],                                             # 1ê°œ (ê³ ì •)
        'pullback_rsi_short': [60],                                            # 1ê°œ (ê³ ì •)
        # Total: 2Ã—1Ã—1Ã—1Ã—1Ã—2Ã—2Ã—1Ã—1Ã—2Ã—1Ã—1 = 8ê°œ âœ…
    }



def generate_standard_grid(trend_tf: str, max_mdd: float = 20.0) -> Dict:
    """Standard ëª¨ë“œìš© Grid (~5,000ê°œ)"""
    return generate_full_grid(trend_tf, max_mdd)

def generate_deep_grid(trend_tf: str, max_mdd: float = 20.0) -> Dict:
    """Deep ëª¨ë“œìš© ì •ë°€ Grid (~1,080ê°œ) - ì „ìˆ˜ ì¡°ì‚¬"""
    from config.parameters import get_param_range_by_mode, DEFAULT_PARAMS

    tf_range = TF_AUTO_RANGE.get(trend_tf, TF_AUTO_RANGE['1h'])

    # None ë°©ì–´: get_param_range_by_mode() ë°˜í™˜ê°’ None ì²´í¬ + ê¸°ë³¸ê°’ í´ë°±
    filter_tf = get_param_range_by_mode('filter_tf', 'deep') or [DEFAULT_PARAMS.get('filter_tf', '4h')]
    atr_mult = get_param_range_by_mode('atr_mult', 'deep') or [DEFAULT_PARAMS.get('atr_mult', 1.5)]
    trail_start_r = get_param_range_by_mode('trail_start_r', 'deep') or [DEFAULT_PARAMS.get('trail_start_r', 0.8)]
    trail_dist_r = get_param_range_by_mode('trail_dist_r', 'deep') or [DEFAULT_PARAMS.get('trail_dist_r', 0.1)]
    entry_validity_hours = get_param_range_by_mode('entry_validity_hours', 'deep') or [DEFAULT_PARAMS.get('entry_validity_hours', 6.0)]

    return {
        'trend_interval': [trend_tf],
        'filter_tf': filter_tf,                                               # 5ê°œ ['2h', '4h', '6h', '12h', '1d']
        'entry_tf': [tf_range['entry_tf'][0]],                               # 1ê°œ (15m ê³ ì •)
        'leverage': [1],                                                      # 1ê°œ (ê³ ì •)
        'direction': ['Both'],                                                # 1ê°œ (ê³ ì •)
        'max_mdd': [max_mdd],                                                 # 1ê°œ (ê³ ì •)
        'atr_mult': atr_mult,                                                 # 6ê°œ [1.0, 1.25, 1.5, 2.0, 2.5, 3.0]
        'trail_start_r': trail_start_r,                                       # 6ê°œ [0.8, 1.0, 1.5, 2.0, 2.5, 3.0]
        'trail_dist_r': trail_dist_r,                                         # 4ê°œ [0.15, 0.2, 0.25, 0.3]
        'pattern_tolerance': [0.05],                                          # 1ê°œ (ê³ ì •)
        'entry_validity_hours': entry_validity_hours,                         # 7ê°œ [6, 12, 24, 36, 48, 72, 96]
        'pullback_rsi_long': [40],                                            # 1ê°œ (ê³ ì •)
        'pullback_rsi_short': [60],                                           # 1ê°œ (ê³ ì •)
        # Total: 5Ã—1Ã—1Ã—1Ã—1Ã—6Ã—6Ã—4Ã—1Ã—7Ã—1Ã—1 = 1,080ê°œ âœ…
    }


def generate_grid_by_mode(
    trend_tf: str,
    mode: str = 'standard',
    max_mdd: float = 20.0,
    use_indicator_ranges: bool = False  # ê¸°ë³¸ê°’ Falseë¡œ ë³€ê²½ (ì¤‘ë³µ ë°©ì§€)
) -> Dict:
    """
    ëª¨ë“œì— ë”°ë¼ ì ì ˆí•œ ê·¸ë¦¬ë“œ ìƒì„± (í†µí•© í•¨ìˆ˜)

    Args:
        trend_tf: ì¶”ì„¸ íƒ€ì„í”„ë ˆì„
        mode: 'quick', 'standard', 'deep'
        max_mdd: ìµœëŒ€ ë‚™í­ í—ˆìš©ì¹˜
        use_indicator_ranges: Trueë©´ ëª¨ë“œë³„ ì§€í‘œ ë²”ìœ„ ì‚¬ìš©, Falseë©´ ê¸°ì¡´ ê·¸ë¦¬ë“œ ìœ ì§€

    Returns:
        íŒŒë¼ë¯¸í„° ê·¸ë¦¬ë“œ

    Examples:
        Quick ëª¨ë“œ (2-3ë¶„, ~100 ì¡°í•©):
            grid = generate_grid_by_mode('1h', 'quick')

        Standard ëª¨ë“œ (5-10ë¶„, ~500 ì¡°í•©):
            grid = generate_grid_by_mode('1h', 'standard')

        Deep ëª¨ë“œ (30-60ë¶„, ~5000 ì¡°í•©):
            grid = generate_grid_by_mode('1h', 'deep')
    """
    mode = mode.lower()

    # ê¸°ì¡´ ê·¸ë¦¬ë“œ í•¨ìˆ˜ ì‚¬ìš© (í•˜ìœ„ í˜¸í™˜ì„±)
    if mode == 'quick':
        grid = generate_quick_grid(trend_tf, max_mdd)
    elif mode == 'deep':
        grid = generate_deep_grid(trend_tf, max_mdd)
    else:
        grid = generate_standard_grid(trend_tf, max_mdd)

    # ëª¨ë“œë³„ ì§€í‘œ ë²”ìœ„ ì ìš© (ì„ íƒì )
    if use_indicator_ranges:
        indicator_range = get_indicator_range(mode)

        # ì§€í‘œ ë²”ìœ„ ë³‘í•© (ê¸°ì¡´ grid ìš°ì„ , ëˆ„ë½ëœ ì§€í‘œë§Œ ì¶”ê°€)
        for key, values in indicator_range.items():
            if key not in grid:
                grid[key] = values

    return grid


# ==================== ëª¨ë“œë³„ ê²°ê³¼ ê°œìˆ˜ ìƒìˆ˜ ====================
MODE_RESULT_COUNT = {
    'quick': 1,      # ìµœì  1ê°œ
    'standard': 3,   # ê³µê²©, ê· í˜•, ë³´ìˆ˜
    'deep': 5,       # ê³µê²©Ã—3, ê· í˜•, ë³´ìˆ˜ (+ ê³ ìŠ¹ë¥ , ì €ë¹ˆë„ = ìµœëŒ€ 7ê°œ)
}


def is_admin_mode() -> bool:
    """
    ê´€ë¦¬ì ê¶Œí•œ ì²´í¬ (Windows)
    Deep ëª¨ë“œ ì‚¬ìš© ì‹œ ê´€ë¦¬ì ê¶Œí•œ í•„ìš”
    
    Returns:
        True if running as admin, False otherwise
    """
    try:
        import ctypes
        return ctypes.windll.shell32.IsUserAnAdmin() != 0
    except Exception:
        # Windowsê°€ ì•„ë‹Œ ê²½ìš° ë˜ëŠ” ì²´í¬ ì‹¤íŒ¨ ì‹œ True ë°˜í™˜ (ì œí•œ ì—†ìŒ)
        return True


def get_mode_from_grid(grid: Dict) -> str:
    """
    Grid ì¡°í•© ìˆ˜ì— ë”°ë¼ ìë™ìœ¼ë¡œ ëª¨ë“œ ê²°ì •
    
    Args:
        grid: íŒŒë¼ë¯¸í„° ê·¸ë¦¬ë“œ
    
    Returns:
        'quick', 'standard', or 'deep'
    """
    total, _ = estimate_combinations(grid)
    
    if total <= 200:
        return 'quick'
    elif total <= 10000:
        return 'standard'
    else:
        return 'deep'


def validate_deep_mode() -> tuple:
    """
    Deep ëª¨ë“œ ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ ê²€ì¦
    
    Returns:
        (can_use: bool, message: str)
    """
    if not is_admin_mode():
        return False, "âš ï¸ Deep ëª¨ë“œëŠ” ê´€ë¦¬ì ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤. ê´€ë¦¬ìë¡œ ì‹¤í–‰í•´ì£¼ì„¸ìš”."
    
    # ë©”ëª¨ë¦¬ ì²´í¬ (ìµœì†Œ 8GB ê¶Œì¥)
    try:
        import psutil
        available_gb = psutil.virtual_memory().available / (1024**3)
        if available_gb < 4:
            return False, f"âš ï¸ Deep ëª¨ë“œëŠ” ìµœì†Œ 4GB ë©”ëª¨ë¦¬ê°€ í•„ìš”í•©ë‹ˆë‹¤. (í˜„ì¬: {available_gb:.1f}GB)"
    except ImportError:
        pass  # psutil ì—†ìœ¼ë©´ ì²´í¬ ìŠ¤í‚µ
    
    return True, "âœ… Deep ëª¨ë“œ ì‚¬ìš© ê°€ëŠ¥"



def generate_fast_grid(trend_tf: str, max_mdd: float = 20.0) -> Dict:
    """
    ë¹ ë¥¸ íƒìƒ‰ìš© ì¶•ì†Œ Grid ìƒì„±
    - INDICATOR_RANGEì—ì„œ ì„±ê¸´(Sparse) í˜•íƒœë¡œ ìƒ˜í”Œë§
    
    Args:
        trend_tf: ì¶”ì„¸ íƒ€ì„í”„ë ˆì„
        max_mdd: ìµœëŒ€ í—ˆìš© MDD (%)
    
    Returns:
        ì¶•ì†Œëœ íŒŒë¼ë¯¸í„° grid dict
    """
    tf_range = TF_AUTO_RANGE.get(trend_tf, TF_AUTO_RANGE['1h'])
    
    # INDICATOR_RANGEì—ì„œ ì§•ê²€ë‹¤ë¦¬ì‹ìœ¼ë¡œ ì„ íƒ (ë°ì´í„° ìˆ˜ ëŒ€í­ ê°ì†Œ)
    grid = {
        'trend_interval': [trend_tf],
        'filter_tf': [tf_range['filter_tf'][0]],      # ìµœì  í›„ë³´ 1ê°œ
        'entry_tf': [tf_range['entry_tf'][0]],        # ìµœì  í›„ë³´ 1ê°œ
        'leverage': [3, 10],                          # 2ë‹¨ê³„ ìƒëµ
        'direction': ['Both'],                         # ê¸°ë³¸ ë°©í–¥
        'max_mdd': [max_mdd],
        'atr_mult': [1.25, 1.35, 1.5],                 # [MOD] ë³´ìˆ˜ì  ë²”ìœ„ë¡œ ì œí•œ
        'trail_start_r': INDICATOR_RANGE['trail_start_r'][::3], # [0.5, 0.8, 1.1]
        'trail_dist_r': INDICATOR_RANGE['trail_dist_r'][::3],   # [0.1, 0.25, 0.4]
    }
    
    return grid


def estimate_combinations(grid: Dict) -> tuple:
    """
    íŒŒë¼ë¯¸í„° ì¡°í•© ìˆ˜ ë° ì˜ˆìƒ ì‹œê°„ ê³„ì‚°
    
    Args:
        grid: íŒŒë¼ë¯¸í„° grid dict
    
    Returns:
        (ì¡°í•©ìˆ˜, ì˜ˆìƒì‹œê°„ë¶„)
    """
    total = 1
    for key, values in grid.items():
        if isinstance(values, list):
            total *= len(values)
    
    # ë°±í…ŒìŠ¤íŠ¸ 1íšŒë‹¹ ì•½ 0.05ì´ˆ ê°€ì •
    estimated_seconds = total * 0.05
    estimated_minutes = estimated_seconds / 60
    
    return (total, round(estimated_minutes, 1))


@dataclass
class OptimizationResult:
    """
    ìµœì í™” ê²°ê³¼ ë°ì´í„°
    
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    ğŸ“Š ì§€í‘œë³„ ì˜í–¥ ê´€ê³„ (METRICS IMPACT REFERENCE)
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    [ì…ë ¥ íŒŒë¼ë¯¸í„°] â†’ [ì˜í–¥ ì§€í‘œ]
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    â€¢ atr_mult (ATR ë°°ìˆ˜)
      â†’ max_drawdown: ATRâ†‘ = ë„“ì€ SL = MDDâ†‘
      â†’ win_rate: ATRâ†‘ = ì—¬ìœ ìˆëŠ” SL = ìŠ¹ë¥ â†‘ (ì¡°ê¸° ì²­ì‚° ë°©ì§€)
      â†’ trades: ì˜í–¥ ì ìŒ
    
    â€¢ trail_start_r (íŠ¸ë ˆì¼ë§ ì‹œì‘ Rë°°ìˆ˜)
      â†’ simple_return/compound_return: ì‹œì‘â†‘ = ë” ë§ì´ ìˆ˜ìµ í™•ë³´ í›„ íŠ¸ë ˆì¼ë§
      â†’ win_rate: ì‹œì‘â†‘ = ìµì ˆ í™•ë¥ â†‘
      â†’ max_drawdown: ê°„ì ‘ ì˜í–¥
    
    â€¢ trail_dist_r (íŠ¸ë ˆì¼ë§ ê±°ë¦¬ Rë°°ìˆ˜)
      â†’ max_drawdown: ê±°ë¦¬â†‘ = ì²­ì‚° ëŠ¦ìŒ = MDDâ†‘
      â†’ simple_return: ê±°ë¦¬â†‘ = ìˆ˜ìµ ë” ì¶”êµ¬ = ìˆ˜ìµâ†‘ or ë°˜ë‚©
    
    â€¢ leverage (ë ˆë²„ë¦¬ì§€)
      â†’ simple_return/compound_return: ë ˆë²„ë¦¬ì§€â†‘ = ìˆ˜ìµë¥ â†‘ (ë¹„ë¡€)
      â†’ max_drawdown: ë ˆë²„ë¦¬ì§€â†‘ = MDDâ†‘ (ë¹„ë¡€)
      â†’ sharpe_ratio: ë³€ë™ì„±â†‘ = ìƒ¤í”„â†“
    
    â€¢ direction (ë°©í–¥: Long/Short/Both)
      â†’ trades: Both = ê±°ë˜â†‘â†‘
      â†’ win_rate: ì‹œì¥ ìƒí™©ì— ë”°ë¼ ë³€ë™
    
    â€¢ filter_tf (í•„í„° íƒ€ì„í”„ë ˆì„)
      â†’ win_rate: ìƒìœ„TF í•„í„° = ì‹ í˜¸ í’ˆì§ˆâ†‘ = ìŠ¹ë¥ â†‘
      â†’ trades: ì—„ê²©í•œ í•„í„° = ê±°ë˜â†“
    
    â€¢ entry_tf (ì§„ì… íƒ€ì„í”„ë ˆì„)
      â†’ trades: ì‘ì€TF = ê¸°íšŒâ†‘ = ê±°ë˜â†‘
      â†’ win_rate: íƒ€ì´ë° ì •í™•ë„ì— ì˜í–¥
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    
    [ì§€í‘œ ê³„ì‚° ìœ„ì¹˜]
    â€¢ win_rate: _calculate_metrics() â†’ (ìˆ˜ìµê±°ë˜/ì „ì²´ê±°ë˜) Ã— 100
    â€¢ max_drawdown: _calculate_metrics() â†’ ìµœê³ ì  ëŒ€ë¹„ ìµœëŒ€ í•˜ë½í­
    â€¢ sharpe_ratio: _calculate_metrics() â†’ (í‰ê· ìˆ˜ìµ/í‘œì¤€í¸ì°¨) Ã— âˆš252
    â€¢ simple_return: _calculate_metrics() â†’ Î£(ê° ê±°ë˜ ìˆ˜ìµë¥ )
    â€¢ compound_return: _calculate_metrics() â†’ Î (1+ìˆ˜ìµë¥ ) - 1
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """
    params: Dict                          # ì‚¬ìš©ëœ íŒŒë¼ë¯¸í„°
    trades: int                           # ë§¤ë§¤ íšŸìˆ˜ â†’ direction, filter_tf, entry_tf ì˜í–¥
    win_rate: float                       # ìŠ¹ë¥ (%) â†’ atr_mult, filter_tf ì˜í–¥
    total_return: float                   # [DEPRECATED] simple_return ë˜ëŠ” compound_return ì‚¬ìš©
    simple_return: float = 0.0            # ë‹¨ë¦¬ ìˆ˜ìµë¥  â†’ leverage, trail_* ì˜í–¥
    compound_return: float = 0.0          # ë³µë¦¬ ìˆ˜ìµë¥  â†’ leverage, trail_* ì˜í–¥
    max_drawdown: float = 0.0             # MDD(%) â†’ atr_mult, leverage, trail_dist_r ì˜í–¥
    sharpe_ratio: float = 0.0             # ìƒ¤í”„ë¹„ìœ¨ â†’ leverage ì˜í–¥ (ë³€ë™ì„±)
    profit_factor: float = 0.0            # ìˆ˜ìµíŒ©í„° â†’ ì „ì²´ì  íŒŒë¼ë¯¸í„° ì˜í–¥
    avg_trades_per_day: float = 0.0       # ì¼í‰ê·  ê±°ë˜ìˆ˜
    stability: str = "âš ï¸"                 # 3êµ¬ê°„ ì•ˆì •ì„± ì§€í‘œ
    strategy_type: str = ""               # ì „ëµ ìœ í˜• (ğŸ”¥ê³µê²©, âš–ê· í˜•, ğŸ›¡ë³´ìˆ˜)
    grade: str = ""                       # ë“±ê¸‰ (S/A/B/C)
    capital_mode: str = "compound"        # ìë³¸ ëª¨ë“œ
    avg_pnl: float = 0.0                  # [NEW] í‰ê·  PnL (%)
    cagr: float = 0.0                     # [NEW] ì—°ê°„ ë³µë¦¬ ìˆ˜ìµë¥  (%)
    passes_filter: bool = True            # [NEW] í•„í„° í†µê³¼ ì—¬ë¶€ (MDD, ìŠ¹ë¥ , ê±°ë˜ìˆ˜)
    symbol: str = ""                      # [NEW] ì‹¬ë³¼ (ë°±í…ŒìŠ¤íŠ¸ìš©)
    timeframe: str = ""                   # [NEW] íƒ€ì„í”„ë ˆì„ (ë°±í…ŒìŠ¤íŠ¸ìš©)
    final_capital: float = 0.0            # [NEW] ìµœì¢… ìë³¸ (ë°±í…ŒìŠ¤íŠ¸ìš©)


# calculate_grade() í•¨ìˆ˜ ì œê±° (utils.metrics.assign_grade_by_preset()ë¡œ ëŒ€ì²´)
# ì´ì „ ìœ„ì¹˜: ë¼ì¸ 376-393
# ìƒˆë¡œìš´ ë“±ê¸‰ ì‹œìŠ¤í…œì€ í”„ë¦¬ì…‹ë³„ ëª©í‘œ ê¸°ì¤€ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.


def _worker_run_single(strategy_class, params, df_pattern, df_entry, slippage, fee):
    """ë©€í‹°í”„ë¡œì„¸ì‹± ì§€ì›ì„ ìœ„í•œ ë…ë¦½í˜• ì›Œì»¤ í•¨ìˆ˜"""
    try:
        # ë°©í–¥ ì²˜ë¦¬
        leverage = params.get('leverage', 3)
        if isinstance(leverage, list): leverage = leverage[0]
        leverage = int(leverage)
        
        direction = params.get('direction', 'Both')
        if isinstance(direction, list): direction = direction[0]
        
        filter_tf = params.get('filter_tf', '4h')
        if isinstance(filter_tf, list): filter_tf = filter_tf[0]
        
        # ì „ëµ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
        strategy = strategy_class()
        
        # ì´ ë¹„ìš©
        total_cost = slippage + fee
        
        # ë°±í…ŒìŠ¤íŠ¸ ì‹¤í–‰ (íŒŒë¼ë¯¸í„°í™” ì™„ë£Œ)
        trades = strategy.run_backtest(
            df_pattern=df_pattern,
            df_entry=df_entry,
            slippage=total_cost,
            atr_mult=params.get('atr_mult', DEFAULT_PARAMS.get('atr_mult', 1.5)),
            trail_start_r=params.get('trail_start_r', DEFAULT_PARAMS.get('trail_start_r', 0.8)),
            trail_dist_r=params.get('trail_dist_r', DEFAULT_PARAMS.get('trail_dist_r', 0.5)),
            pattern_tolerance=params.get('pattern_tolerance', DEFAULT_PARAMS.get('pattern_tolerance', 0.03)),
            entry_validity_hours=params.get('entry_validity_hours', DEFAULT_PARAMS.get('entry_validity_hours', 12.0)),
            pullback_rsi_long=params.get('pullback_rsi_long', DEFAULT_PARAMS.get('pullback_rsi_long', 35)),
            pullback_rsi_short=params.get('pullback_rsi_short', DEFAULT_PARAMS.get('pullback_rsi_short', 65)),
            max_adds=params.get('max_adds', DEFAULT_PARAMS.get('max_adds', 1)),
            filter_tf=filter_tf,
            rsi_period=params.get('rsi_period', DEFAULT_PARAMS.get('rsi_period', 14)),
            atr_period=params.get('atr_period', DEFAULT_PARAMS.get('atr_period', 14)),
            macd_fast=params.get('macd_fast', DEFAULT_PARAMS.get('macd_fast', 12)),
            macd_slow=params.get('macd_slow', DEFAULT_PARAMS.get('macd_slow', 26)),
            macd_signal=params.get('macd_signal', DEFAULT_PARAMS.get('macd_signal', 9)),
            ema_period=params.get('ema_period', DEFAULT_PARAMS.get('ema_period', 20)),
            enable_pullback=params.get('enable_pullback', False)
        )

        
        if not trades:
            return None
            
        min_trades = params.get('min_trades', 1)
        if len(trades) < min_trades:
            return None
            
        # ë°©í–¥ í•„í„°ë§
        if direction != 'Both':
            trades = [t for t in trades if t['type'] == direction]
            if len(trades) < min_trades: return None
            
        # ë ˆë²„ë¦¬ì§€ ì ìš©
        for t in trades:
            t['pnl'] = t['pnl'] * leverage
            
        # ë©”íŠ¸ë¦­ ê³„ì‚° (ê³µìš© ì •ì  ë©”ì„œë“œ í˜¸ì¶œ)
        metrics = BacktestOptimizer.calculate_metrics(trades)
        
        # MDD í•„í„°
        max_mdd_limit = params.get('max_mdd', 100.0)
        if max_mdd_limit < 100.0 and abs(metrics['max_drawdown']) > max_mdd_limit:
            return None
            
        # ë“±ê¸‰ í• ë‹¹ (strategy_typeì€ ë‚˜ì¤‘ì— _classify_results()ì—ì„œ í• ë‹¹)
        # ì—¬ê¸°ì„œëŠ” ê· í˜•í˜• ê¸°ì¤€ìœ¼ë¡œ ì„ì‹œ ë“±ê¸‰ ë¶€ì—¬
        grade = assign_grade_by_preset(
            preset_type='balanced',
            metrics={
                'win_rate': metrics['win_rate'],
                'profit_factor': metrics['profit_factor'],
                'mdd': metrics['max_drawdown'],
                'sharpe_ratio': metrics['sharpe_ratio'],
                'compound_return': metrics['compound_return']
            }
        )

        return OptimizationResult(
            params=params,
            trades=len(trades),
            win_rate=metrics['win_rate'],
            total_return=metrics['total_return'],
            simple_return=metrics['simple_return'],
            compound_return=metrics['compound_return'],
            max_drawdown=metrics['max_drawdown'],
            sharpe_ratio=metrics['sharpe_ratio'],
            profit_factor=metrics['profit_factor'],
            avg_trades_per_day=metrics.get('avg_trades_per_day', 0.0),
            stability=metrics.get('stability', "âš ï¸"),
            grade=grade,
            avg_pnl=metrics.get('avg_pnl', 0.0),
            cagr=metrics.get('cagr', 0.0)
        )
    except Exception:
        return None



    # _calculate_metrics_standalone removed and unified inside BacktestOptimizer



class BacktestOptimizer:
    """íŒŒë¼ë¯¸í„° ê·¸ë¦¬ë“œ ì„œì¹˜ ìµœì í™”"""
    
    # TF ë§¤í•‘ì€ ìƒë‹¨ì—ì„œ importí•œ TF_MAPPING ì‚¬ìš©
    
    def __init__(
        self,
        strategy_class,
        df: Optional[pd.DataFrame] = None,
        strategy_type: str = 'macd'
    ):
        """
        Args:
            strategy_class: X7PlusStrategy ë“± ì „ëµ í´ë˜ìŠ¤
            df: ë°±í…ŒìŠ¤íŠ¸ìš© ë°ì´í„°í”„ë ˆì„
            strategy_type: ì „ëµ ìœ í˜• ('macd' or 'adx')
        """
        self.strategy_class = strategy_class
        self.df = df
        self.strategy_type = strategy_type
        self.results: List[OptimizationResult] = []
        self.progress_callback: Optional[Callable] = None
        self.cancelled = False
    
    def set_data(self, df: pd.DataFrame) -> None:
        """ë°ì´í„° ì„¤ì •"""
        self.df = df
    
    def set_progress_callback(self, callback: Optional[Callable]) -> None:
        """ì§„í–‰ë¥  ì½œë°± ì„¤ì •"""
        self.progress_callback = callback
    
    def cancel(self) -> None:
        """ìµœì í™” ì·¨ì†Œ"""
        self.cancelled = True
        
    def _resample(self, df: pd.DataFrame, target_tf: str, quiet: bool = False) -> pd.DataFrame:
        """15m â†’ Target TF ë¦¬ìƒ˜í”Œë§ (ê³µìš© í•¨ìˆ˜ ì‚¬ìš©)"""
        # ê³µìš© utils.data_utils.resample_data ì‚¬ìš©
        if shared_resample:
            return shared_resample(df, target_tf, add_indicators=True)
        
        # Fallback: ë¡œì»¬ êµ¬í˜„
        rule = TF_RESAMPLE_MAP.get(target_tf, target_tf)
        df = df.copy()
        if 'datetime' not in df.columns:
            if pd.api.types.is_numeric_dtype(df['timestamp']):
                df['datetime'] = pd.to_datetime(df['timestamp'], unit='ms', utc=True)
            else:
                df['datetime'] = pd.to_datetime(df['timestamp'])
        df = df.set_index('datetime')
        resampled = df.resample(rule).agg({
            'timestamp': 'first', 'open': 'first', 'high': 'max',
            'low': 'min', 'close': 'last', 'volume': 'sum'
        }).dropna().reset_index()
        try:
            from utils.indicators import IndicatorGenerator
            resampled = IndicatorGenerator.add_all_indicators(resampled)
            if 'rsi' not in resampled.columns and 'rsi_14' in resampled.columns:
                resampled['rsi'] = resampled['rsi_14']
            if 'atr' not in resampled.columns and 'atr_14' in resampled.columns:
                resampled['atr'] = resampled['atr_14']
        except Exception as e:
            if not quiet: logger.info(f"âš ï¸ ì§€í‘œ ì¬ê³„ì‚° ì‹¤íŒ¨: {e}")
        if not quiet: logger.info(f"ğŸ“Š [OPT] ì§€í‘œ ì¬ê³„ì‚°: {target_tf} ({len(resampled)}ìº”ë“¤)")
        return resampled
    
    def run_optimization(self, df: Optional[pd.DataFrame], grid: Dict, max_workers: int = 4,
                         metric: str = 'WinRate', task_callback: Optional[Callable] = None,
                         capital_mode: str = 'compound', n_cores: Optional[int] = None,
                         mode: str = 'standard') -> List[OptimizationResult]:
        """
        ê·¸ë¦¬ë“œ ì„œì¹˜ ìµœì í™” ì‹¤í–‰
        
        Args:
            df: ë°±í…ŒìŠ¤íŠ¸ìš© ë°ì´í„°í”„ë ˆì„
            grid: íŒŒë¼ë¯¸í„° ê·¸ë¦¬ë“œ
            max_workers: ìµœëŒ€ ì›Œì»¤ ìˆ˜ (deprecated, n_cores ì‚¬ìš©)
            metric: ì •ë ¬ ê¸°ì¤€ ë©”íŠ¸ë¦­
            task_callback: ì‘ì—… ì½œë°±
            capital_mode: ìë³¸ ëª¨ë“œ ('simple' or 'compound')
            n_cores: CPU ì½”ì–´ ìˆ˜
            mode: ìµœì í™” ëª¨ë“œ ('quick'=1ê°œ, 'standard'=3ê°œ, 'deep'=5ê°œ+)
        
        Returns:
            ìµœì í™” ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        """
        self.df = df
        self.results = []
        self.cancelled = False
        self.capital_mode = capital_mode.lower()
        if self.df is None or self.df.empty:
            raise ValueError("ë°ì´í„°ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
        
        # [FIX] df íƒ€ì„ìŠ¤íƒ¬í”„ ë³€í™˜ (í•œ ë²ˆë§Œ ìˆ˜í–‰)
        df = self.df.copy()
        if not pd.api.types.is_datetime64_any_dtype(df['timestamp']):
            first_ts = df['timestamp'].iloc[0]
            if isinstance(first_ts, (int, float, np.number)) and first_ts > 100000000000:
                df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms', utc=True)
            else:
                df['timestamp'] = pd.to_datetime(df['timestamp'])
        self.df = df

        self.cancelled = False
        self.results = []
        
        # ë¦¬ìƒ˜í”Œë§ ìºì‹œ ì´ˆê¸°í™”
        self._resample_cache = {}
        
        # ëª¨ë“  íŒŒë¼ë¯¸í„° ì¡°í•© ìƒì„±
        keys = list(grid.keys())
        values = list(grid.values())
        combinations = list(itertools.product(*values))
        total = len(combinations)
        
        # [NEW] n_cores ì²˜ë¦¬
        if n_cores is None:
            import multiprocessing
            n_cores = multiprocessing.cpu_count()
        
        # [NEW] ì§€í‘œ ì„ í–‰ ê³„ì‚° (ThreadPool ê²½í•© ë°©ì§€)
        all_trend_tfs = set(grid.get('trend_interval', []))
        all_entry_tfs = set(grid.get('entry_tf', []))
        
        for tf in all_trend_tfs:
            key = f"p_{tf}"
            if key not in self._resample_cache:
                self._resample_cache[key] = self._resample(df, tf)
                
        for tf in all_entry_tfs:
            key = f"e_{tf}"
            if key not in self._resample_cache:
                if tf and tf not in ['15min', '15m']:
                    self._resample_cache[key] = self._resample(df, tf)
                else:
                    self._resample_cache[key] = df.copy()
        
        logger.info(f"Optimization started: {total} combinations, {n_cores} cores (ProcessPool)")
        
        # ë³‘ë ¬ ì²˜ë¦¬ (ProcessPoolExecutor)
        from concurrent.futures import ProcessPoolExecutor, as_completed
        
        with ProcessPoolExecutor(max_workers=n_cores) as executor:
            # TFë³„ ë¯¸ë¦¬ ë¦¬ìƒ˜í”Œë§ëœ DFë“¤ì„ ë§µìœ¼ë¡œ ì¤€ë¹„
            # (ë©€í‹°í”„ë¡œì„¸ì‹± ì‹œ íŒŒë¼ë¯¸í„°ë¡œ ë§¤ë²ˆ DFë¥¼ í†µì§¸ë¡œ ì „ë‹¬í•˜ë©´ ì˜¤ë²„í—¤ë“œê°€ í¬ì§€ë§Œ, 
            #  ì—¬ê¸°ì„œëŠ” pickleë¡œ ì „ë‹¬ë¨)
            
            futures = []
            for combo in combinations:
                params = dict(zip(keys, combo))
                
                # í•´ë‹¹ ì¡°í•©ì— ë§ëŠ” cached df ì¶”ì¶œ
                trend_tf = params.get('trend_interval', '4h')
                if isinstance(trend_tf, list): trend_tf = trend_tf[0]
                entry_tf = params.get('entry_tf')
                if isinstance(entry_tf, list): entry_tf = entry_tf[0]
                if not entry_tf:
                    try:
                        from GUI.constants import TF_MAPPING
                    except ImportError:
                        # Fallback if GUI package not found or structure differs
                        TF_MAPPING = {'1h': '15m', '4h': '1h', '1d': '4h'}
                    entry_tf = TF_MAPPING.get(trend_tf, '15min')
                
                df_pattern = self._resample_cache.get(f"p_{trend_tf}")
                df_entry = self._resample_cache.get(f"e_{entry_tf}")
                
                # íŒŒë¼ë¯¸í„°ì—ì„œ ê°’ ì¶”ì¶œ
                _symbol = params.get('symbol', 'BTCUSDT')
                _leverage = params.get('leverage', 3)
                if isinstance(_leverage, list): _leverage = _leverage[0]
                _slippage = params.get('slippage', DEFAULT_PARAMS['slippage'])
                _fee = params.get('fee', DEFAULT_PARAMS['fee'])

                futures.append(executor.submit(
                    _worker_run_single,
                    self.strategy_class,
                    params,
                    df_pattern,
                    df_entry,
                    _slippage,
                    _fee
                ))
            
            for i, future in enumerate(as_completed(futures)):
                if self.cancelled:
                    logger.info("âŒ ìµœì í™” ì·¨ì†Œë¨")
                    executor.shutdown(wait=False, cancel_futures=True)
                    break

                try:
                    # íƒ€ì„ì•„ì›ƒ 10ì´ˆ ì„¤ì • (Deep ëª¨ë“œ ëŒ€ì‘)
                    result = future.result(timeout=10)
                    if result:
                        # === í•„í„°ë§ ì¡°ê±´ (v3.0 - SSOT ê¸°ë°˜ ì‚¬ìš©ì ëª©í‘œ) ===
                        # ì „ëµ: ê³ í’ˆì§ˆ ê²°ê³¼ë§Œ ìˆ˜ì§‘ â†’ ì •ë ¬ë¡œ ìµœì  ì¡°í•© ì°¾ê¸°
                        # SSOT: config.parameters.OPTIMIZATION_FILTER
                        # 1. ìŠ¹ë¥  â‰¥ 80%
                        # 2. MDD â‰¤ 20%
                        # 3. ì „ì²´ ë‹¨ë¦¬ ìˆ˜ìµë¥  â‰¥ 0.5%
                        # 4. ì¼í‰ê·  ê±°ë˜ ë¹ˆë„ â‰¥ 0.5íšŒ/ì¼
                        # 5. ì ˆëŒ€ ìµœì†Œ ê±°ë˜ìˆ˜ â‰¥ 10ê°œ
                        from config.parameters import OPTIMIZATION_FILTER

                        # ê±°ë˜ ë¹ˆë„ ê³„ì‚° (avg_trades_per_dayëŠ” ì´ë¯¸ resultì— ìˆìŒ)
                        avg_trades_per_day = result.avg_trades_per_day

                        passes_filter = (
                            result.win_rate >= OPTIMIZATION_FILTER['min_win_rate'] and
                            abs(result.max_drawdown) <= OPTIMIZATION_FILTER['max_mdd'] and
                            result.simple_return >= OPTIMIZATION_FILTER['min_total_return'] and
                            avg_trades_per_day >= OPTIMIZATION_FILTER['min_trades_per_day'] and
                            result.trades >= OPTIMIZATION_FILTER['min_absolute_trades']
                        )

                        if passes_filter:
                            self.results.append(result)
                            if task_callback:
                                task_callback(result)
                except Exception as e:
                    # í”„ë¡œì„¸ìŠ¤ ì˜¤ë¥˜ ë¡œê·¸
                    pass
                
                # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
                if self.progress_callback:
                    progress = int((i + 1) / total * 100)
                    self.progress_callback(progress)
        
        # ê²°ê³¼ ì •ë ¬ ë° ìƒì„¸ ë¶„ë¥˜ (v2)
        if self.results:
            # 1. ì§€ì •ëœ ë©”íŠ¸ë¦­ìœ¼ë¡œ ì „ì²´ ì •ë ¬
            self.results.sort(key=lambda x: getattr(x, metric, 0), reverse=True)
            
            # 2. [NEW] ëŒ€í‘œ ìœ í˜• ë§¤ì¹­ (ì›ë³¸ ë¦¬ìŠ¤íŠ¸ëŠ” ìœ ì§€í•˜ê³  íƒœê¹…ë§Œ ìˆ˜í–‰)
            # ìƒìœ„ 1000ê°œ ê²°ê³¼ ì¤‘ ì¤‘ë³µ ì—†ëŠ” ëŒ€í‘œ ìœ í˜•ë“¤ ì„ ì •
            top_results = self.results[:1000]
            unique_for_classification = self.filter_unique_results(top_results, max_count=100)
            representatives = self._classify_results(unique_for_classification, mode=mode)
            
            # ëŒ€í‘œ ìœ í˜•ë“¤ì„ self.results ìƒë‹¨ì— ë°°ì¹˜í•˜ê³  ë‚˜ë¨¸ì§€ëŠ” ìˆœì„œ ìœ ì§€
            rep_keys = [str(r.params) for r in representatives]
            final_list = representatives + [r for r in self.results if str(r.params) not in rep_keys]
            
            self.results = final_list[:2000] # ë©”ëª¨ë¦¬ ê´€ë¦¬ë¥¼ ìœ„í•´ ìƒìœ„ 2000ê°œë¡œ ì œí•œ


        # ë¦¬ìƒ˜í”Œë§ ìºì‹œ ì •ë¦¬ (ë©”ëª¨ë¦¬ í•´ì œ)
        self._resample_cache = {}
        
        logger.info(f"âœ… ìµœì í™” ì™„ë£Œ: {len(self.results)}ê°œ ëŒ€í‘œ ê²°ê³¼ ë„ì¶œ")
        return self.results

    def save_results_to_csv(
        self,
        exchange: str,
        symbol: str,
        timeframe: str,
        mode: str = 'deep',
        output_dir: str = 'data/optimization_results'
    ) -> str:
        """
        ìµœì í™” ê²°ê³¼ë¥¼ CSVë¡œ ì €ì¥

        Args:
            exchange: ê±°ë˜ì†Œ
            symbol: ì‹¬ë³¼
            timeframe: íƒ€ì„í”„ë ˆì„
            mode: ìµœì í™” ëª¨ë“œ
            output_dir: ì¶œë ¥ ë””ë ‰í† ë¦¬

        Returns:
            ì €ì¥ëœ CSV íŒŒì¼ ê²½ë¡œ
        """
        from datetime import datetime

        if not self.results:
            raise ValueError("ì €ì¥í•  ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤")

        # 1. DataFrame ìƒì„±
        rows = []
        for rank, result in enumerate(self.results, 1):
            row = {
                'rank': rank,
                'score': result.profit_factor * (result.win_rate / 100) if result.win_rate else 0,
                'win_rate': result.win_rate,
                'profit_factor': result.profit_factor,
                'mdd': result.max_drawdown,
                'sharpe': result.sharpe_ratio,
                'sortino': getattr(result, 'sortino_ratio', 0),
                'calmar': getattr(result, 'calmar_ratio', 0),
                'trades': result.trades,
                'total_return': result.simple_return,
                **result.params  # ëª¨ë“  íŒŒë¼ë¯¸í„° ì»¬ëŸ¼ìœ¼ë¡œ ì¶”ê°€
            }
            rows.append(row)

        df = pd.DataFrame(rows)

        # 2. íŒŒì¼ëª… ìƒì„±
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        filename = f"{exchange}_{symbol}_{timeframe}_{mode}_{timestamp}.csv"

        # 3. ì €ì¥
        output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)
        csv_path = output_path / filename

        df.to_csv(csv_path, index=False, encoding='utf-8')

        logger.info(f"CSV ì €ì¥ ì™„ë£Œ: {csv_path} ({len(df)} rows)")
        return str(csv_path)
    
    def _run_single(self, params: Dict, slippage: float, fee: float) -> Optional[OptimizationResult]:
        """ë‹¨ì¼ íŒŒë¼ë¯¸í„° ì¡°í•©ìœ¼ë¡œ ë°±í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        if self.df is None:
            return None
            
        assert self.df is not None, "self.df cannot be None here"
        
        try:
            # íŒŒë¼ë¯¸í„° ì¶”ì¶œ (ë¦¬ìŠ¤íŠ¸ì¼ ê²½ìš° ë‹¨ì¼ ê°’ìœ¼ë¡œ ë³€í™˜)
            filter_tf = params.get('filter_tf', '4h')
            if isinstance(filter_tf, list): filter_tf = filter_tf[0]
            
            trend_tf = params.get('trend_interval', '1h')
            if isinstance(trend_tf, list): trend_tf = trend_tf[0]
            
            # Entry TF: paramsì— ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ TF_MAPPING
            entry_tf = params.get('entry_tf')
            if isinstance(entry_tf, list): entry_tf = entry_tf[0]
            if not entry_tf:
                entry_tf = TF_MAPPING.get(trend_tf, '15min')
            
            # [NEW] ë¦¬ìƒ˜í”Œë§ ìºì‹œ ì‚¬ìš© (ì„±ëŠ¥ ëŒ€í­ í–¥ìƒ)
            if not hasattr(self, '_resample_cache'): self._resample_cache = {}
            
            # df_pattern ìºì‹œ í‚¤
            p_key = f"p_{trend_tf}"
            if p_key not in self._resample_cache:
                self._resample_cache[p_key] = self._resample(self.df, trend_tf)
            df_pattern = self._resample_cache[p_key]
            
            # df_entry ìºì‹œ í‚¤
            e_key = f"e_{entry_tf}"
            if e_key not in self._resample_cache:
                if entry_tf and entry_tf not in ['15min', '15m']:
                    self._resample_cache[e_key] = self._resample(self.df, entry_tf)
                else:
                    self._resample_cache[e_key] = self.df.copy()
            df_entry = self._resample_cache[e_key]
            
            # ë°°ìœ¨/ë°©í–¥ ì²˜ë¦¬
            leverage = params.get('leverage', 3)
            if isinstance(leverage, list): leverage = leverage[0]
            leverage = int(leverage)
            
            direction = params.get('direction', 'Both')
            if isinstance(direction, list): direction = direction[0]
            
            # ì „ëµ ìƒì„± ì‹œ íŒŒë¼ë¯¸í„° ì „ë‹¬
            init_params = {}
            if 'trend_interval' in params:
               init_params['trend_interval'] = params['trend_interval']
            
            # ê³„ì‚°ëœ entry_intervalë„ ì „ë‹¬ (ì „ëµ ë‚´ë¶€ ë¦¬ìƒ˜í”Œë§ìš©)
            init_params['entry_interval'] = entry_tf
            
            # ì „ëµ ì¸ìŠ¤í„´ìŠ¤ ìƒì„± (Core)
            # strategy_classëŠ” AlphaX7Coreë¼ê³  ê°€ì • (ë˜ëŠ” í˜¸í™˜)
            # AlphaX7CoreëŠ” initì— dfë¥¼ ë°›ì§€ ì•ŠìŒ. stateless.
            try:
                strategy = self.strategy_class()
                # paramsì— 'rsi_period'ê°€ ìˆìœ¼ë©´ ì „ë‹¬í•´ì•¼ í•¨
            except Exception:
                # ë ˆê±°ì‹œ í˜¸í™˜ (í˜¹ì‹œ ë‹¤ë¥¸ ì „ëµì„ ì“¸ ê²½ìš°)
                strategy = self.strategy_class(df=df, **init_params)
                if hasattr(strategy, 'prepare_data'):
                    strategy.prepare_data()
            
            # âœ… ì´ ë¹„ìš© ê³„ì‚° (ìŠ¬ë¦¬í”¼ì§€ + ìˆ˜ìˆ˜ë£Œ)
            # AlphaX7CoreëŠ” 'slippage' ì¸ìë¥¼ ì°¨ê°í•  ë•Œ 2ë°°ë¥¼ ì ìš©í•˜ë¯€ë¡œ (pnl - slippage*2)
            # ì™•ë³µ ìˆ˜ìˆ˜ë£Œì™€ ìŠ¬ë¦¬í”¼ì§€ë¥¼ í•©ì‚°í•˜ì—¬ ì „ë‹¬í•˜ë©´ ë¨.
            # ì˜ˆ: ìŠ¬ë¦¬í”¼ì§€ 0.05%, ìˆ˜ìˆ˜ë£Œ 0.05% -> í•© 0.1% -> ë¡œì§ìƒ 2ë°°ì¸ 0.2%(ì™•ë³µ) ë¹„ìš© ì²˜ë¦¬
            total_cost = slippage + fee
            
            # ê¸°ë³¸ íŒŒë¼ë¯¸í„°ì™€ ë³‘í•© (DEFAULT_PARAMS ì°¸ì¡°)
            backtest_params = {
                'slippage': total_cost,  # ì´ ë¹„ìš© ì ìš©
                'atr_mult': params.get('atr_mult', DEFAULT_PARAMS.get('atr_mult', 1.5)),
                'trail_start_r': params.get('trail_start_r', DEFAULT_PARAMS.get('trail_start_r', 0.8)),
                'trail_dist_r': params.get('trail_dist_r', DEFAULT_PARAMS.get('trail_dist_r', 0.5)),
                'pattern_tolerance': params.get('pattern_tolerance', DEFAULT_PARAMS.get('pattern_tolerance', 0.03)),
                'entry_validity_hours': params.get('entry_validity_hours', DEFAULT_PARAMS.get('entry_validity_hours', 12.0)),
                'pullback_rsi_long': params.get('pullback_rsi_long', DEFAULT_PARAMS.get('pullback_rsi_long', 35)),
                'pullback_rsi_short': params.get('pullback_rsi_short', DEFAULT_PARAMS.get('pullback_rsi_short', 65)),
                'max_adds': params.get('max_adds', DEFAULT_PARAMS.get('max_adds', 1))
            }
            
            # ğŸ“Š ë””ë²„ê¹… ë¡œê·¸
            if params.get('trend_interval') == '1d' and params.get('atr_mult') == 1.5:
                logger.info(f"ğŸ“Š [OPT] slippage={total_cost:.4f}, atr_mult={backtest_params['atr_mult']}, trail_start_r={backtest_params['trail_start_r']}, trail_dist_r={backtest_params['trail_dist_r']}")
            
            # ì „ëµ ì‹¤í–‰ ì‹œ ì „ë‹¬í•  íŒŒë¼ë¯¸í„°
            # X7PlusStrategy.run_backtest_plusì— filter_tf ì „ë‹¬
            backtest_params['filter_tf'] = filter_tf
            
            # ë°±í…ŒìŠ¤íŠ¸ ì‹¤í–‰ (Core Interface)
            if hasattr(strategy, 'run_backtest') and not hasattr(strategy, 'run_backtest_plus'):
                # AlphaX7Core
                trades = strategy.run_backtest(
                    df_pattern=df_pattern,
                    df_entry=df_entry,  # [FIX] ì›ë³¸ 15min ë°ì´í„° ì‚¬ìš©
                    slippage=total_cost,  # [FIX] ì´ ë¹„ìš© ì „ë‹¬
                    atr_mult=backtest_params.get('atr_mult'),
                    trail_start_r=backtest_params.get('trail_start_r'),
                    trail_dist_r=backtest_params.get('trail_dist_r'),
                    pattern_tolerance=backtest_params.get('pattern_tolerance'),
                    entry_validity_hours=backtest_params.get('entry_validity_hours'),
                    pullback_rsi_long=backtest_params.get('pullback_rsi_long'),
                    pullback_rsi_short=backtest_params.get('pullback_rsi_short'),
                    max_adds=backtest_params.get('max_adds'),
                    filter_tf=filter_tf,
                    rsi_period=params.get('rsi_period', DEFAULT_PARAMS.get('rsi_period', 14)),
                    atr_period=params.get('atr_period', DEFAULT_PARAMS.get('atr_period', 14)),
                    macd_fast=params.get('macd_fast', DEFAULT_PARAMS.get('macd_fast', 12)),
                    macd_slow=params.get('macd_slow', DEFAULT_PARAMS.get('macd_slow', 26)),
                    macd_signal=params.get('macd_signal', DEFAULT_PARAMS.get('macd_signal', 9)),
                    ema_period=params.get('ema_period', DEFAULT_PARAMS.get('ema_period', 20)),
                    enable_pullback=params.get('enable_pullback', False)  # [NEW] ë¶ˆíƒ€ê¸° ì˜µì…˜
                )

            else:
                # Legacy Strategy
                backtest_params['filter_tf'] = filter_tf
                trades = strategy.run_backtest_plus(**backtest_params)
            
            # [DEBUG] ê±°ë˜ ìˆ˜ í™•ì¸
            # logger.info(f"[DEBUG-OPT] ê±°ë˜ ìˆ˜: {len(trades) if trades else 0}ê°œ")
            
            # [FIX] 10ê°œëŠ” ë„ˆë¬´ ê°€í˜¹í•¨ (ìµœì†Œ ê±°ë˜ìˆ˜ íŒŒë¼ë¯¸í„°í™”)
            min_trades = params.get('min_trades', 3)
            if not trades or len(trades) < min_trades:
                return None
            
            # 1. ë°©í–¥ í•„í„°ë§
            if direction != 'Both':
                trades = [t for t in trades if t['type'] == direction]
                if len(trades) < 3: return None
            
            # [FIX] Option 2: ë ˆë²„ë¦¬ì§€ ìë™ ìµœì í™” (MDD íƒ€ê²Ÿ ë§ì¶¤)
            # 2. ë ˆë²„ë¦¬ì§€ ì ìš© (ê·¸ë¦¬ë“œì— ì„¤ì •ëœ ì •ìˆ˜ ë°°ìœ¨ ì‚¬ìš©)
            max_mdd_limit = params.get('max_mdd', 20.0)
            if isinstance(max_mdd_limit, list): max_mdd_limit = max_mdd_limit[0]
            
            # ê·¸ë¦¬ë“œì—ì„œ ë„˜ì–´ì˜¨ ë ˆë²„ë¦¬ì§€ (í•­ìƒ ì •ìˆ˜ì—¬ì•¼ í•¨)
            grid_leverage = int(leverage)
            
            # ë ˆë²„ë¦¬ì§€ ì ìš© (PnL ìˆ˜ì •)
            for t in trades:
                t['pnl'] = t['pnl'] * grid_leverage
            
            # ë©”íŠ¸ë¦­ ê³„ì‚° (ë ˆë²„ë¦¬ì§€ ë°˜ì˜ë¨)
            metrics = self._calculate_metrics(trades)
            
            # [FIX] ë ˆë²„ë¦¬ì§€ ì ìš© í›„ MDDê°€ í•œë„ë¥¼ ì´ˆê³¼í•˜ë©´ íƒˆë½ (max_mddê°€ 100ì´ë©´ ì‚¬ì‹¤ìƒ ë¬´ì‹œ)
            if max_mdd_limit < 100.0 and abs(metrics['max_drawdown']) > max_mdd_limit:
                return None

            # ë“±ê¸‰ í• ë‹¹ (ê· í˜•í˜• ê¸°ì¤€ìœ¼ë¡œ ì„ì‹œ ë“±ê¸‰ ë¶€ì—¬)
            grade = assign_grade_by_preset(
                preset_type='balanced',
                metrics={
                    'win_rate': metrics['win_rate'],
                    'profit_factor': metrics['profit_factor'],
                    'mdd': metrics['max_drawdown'],
                    'sharpe_ratio': metrics['sharpe_ratio'],
                    'compound_return': metrics['compound_return']
                }
            )

            return OptimizationResult(
                params=params,
                trades=len(trades),
                win_rate=metrics['win_rate'],
                total_return=metrics['total_return'],
                simple_return=metrics['simple_return'],
                compound_return=metrics['compound_return'],
                max_drawdown=metrics['max_drawdown'],
                sharpe_ratio=metrics['sharpe_ratio'],
                profit_factor=metrics['profit_factor'],
                avg_trades_per_day=metrics.get('avg_trades_per_day', 0.0),
                stability=metrics.get('stability', "âš ï¸"),
                grade=grade,
                avg_pnl=metrics.get('avg_pnl', 0.0),
                cagr=metrics.get('cagr', 0.0)
            )
            
        except Exception as e:
            logger.warning(f"  âš ï¸ ë°±í…ŒìŠ¤íŠ¸ ì˜¤ë¥˜: {e}")
            return None
    
    @staticmethod
    def calculate_mdd(equity_curve: List[float]) -> float:
        """
        Equity Curveì—ì„œ MDD ê³„ì‚°
        Args:
            equity_curve: ìì‚° ê³¡ì„  (List[float])
        Returns:
            MDD (%)
        """
        if not equity_curve:
            return 0.0
            
        peak = equity_curve[0]
        max_drawdown = 0.0
        
        for val in equity_curve:
            if val > peak:
                peak = val
            
            if peak > 1e-9:
                drawdown = (peak - val) / peak * 100
                if drawdown > max_drawdown:
                    max_drawdown = drawdown
                    
        return min(max_drawdown, 100.0)

    @staticmethod
    def calculate_metrics(trades: List[Dict]) -> Dict:
        """
        ê±°ë˜ ê²°ê³¼ì—ì„œ ë©”íŠ¸ë¦­ ê³„ì‚° (í†µí•© ì •ì  ë©”ì„œë“œ)
        
        â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        ğŸ“Š ì§€í‘œ ê³„ì‚° ê³µì‹ (METRICS CALCULATION FORMULAS)
        â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        
        1. win_rate (ìŠ¹ë¥ )
           ê³µì‹: (ìˆ˜ìµ ê±°ë˜ ìˆ˜ / ì „ì²´ ê±°ë˜ ìˆ˜) Ã— 100
           ì˜í–¥: filter_tfâ†‘ â†’ ìŠ¹ë¥ â†‘, atr_multâ†‘ â†’ ìŠ¹ë¥ â†‘
        
        2. simple_return (ë‹¨ë¦¬ ìˆ˜ìµë¥ )
           ê³µì‹: Î£(ê° ê±°ë˜ì˜ PnL%)
           ì˜í–¥: leverageâ†‘ â†’ ìˆ˜ìµâ†‘, trail_start_râ†‘ â†’ ìˆ˜ìµâ†‘
        
        3. compound_return (ë³µë¦¬ ìˆ˜ìµë¥ )
           ê³µì‹: (Î (1 + PnL%/100) - 1) Ã— 100
           ì˜í–¥: leverageâ†‘ â†’ ìˆ˜ìµâ†‘â†‘ (ë³µë¦¬ íš¨ê³¼)
        
        4. max_drawdown (MDD, ìµœëŒ€ ë‚™í­)
           ê³µì‹: max((peak - current) / peak Ã— 100)
           ì˜í–¥: leverageâ†‘ â†’ MDDâ†‘, atr_multâ†‘ â†’ MDDâ†‘
        
        5. sharpe_ratio (ìƒ¤í”„ ë¹„ìœ¨)
           ê³µì‹: (í‰ê·  ìˆ˜ìµ / í‘œì¤€í¸ì°¨) Ã— âˆš(252 Ã— 4)
           ì˜í–¥: leverageâ†‘ â†’ ë³€ë™ì„±â†‘ â†’ ìƒ¤í”„â†“
        
        6. profit_factor (ìˆ˜ìµ íŒ©í„°)
           ê³µì‹: ì´ ìˆ˜ìµ / ì´ ì†ì‹¤
           ì˜í–¥: ì „ì²´ íŒŒë¼ë¯¸í„°ì˜ ë³µí•© íš¨ê³¼
        â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        """
        if not trades:
            return {k: 0 for k in ['win_rate', 'total_return', 'simple_return', 'compound_return', 'max_drawdown', 'sharpe_ratio', 'profit_factor']}
            
        pnls = [t.get('pnl', 0) for t in trades]
        pnl_series = pd.Series(pnls)

        # ê¸°ë³¸ ë©”íŠ¸ë¦­ - SSOT ì‚¬ìš©
        win_rate = calculate_win_rate(trades)
        simple_return = pnl_series.sum()
        
        # 1. ëˆ„ì  ìˆ˜ìµë¥  (Compound/Equity) ê³„ì‚°
        # [FIX] ë‹¨ì¼ ê±°ë˜ PnL ìƒí•œì„  ì ìš© (Â±50%) - ì˜¤ë²„í”Œë¡œìš° ë°©ì§€
        MAX_SINGLE_PNL = 50.0  # ë‹¨ì¼ ê±°ë˜ ìµœëŒ€ ìˆ˜ìµë¥  ìƒí•œ
        MIN_SINGLE_PNL = -50.0  # ë‹¨ì¼ ê±°ë˜ ìµœëŒ€ ì†ì‹¤ë¥  í•˜í•œ
        
        equity = 1.0
        cumulative_equity = [1.0]
        for p in pnls:
            # PnL í´ë¨í•‘ (ìƒí•œ/í•˜í•œ ì ìš©)
            clamped_pnl = max(MIN_SINGLE_PNL, min(MAX_SINGLE_PNL, p))
            equity *= (1 + clamped_pnl / 100)
            if equity <= 0: equity = 0
            cumulative_equity.append(equity)
            if equity == 0: break
        
        compound_return = (equity - 1) * 100
        compound_return = max(-100.0, min(compound_return, 1e10))  # ë²”ìœ„ ì œí•œ: -100% ~ 1e10%

        # 2. ìµœëŒ€ ë‚™í­ (MDD %) ê³„ì‚° - SSOT ì‚¬ìš©
        # PnL í´ë¨í•‘ì´ ì ìš©ëœ trades ë¦¬ìŠ¤íŠ¸ ìƒì„±
        clamped_trades = []
        for p in pnls:
            clamped_pnl = max(MIN_SINGLE_PNL, min(MAX_SINGLE_PNL, p))
            clamped_trades.append({'pnl': clamped_pnl})

        # SSOT calculate_mdd() í˜¸ì¶œ
        max_drawdown = calculate_mdd(clamped_trades)
        
        # 3. ìƒ¤í”„ ë¹„ìœ¨ (Sharpe Ratio, ì—°ê°„í™”) - SSOT
        sharpe_ratio = calculate_sharpe_ratio(pnl_series.tolist(), periods_per_year=252 * 4)

        # 4. Profit Factor - SSOT
        trades_for_pf = [{'pnl': p} for p in pnls]
        profit_factor = calculate_profit_factor(trades_for_pf)

        # 5. ì•ˆì •ì„± ê³„ì‚° - âœ… Phase 1-E P0-2: SSOT ì‚¬ìš©
        from utils.metrics import calculate_stability
        stability = calculate_stability(pnls)

        # 6. ì¼í‰ê·  ê±°ë˜ìˆ˜ ê³„ì‚°
        avg_trades_per_day = 0.0
        if len(trades) >= 2:
            try:
                # entry_time ë˜ëŠ” entry_idx ê¸°ë°˜ ê¸°ê°„ ê³„ì‚°
                first_entry = trades[0].get('entry_time') or trades[0].get('entry_idx', 0)
                last_entry = trades[-1].get('entry_time') or trades[-1].get('entry_idx', len(trades))
                
                if hasattr(first_entry, 'astype'):  # numpy datetime64
                    first_entry = pd.Timestamp(first_entry)
                    last_entry_ts = pd.Timestamp(last_entry)
                    # NaT ì²´í¬
                    if isinstance(last_entry_ts, type(pd.NaT)):
                        raise ValueError("last_entry is NaT")
                    last_entry = last_entry_ts

                if isinstance(first_entry, (pd.Timestamp, np.datetime64)):
                    first_ts = pd.Timestamp(first_entry)
                    last_ts = pd.Timestamp(last_entry)
                    # NaT ì²´í¬
                    if isinstance(first_ts, type(pd.NaT)) or isinstance(last_ts, type(pd.NaT)):
                        raise ValueError("Timestamp is NaT")
                    total_days = max((last_ts - first_ts).days, 1)  # type: ignore[operator]
                else:
                    # index ê¸°ë°˜ (ëŒ€ëµ 1ì‹œê°„ë´‰ ê¸°ì¤€ 24ìº”ë“¤ = 1ì¼)
                    total_days = max((last_entry - first_entry) / 24, 1)  # type: ignore[operator]
                
                avg_trades_per_day = round(len(trades) / total_days, 2)
            except Exception:

                avg_trades_per_day = round(len(trades) / 30, 2)  # ê¸°ë³¸ 30ì¼ ê°€ì •

        result = {
            'win_rate': round(win_rate, 2),
            'total_pnl': round(simple_return, 2),  # âœ… SSOT í‘œì¤€ í•„ë“œëª…
            'simple_return': round(simple_return, 2),
            'compound_return': round(compound_return, 2),
            'mdd': round(max_drawdown, 2),  # âœ… SSOT í‘œì¤€ í•„ë“œëª…
            'sharpe_ratio': round(sharpe_ratio, 2),
            'profit_factor': round(profit_factor, 2),
            'stability': stability,
            'avg_trades_per_day': avg_trades_per_day,
            'avg_pnl': round(pnl_series.mean(), 4),
            'cagr': round(BacktestOptimizer._calculate_cagr(equity, trades), 2)
        }

        # í•˜ìœ„ í˜¸í™˜ì„±: alias ì œê³µ (Deprecated)
        result['total_return'] = result['total_pnl']  # Deprecated: use 'total_pnl'
        result['max_drawdown'] = result['mdd']  # Deprecated: use 'mdd'

        return result

    @staticmethod
    def _calculate_cagr(final_equity: float, trades: List[Dict]) -> float:
        """
        ì—°ê°„ ë³µë¦¬ ì„±ì¥ë¥ (CAGR) ê³„ì‚°

        Wrapper for utils.metrics.calculate_cagr() (SSOT)
        """
        from utils.metrics import calculate_cagr
        return calculate_cagr(trades, final_capital=final_equity, initial_capital=1.0)

    def _calculate_metrics(self, trades: List[Dict]) -> Dict:
        """ì¸ìŠ¤í„´ìŠ¤ìš© í•˜ìœ„ í˜¸í™˜ ë©”ì„œë“œ"""
        return self.calculate_metrics(trades)

    def _calculate_stability(self, pnls: List[float]) -> str:
        """
        3êµ¬ê°„ ì•ˆì •ì„± ì²´í¬ (ê³¼ê±°/ì¤‘ê°„/ìµœê·¼)

        Wrapper for utils.metrics.calculate_stability() (SSOT)
        """
        from utils.metrics import calculate_stability
        return calculate_stability(pnls)

    def _classify_results(self, results: List[OptimizationResult], mode: str = 'standard') -> List[OptimizationResult]:
        """
        ê²°ê³¼ë¥¼ í´ëŸ¬ìŠ¤í„°ë§í•˜ì—¬ ìœ í˜•ë³„ ëŒ€í‘œê°’ ì„ ì • (v3 ê°œì„ )
        
        Args:
            results: ìµœì í™” ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
            mode: 'quick' (1ê°œ), 'standard' (3ê°œ), 'deep' (5ê°œ+)
        
        Returns:
            ëŒ€í‘œ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        """
        if not results:
            return []
        
        # ê²°ê³¼ ë³µì‚¬ ë° ì •ë ¬ ê¸°ì¤€ë³„ í•„í„°ë§
        representatives = []
        seen_params = set()

        def add_rep(res, label):
            param_key = str(res.params)
            if param_key not in seen_params:
                res.strategy_type = label
                # í”„ë¦¬ì…‹ íƒ€ì…ì— ë§ê²Œ ë“±ê¸‰ ì¬í• ë‹¹
                res.grade = assign_grade_by_preset(
                    preset_type=label,
                    metrics={
                        'win_rate': res.win_rate,
                        'profit_factor': res.profit_factor,
                        'mdd': res.max_drawdown,
                        'sharpe_ratio': res.sharpe_ratio,
                        'compound_return': res.compound_return
                    }
                )
                representatives.append(res)
                seen_params.add(param_key)
        
        def add_multiple_reps(sorted_results, label_prefix, count):
            """ìƒìœ„ Nê°œ ê²°ê³¼ë¥¼ ì¶”ê°€ (ì¤‘ë³µ ì œì™¸)"""
            added = 0
            for i, res in enumerate(sorted_results):
                if added >= count:
                    break
                param_key = str(res.params)
                if param_key not in seen_params:
                    res.strategy_type = f"{label_prefix}#{added+1}"
                    # í”„ë¦¬ì…‹ íƒ€ì…ì— ë§ê²Œ ë“±ê¸‰ ì¬í• ë‹¹
                    res.grade = assign_grade_by_preset(
                        preset_type=label_prefix,  # "ğŸ”¥ê³µê²©" ë“±
                        metrics={
                            'win_rate': res.win_rate,
                            'profit_factor': res.profit_factor,
                            'mdd': res.max_drawdown,
                            'sharpe_ratio': res.sharpe_ratio,
                            'compound_return': res.compound_return
                        }
                    )
                    representatives.append(res)
                    seen_params.add(param_key)
                    added += 1

        profitable = [r for r in results if r.total_return > 0]
        
        # ===== Quick ëª¨ë“œ: 1ê°œ (ìµœê³  ìŠ¤ì½”ì–´) =====
        if mode == 'quick':
            # ë³µí•© ìŠ¤ì½”ì–´ ê¸°ì¤€ ìµœê³  1ê°œ
            best = max(results, key=lambda x: (
                x.win_rate * 1.0 + 
                (100 - abs(x.max_drawdown)) * 0.5 + 
                x.sharpe_ratio * 2.0
            ))
            add_rep(best, "ğŸ†ìµœì ")
            return representatives
        
        # ===== Standard ëª¨ë“œ: 3ê°œ (ê³µê²©, ê· í˜•, ë³´ìˆ˜) =====
        if mode == 'standard':
            # 1. ğŸ”¥ê³µê²©í˜•: ìµœê³  ìˆ˜ìµë¥ 
            aggressive = max(results, key=lambda x: x.compound_return)
            add_rep(aggressive, "ğŸ”¥ê³µê²©")
            
            # 2. âš–ê· í˜•í˜•: ìµœê³  ìƒ¤í”„ ì§€ìˆ˜
            balanced = max(results, key=lambda x: x.sharpe_ratio)
            add_rep(balanced, "âš–ê· í˜•")
            
            # 3. ğŸ›¡ë³´ìˆ˜í˜•: ìµœì € MDD (ìˆ˜ìµ > 0 ì¤‘)
            if profitable:
                conservative = min(profitable, key=lambda x: abs(x.max_drawdown))
                add_rep(conservative, "ğŸ›¡ë³´ìˆ˜")
            
            return representatives
        
        # ===== Deep ëª¨ë“œ: 5ê°œ+ (ê³µê²©Ã—3, ê· í˜•, ë³´ìˆ˜) =====
        # 1. ğŸ”¥ê³µê²©í˜• Top 3: ìµœê³  ìˆ˜ìµë¥  ìƒìœ„ 3ê°œ
        sorted_by_return = sorted(results, key=lambda x: x.compound_return, reverse=True)
        add_multiple_reps(sorted_by_return, "ğŸ”¥ê³µê²©", 3)
        
        # 2. âš–ê· í˜•í˜•: ìµœê³  ìƒ¤í”„ ì§€ìˆ˜
        balanced = max(results, key=lambda x: x.sharpe_ratio)
        add_rep(balanced, "âš–ê· í˜•")
        
        # 3. ğŸ›¡ë³´ìˆ˜í˜•: ìµœì € MDD (ìˆ˜ìµ > 0 ì¤‘)
        if profitable:
            conservative = min(profitable, key=lambda x: abs(x.max_drawdown))
            add_rep(conservative, "ğŸ›¡ë³´ìˆ˜")
        
        # 4. ğŸ¯ê³ ìŠ¹ë¥ í˜•: ìµœê³  ìŠ¹ë¥ 
        high_wr = max(results, key=lambda x: x.win_rate)
        add_rep(high_wr, "ğŸ¯ê³ ìŠ¹ë¥ ")
        
        # 5. ğŸ¢ì €ë¹ˆë„í˜•: ì¼í‰ê·  ê±°ë˜ ê°€ì¥ ì ì€ ê²ƒ (ìˆ˜ìµ > 0)
        if profitable:
            low_freq = min(profitable, key=lambda x: getattr(x, 'avg_trades_per_day', x.trades / 30))
            add_rep(low_freq, "ğŸ¢ì €ë¹ˆë„")
        
        return representatives
    
    def get_best(self, n: int = 10) -> List[OptimizationResult]:
        """ìƒìœ„ Nê°œ ê²°ê³¼ ë°˜í™˜"""
        return self.results[:n]
    
    def analyze_top_results(self, n: int = 100, threshold: float = 0.85) -> Dict:
        """
        ìƒìœ„ ê²°ê³¼ ë¶„ì„ â†’ ì§€ë°°ì  íŒŒë¼ë¯¸í„° ê³ ì • ë° ë²”ìœ„ ì¶•ì†Œ (Iterative Optimizationìš©)
        
        Args:
            n: ë¶„ì„í•  ìƒìœ„ ê²°ê³¼ ìˆ˜
            threshold: ê³ ì • íŒë‹¨ ì„ê³„ê°’ (ì˜ˆ: 0.85 -> 85% ì´ìƒ ê°™ì€ ê°’ì´ë©´ ê³ ì •)
            
        Returns:
            Dict: ì¶•ì†Œëœ íŒŒë¼ë¯¸í„° ê·¸ë¦¬ë“œ
        """
        if not self.results:
            return {}
            
        from collections import Counter
        top_results = sorted(self.results, key=lambda x: getattr(x, 'sharpe_ratio', 0), reverse=True)[:n]
        
        # ë¶„ì„ ëŒ€ìƒ íŒŒë¼ë¯¸í„° (ì§€í‘œ ê´€ë ¨)
        target_params = ['atr_mult', 'trail_start_r', 'trail_dist_r', 'pattern_tolerance', 'entry_validity_hours', 'pullback_rsi_long', 'pullback_rsi_short', 'filter_tf', 'entry_tf', 'leverage']

        
        fixed_params = {}
        reduced_ranges = {}
        
        for param in target_params:
            # í•´ë‹¹ íŒŒë¼ë¯¸í„° ê°’ ì¶”ì¶œ
            values = []
            for res in top_results:
                val = res.params.get(param)
                if val is not None:
                    if isinstance(val, list): val = val[0]
                    values.append(val)
            
            if not values: continue
            
            # ë¹ˆë„ ë¶„ì„
            counts = Counter(values)
            most_common_val, count = counts.most_common(1)[0]
            ratio = count / len(values)
            
            if ratio >= threshold:
                # ì§€ë°°ì ì¸ ê°’ ë°œê²¬ -> ê³ ì •
                fixed_params[param] = [most_common_val]
                logger.info(f"ğŸ“Œ [OPT-ADAPT] '{param}' fixed to {most_common_val} (Dominance: {ratio:.1%})")
            else:
                # ë¶„í¬ ë¶„ì„ -> ë²”ìœ„ ì¶•ì†Œ (ìµœì†Œ~ìµœëŒ€ê°’ ì‚¬ì´ë¥¼ ë‹¤ì‹œ ì´˜ì´˜í•˜ê²Œ)
                min_v = min(values)
                max_v = max(values)
                
                # ê¸°ì¡´ INDICATOR_RANGEë‚˜ ì›ë³¸ ê·¸ë¦¬ë“œì—ì„œ í•´ë‹¹ êµ¬ê°„ì˜ ê°’ë“¤ ì¶”ì¶œ
                # ì—¬ê¸°ì„œëŠ” ê°„ë‹¨íˆ 5ë¶„í• í•˜ì—¬ ì´˜ì´˜í•˜ê²Œ ìƒì„±
                if isinstance(min_v, (int, float)) and not isinstance(min_v, bool):
                     # ìˆ˜ì¹˜í˜• íŒŒë¼ë¯¸í„°
                     step = (max_v - min_v) / 5
                     if step > 0:
                         new_vals = [round(min_v + step * i, 3) for i in range(6)]
                         reduced_ranges[param] = sorted(list(set(new_vals)))
                     else:
                         reduced_ranges[param] = [min_v]
                else:
                    # ì¹´í…Œê³ ë¦¬í˜• (filter_tf ë“±)
                    reduced_ranges[param] = sorted(list(set(values)))
                
                logger.debug(f"ğŸ” [OPT-ADAPT] '{param}' range narrowed: {min_v} ~ {max_v}")

        # ìƒˆë¡œìš´ ê·¸ë¦¬ë“œ ìƒì„±
        new_grid = {}
        # 1. ê³ ì •ëœ ê°’ ì ìš©
        new_grid.update(fixed_params)
        # 2. ì¶•ì†Œëœ ë²”ìœ„ ì ìš©
        new_grid.update(reduced_ranges)
        
        # 3. ê³µí†µ í•„ë“œ ìœ ì§€ (trend_interval, max_mdd ë“±)
        if self.results:
            first_params = self.results[0].params
            for k in ['trend_interval', 'max_mdd', 'direction']:
                if k not in new_grid and k in first_params:
                    val = first_params[k]
                    new_grid[k] = val if isinstance(val, list) else [val]
        
        return new_grid

    def filter_unique_results(self, results: Optional[List[OptimizationResult]] = None, 
                              max_count: int = 30) -> List[OptimizationResult]:
        """
        ì¤‘ë³µ/ìœ ì‚¬ ê²°ê³¼ ì œê±° + ìƒìœ„ Nê°œ ì„ íƒ
        
        ê¸°ì¤€:
        - ìŠ¹ë¥  1% ì´ë‚´ + MDD 2% ì´ë‚´ = ìœ ì‚¬ ê²°ê³¼
        - ìœ ì‚¬ ê·¸ë£¹ ë‚´ â†’ ë³µí•© ìŠ¤ì½”ì–´ ë†’ì€ 1ê°œë§Œ
        - ìµœì¢… max_countê°œ ë°˜í™˜
        """
        if results is None:
            results = self.results
        
        if not results:
            return []
        
        # ë³µí•© ìŠ¤ì½”ì–´ ê³„ì‚° (ìŠ¹ë¥  > MDD > ìƒ¤í”„ > ìˆ˜ìµë¥ )
        def calc_score(r):
            return (
                r.win_rate * 1.0 +                    # ìŠ¹ë¥  88% â†’ 88ì 
                (100 + r.max_drawdown) * 0.5 +        # MDD -17% â†’ 41.5ì 
                r.sharpe_ratio * 2.0 +                # ìƒ¤í”„ 26 â†’ 52ì 
                min(r.total_return / 100, 50) * 0.2   # ìˆ˜ìµë¥  cap 50
            )
        
        # ìŠ¤ì½”ì–´ ìˆœ ì •ë ¬
        scored = sorted(results, key=calc_score, reverse=True)
        
        # ìœ ì‚¬ ê²°ê³¼ ì œê±°
        unique = []
        for r in scored:
            is_duplicate = False
            for u in unique:
                # MDDëŠ” ë³´í†µ ìŒìˆ˜ì´ë¯€ë¡œ abs()ë¡œ ì°¨ì´ í™•ì¸
                if (abs(r.win_rate - u.win_rate) < 1.0 and
                    abs(r.max_drawdown - u.max_drawdown) < 2.0):
                    is_duplicate = True
                    break
            
            if not is_duplicate:
                unique.append(r)
            
            if len(unique) >= max_count:
                break
        
        logger.info(f"ğŸ”„ [FILTER] {len(results)} â†’ {len(unique)} (ì¤‘ë³µ ì œê±°)")
        return unique

    def to_dataframe(self) -> pd.DataFrame:
        """ê²°ê³¼ë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜"""
        if not self.results:
            return pd.DataFrame()
        
        rows = []
        for r in self.results:
            row = {**r.params}
            row['trades'] = r.trades
            row['win_rate'] = r.win_rate
            row['total_return'] = r.total_return
            row['max_drawdown'] = r.max_drawdown
            row['sharpe_ratio'] = r.sharpe_ratio
            row['profit_factor'] = r.profit_factor
            rows.append(row)
        
        return pd.DataFrame(rows)


# í…ŒìŠ¤íŠ¸
if __name__ == "__main__":
    import os
    import sys
    import pandas as pd
    import traceback
    
    try:
        # 1. ê²½ë¡œ ì„¤ì •
        BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
        if BASE_DIR not in sys.path:
            sys.path.append(BASE_DIR)
        
        from core.strategy_core import AlphaX7Core
        
        # ë°ì´í„° ë¡œë“œ (Parquet ìš°ì„  íƒìƒ‰)
        csv_path = os.path.join(BASE_DIR, 'data', 'cache', 'bybit_btcusdt_15m.parquet')
        if not os.path.exists(csv_path):
            csv_path = os.path.join(BASE_DIR, 'data', 'bybit_BTCUSDT_15m.csv') # Fallback
            
        logger.info(f"ğŸ“Š Testing with: {csv_path}")
        
        if os.path.exists(csv_path):
            if csv_path.endswith('.parquet'):
                df = pd.read_parquet(csv_path)
            else:
                df = pd.read_csv(csv_path)
                
            # íƒ€ì„ìŠ¤íƒ¬í”„ ë³€í™˜
            if 'timestamp' in df.columns and not pd.api.types.is_datetime64_any_dtype(df['timestamp']):
                first_ts = df['timestamp'].iloc[0]
                val = float(first_ts)
                if val > 1e12:
                    df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms', utc=True)
                elif val > 1e8:
                    df['timestamp'] = pd.to_datetime(df['timestamp'], unit='s')
                else:
                    df['timestamp'] = pd.to_datetime(df['timestamp'])
            
            # ìµœê·¼ 5000ê°œë§Œ ì‚¬ìš© (í…ŒìŠ¤íŠ¸ìš©)
            df = df.tail(5000).reset_index(drop=True)
            logger.info(f"Loaded {len(df)} candles. Range: {df['timestamp'].iloc[0]} ~ {df['timestamp'].iloc[-1]}")
            
            # 1. ìµœì í™” ì—”ì§„ ì‹œì‘
            optimizer = BacktestOptimizer(AlphaX7Core, df)
            grid = generate_fast_grid('1h')
            
            logger.info(f"ğŸš€ [Stage 1] Fast Grid Search Starting...")
            results = optimizer.run_optimization(df, grid, metric='sharpe_ratio')
            logger.info(f"âœ… Found {len(results)} combinations.")
            
            # 2. ë¶„ì„ ë° ë²”ìœ„ ì¶•ì†Œ (ì‹ ê·œ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸)
            refined_grid = optimizer.analyze_top_results(n=10, threshold=0.7)
            
            # 3. 2ë‹¨ê³„ ì •ë°€ ìµœì í™”
            if refined_grid:
                logger.info(f"âœ¨ [Analysis] Refined Grid calculated: {refined_grid}")
                logger.info(f"ğŸš€ [Stage 2] Iterative Scan Starting...")
                refined_results = optimizer.run_optimization(df, refined_grid, metric='sharpe_ratio')
                logger.info(f"ğŸ† Final Best Results: {len(refined_results)}")
                
                for res in refined_results[:5]:
                    logger.info(f" - {res.params}: Sharpe={res.sharpe_ratio:.2f}, WR={res.win_rate:.1f}%")
            else:
                logger.info("âœ¨ [Analysis] No dominant patterns found to refine.")
        else:
            logger.error(f"âŒ No test data found at {csv_path}. Please download data first.")
            
    except Exception:
        logger.info("âŒ Test failed with error:")
        traceback.print_exc()
