# optimizer.py
"""
STAR-U Bot ìµœì í™” ì—”ì§„
- íŒŒë¼ë¯¸í„° ê·¸ë¦¬ë“œ ì„œì¹˜
- ê²°ê³¼ ì •ë ¬ ë° ë­í‚¹
- ìµœì ê°’ ë°˜í™˜
"""
import logging
logger = logging.getLogger(__name__)


import itertools
import pandas as pd
import numpy as np
from typing import Dict, List, Optional, Callable
from dataclasses import dataclass

import sys
import os

# Logging
from utils.logger import get_module_logger
logger = get_module_logger(__name__)

# TF_MAPPING, TF_RESAMPLE_MAP import
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'GUI'))
try:
    from constants import TF_MAPPING, TF_RESAMPLE_MAP, DEFAULT_PARAMS
    from utils.data_utils import resample_data as shared_resample
except ImportError:
    TF_MAPPING = {'1h': '15min', '4h': '1h', '1d': '4h', '1w': '1d'}
    TF_RESAMPLE_MAP = {
        '15min': '15min', '15m': '15min', '30min': '30min', '30m': '30min',
        '1h': '1h', '1H': '1h', '4h': '4h', '4H': '4h', '1d': '1D', '1D': '1D', '1w': '1W', '1W': '1W'
    }
    DEFAULT_PARAMS = {'atr_mult': 1.25, 'slippage': 0.0005, 'fee': 0.00055}
    shared_resample = None  # fallback


# ==================== ìµœì í™” ìƒìˆ˜ ====================

# ë¦¬ìƒ˜í”Œë§ ê°€ëŠ¥í•œ TF
AVAILABLE_TF = ['15m', '30m', '45m', '1h', '2h', '3h', '4h', '6h', '12h', '1d', '1w']

# ì¶”ì„¸ TFë³„ ìë™ íƒìƒ‰ ë²”ìœ„
TF_AUTO_RANGE = {
    '1h': {
        'filter_tf': ['2h', '4h', '6h', '12h', '1d'],
        'entry_tf': ['15m', '30m', '45m']
    },
    '4h': {
        'filter_tf': ['6h', '12h', '1d'],
        'entry_tf': ['15m', '30m', '1h', '2h']
    },
    '1d': {
        'filter_tf': ['1w'],
        'entry_tf': ['1h', '2h', '4h', '6h', '12h']
    },
    '1w': {
        'filter_tf': ['1d'],
        'entry_tf': ['4h', '6h', '12h', '1d']
    }
}

# ë°°ìœ¨ ë²”ìœ„
LEVERAGE_RANGE = [1, 2, 3, 5, 7, 10, 15, 20]

# ë°©í–¥ ë²”ìœ„
DIRECTION_RANGE = ['Both', 'Long', 'Short']

# ì§€í‘œ ë²”ìœ„ ì„¤ì •
INDICATOR_RANGE = {
    'macd_fast': [6, 8, 10, 12],
    'macd_slow': [18, 20, 24, 26, 32],
    'macd_signal': [7, 9, 12],
    'ema_period': [10, 20, 50],
    
    # ê¸°ì¡´ ìœ ì§€ ë° ìµœì í™”
    'atr_mult': [1.0, 1.5, 2.0, 2.2],
    'atr_period': [7, 14, 21],
    'rsi_period': [7, 14, 21],
    'trail_start_r': [0.5, 0.7, 1.0],
    'trail_dist_r': [0.2, 0.35, 0.5],
    'pullback_rsi_long': [35, 40, 45],
    'pullback_rsi_short': [55, 60, 65],
    'pattern_tolerance': [0.03, 0.04, 0.05],
    'entry_validity_hours': [12, 24, 48],
    'max_adds': [0, 1, 2],
}





# ==================== Grid ìƒì„± í•¨ìˆ˜ ====================

def generate_full_grid(trend_tf: str, max_mdd: float = 20.0) -> Dict:
    """
    Standard ëª¨ë“œìš© Grid (~5,000ê°œ)
    """
    tf_range = TF_AUTO_RANGE.get(trend_tf, TF_AUTO_RANGE['1h'])
    
    return {
        'trend_interval': [trend_tf],
        'filter_tf': tf_range['filter_tf'][:3],      # 3ê°œ
        'entry_tf': [tf_range['entry_tf'][0]],       # 1ê°œ
        'leverage': [3, 5],                          # 2ê°œ
        'direction': ['Both', 'Long'],               # 2ê°œ
        'max_mdd': [max_mdd],
        'atr_mult': [1.1, 1.25, 1.5],                # 3ê°œ
        'trail_start_r': [0.7, 1.0, 1.5, 2.5],       # 4ê°œ
        'trail_dist_r': [0.1, 0.2, 0.35],            # 3ê°œ
        'pattern_tolerance': [0.05],                 # 1ê°œ (ê³ ì •)
        'entry_validity_hours': [6.0, 12.0, 24.0],   # 3ê°œ
        'pullback_rsi_long': [35, 40],               # 2ê°œ
        'pullback_rsi_short': [60, 65],              # 2ê°œ
        # Total: 3Ã—1Ã—2Ã—2Ã—3Ã—4Ã—3Ã—1Ã—3Ã—2Ã—2 = 5,184ê°œ
    }



def generate_quick_grid(trend_tf: str, max_mdd: float = 20.0) -> Dict:
    """Quick ëª¨ë“œìš© ìµœì†Œ Grid (~50ê°œ) - í•µì‹¬ íŒŒë¼ë¯¸í„°ë§Œ"""
    tf_range = TF_AUTO_RANGE.get(trend_tf, TF_AUTO_RANGE['1h'])
    
    return {
        'trend_interval': [trend_tf],
        'filter_tf': [tf_range['filter_tf'][0]],     # 1ê°œ (ê³ ì •)
        'entry_tf': [tf_range['entry_tf'][0]],       # 1ê°œ (ê³ ì •)
        'leverage': [1, 3],                          # 2ê°œ
        'direction': ['Both'],                       # 1ê°œ (ê³ ì •)
        'max_mdd': [max_mdd],
        'atr_mult': [1.25, 1.5],                     # 2ê°œ
        'trail_start_r': [0.8, 1.5, 2.5],            # 3ê°œ
        'trail_dist_r': [0.15, 0.25],                # 2ê°œ
        'pattern_tolerance': [0.05],                 # 1ê°œ (ê³ ì •)
        'entry_validity_hours': [6.0, 12.0],         # 2ê°œ
        'pullback_rsi_long': [40],                   # 1ê°œ (ê³ ì •)
        'pullback_rsi_short': [60],                  # 1ê°œ (ê³ ì •)
        # Total: 2Ã—2Ã—3Ã—2Ã—2 = 48ê°œ
    }



def generate_standard_grid(trend_tf: str, max_mdd: float = 20.0) -> Dict:
    """Standard ëª¨ë“œìš© Grid (~5,000ê°œ)"""
    return generate_full_grid(trend_tf, max_mdd)

def generate_deep_grid(trend_tf: str, max_mdd: float = 20.0) -> Dict:
    """Deep ëª¨ë“œìš© ì •ë°€ Grid (~50,000ê°œ)"""
    tf_range = TF_AUTO_RANGE.get(trend_tf, TF_AUTO_RANGE['1h'])
    
    return {
        'trend_interval': [trend_tf],
        'filter_tf': tf_range['filter_tf'][:4],      # 4ê°œ
        'entry_tf': tf_range['entry_tf'][:2],        # 2ê°œ
        'leverage': [1, 3, 5, 10],                   # 4ê°œ
        'direction': ['Both', 'Long', 'Short'],      # 3ê°œ
        'max_mdd': [max_mdd],
        'atr_mult': [1.0, 1.1, 1.25, 1.5, 2.0],      # 5ê°œ
        'trail_start_r': [0.5, 0.8, 1.0, 1.5, 2.0, 3.0],  # 6ê°œ
        'trail_dist_r': [0.1, 0.15, 0.2, 0.3, 0.4],  # 5ê°œ
        'pattern_tolerance': [0.04, 0.05],           # 2ê°œ
        'entry_validity_hours': [6.0, 12.0, 24.0],   # 3ê°œ
        'pullback_rsi_long': [35, 40, 45],           # 3ê°œ
        'pullback_rsi_short': [55, 60, 65],          # 3ê°œ
        # Total: 4Ã—2Ã—4Ã—3Ã—5Ã—6Ã—5Ã—2Ã—3Ã—3Ã—3 = 388,800ê°œ (ì „ìˆ˜ì¡°ì‚¬)
    }



def generate_fast_grid(trend_tf: str, max_mdd: float = 20.0) -> Dict:
    """
    ë¹ ë¥¸ íƒìƒ‰ìš© ì¶•ì†Œ Grid ìƒì„±
    - INDICATOR_RANGEì—ì„œ ì„±ê¸´(Sparse) í˜•íƒœë¡œ ìƒ˜í”Œë§
    
    Args:
        trend_tf: ì¶”ì„¸ íƒ€ì„í”„ë ˆì„
        max_mdd: ìµœëŒ€ í—ˆìš© MDD (%)
    
    Returns:
        ì¶•ì†Œëœ íŒŒë¼ë¯¸í„° grid dict
    """
    tf_range = TF_AUTO_RANGE.get(trend_tf, TF_AUTO_RANGE['1h'])
    
    # INDICATOR_RANGEì—ì„œ ì§•ê²€ë‹¤ë¦¬ì‹ìœ¼ë¡œ ì„ íƒ (ë°ì´í„° ìˆ˜ ëŒ€í­ ê°ì†Œ)
    grid = {
        'trend_interval': [trend_tf],
        'filter_tf': [tf_range['filter_tf'][0]],      # ìµœì  í›„ë³´ 1ê°œ
        'entry_tf': [tf_range['entry_tf'][0]],        # ìµœì  í›„ë³´ 1ê°œ
        'leverage': [3, 10],                          # 2ë‹¨ê³„ ìƒëµ
        'direction': ['Both'],                         # ê¸°ë³¸ ë°©í–¥
        'max_mdd': [max_mdd],
        'atr_mult': [1.25, 1.35, 1.5],                 # [MOD] ë³´ìˆ˜ì  ë²”ìœ„ë¡œ ì œí•œ
        'trail_start_r': INDICATOR_RANGE['trail_start_r'][::3], # [0.5, 0.8, 1.1]
        'trail_dist_r': INDICATOR_RANGE['trail_dist_r'][::3],   # [0.1, 0.25, 0.4]
    }
    
    return grid


def estimate_combinations(param_grid: Dict) -> tuple:
    """
    íŒŒë¼ë¯¸í„° ì¡°í•© ìˆ˜ ë° ì˜ˆìƒ ì‹œê°„ ê³„ì‚°
    
    Args:
        param_grid: íŒŒë¼ë¯¸í„° grid dict
    
    Returns:
        (ì¡°í•©ìˆ˜, ì˜ˆìƒì‹œê°„ë¶„)
    """
    total = 1
    for key, values in param_grid.items():
        if isinstance(values, list):
            total *= len(values)
    
    # ë°±í…ŒìŠ¤íŠ¸ 1íšŒë‹¹ ì•½ 0.05ì´ˆ ê°€ì •
    estimated_seconds = total * 0.05
    estimated_minutes = estimated_seconds / 60
    
    return (total, round(estimated_minutes, 1))


@dataclass
class OptimizationResult:
    """
    ìµœì í™” ê²°ê³¼ ë°ì´í„°
    
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    ğŸ“Š ì§€í‘œë³„ ì˜í–¥ ê´€ê³„ (METRICS IMPACT REFERENCE)
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    [ì…ë ¥ íŒŒë¼ë¯¸í„°] â†’ [ì˜í–¥ ì§€í‘œ]
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    â€¢ atr_mult (ATR ë°°ìˆ˜)
      â†’ max_drawdown: ATRâ†‘ = ë„“ì€ SL = MDDâ†‘
      â†’ win_rate: ATRâ†‘ = ì—¬ìœ ìˆëŠ” SL = ìŠ¹ë¥ â†‘ (ì¡°ê¸° ì²­ì‚° ë°©ì§€)
      â†’ trades: ì˜í–¥ ì ìŒ
    
    â€¢ trail_start_r (íŠ¸ë ˆì¼ë§ ì‹œì‘ Rë°°ìˆ˜)
      â†’ simple_return/compound_return: ì‹œì‘â†‘ = ë” ë§ì´ ìˆ˜ìµ í™•ë³´ í›„ íŠ¸ë ˆì¼ë§
      â†’ win_rate: ì‹œì‘â†‘ = ìµì ˆ í™•ë¥ â†‘
      â†’ max_drawdown: ê°„ì ‘ ì˜í–¥
    
    â€¢ trail_dist_r (íŠ¸ë ˆì¼ë§ ê±°ë¦¬ Rë°°ìˆ˜)
      â†’ max_drawdown: ê±°ë¦¬â†‘ = ì²­ì‚° ëŠ¦ìŒ = MDDâ†‘
      â†’ simple_return: ê±°ë¦¬â†‘ = ìˆ˜ìµ ë” ì¶”êµ¬ = ìˆ˜ìµâ†‘ or ë°˜ë‚©
    
    â€¢ leverage (ë ˆë²„ë¦¬ì§€)
      â†’ simple_return/compound_return: ë ˆë²„ë¦¬ì§€â†‘ = ìˆ˜ìµë¥ â†‘ (ë¹„ë¡€)
      â†’ max_drawdown: ë ˆë²„ë¦¬ì§€â†‘ = MDDâ†‘ (ë¹„ë¡€)
      â†’ sharpe_ratio: ë³€ë™ì„±â†‘ = ìƒ¤í”„â†“
    
    â€¢ direction (ë°©í–¥: Long/Short/Both)
      â†’ trades: Both = ê±°ë˜â†‘â†‘
      â†’ win_rate: ì‹œì¥ ìƒí™©ì— ë”°ë¼ ë³€ë™
    
    â€¢ filter_tf (í•„í„° íƒ€ì„í”„ë ˆì„)
      â†’ win_rate: ìƒìœ„TF í•„í„° = ì‹ í˜¸ í’ˆì§ˆâ†‘ = ìŠ¹ë¥ â†‘
      â†’ trades: ì—„ê²©í•œ í•„í„° = ê±°ë˜â†“
    
    â€¢ entry_tf (ì§„ì… íƒ€ì„í”„ë ˆì„)
      â†’ trades: ì‘ì€TF = ê¸°íšŒâ†‘ = ê±°ë˜â†‘
      â†’ win_rate: íƒ€ì´ë° ì •í™•ë„ì— ì˜í–¥
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    
    [ì§€í‘œ ê³„ì‚° ìœ„ì¹˜]
    â€¢ win_rate: _calculate_metrics() â†’ (ìˆ˜ìµê±°ë˜/ì „ì²´ê±°ë˜) Ã— 100
    â€¢ max_drawdown: _calculate_metrics() â†’ ìµœê³ ì  ëŒ€ë¹„ ìµœëŒ€ í•˜ë½í­
    â€¢ sharpe_ratio: _calculate_metrics() â†’ (í‰ê· ìˆ˜ìµ/í‘œì¤€í¸ì°¨) Ã— âˆš252
    â€¢ simple_return: _calculate_metrics() â†’ Î£(ê° ê±°ë˜ ìˆ˜ìµë¥ )
    â€¢ compound_return: _calculate_metrics() â†’ Î (1+ìˆ˜ìµë¥ ) - 1
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """
    params: Dict                          # ì‚¬ìš©ëœ íŒŒë¼ë¯¸í„°
    trades: int                           # ë§¤ë§¤ íšŸìˆ˜ â†’ direction, filter_tf, entry_tf ì˜í–¥
    win_rate: float                       # ìŠ¹ë¥ (%) â†’ atr_mult, filter_tf ì˜í–¥
    total_return: float                   # [DEPRECATED] simple_return ë˜ëŠ” compound_return ì‚¬ìš©
    simple_return: float = 0.0            # ë‹¨ë¦¬ ìˆ˜ìµë¥  â†’ leverage, trail_* ì˜í–¥
    compound_return: float = 0.0          # ë³µë¦¬ ìˆ˜ìµë¥  â†’ leverage, trail_* ì˜í–¥
    max_drawdown: float = 0.0             # MDD(%) â†’ atr_mult, leverage, trail_dist_r ì˜í–¥
    sharpe_ratio: float = 0.0             # ìƒ¤í”„ë¹„ìœ¨ â†’ leverage ì˜í–¥ (ë³€ë™ì„±)
    profit_factor: float = 0.0            # ìˆ˜ìµíŒ©í„° â†’ ì „ì²´ì  íŒŒë¼ë¯¸í„° ì˜í–¥
    avg_trades_per_day: float = 0.0       # ì¼í‰ê·  ê±°ë˜ìˆ˜
    stability: str = "âš ï¸"                 # 3êµ¬ê°„ ì•ˆì •ì„± ì§€í‘œ
    strategy_type: str = ""               # ì „ëµ ìœ í˜• (ğŸ”¥ê³µê²©, âš–ê· í˜•, ğŸ›¡ë³´ìˆ˜)
    grade: str = ""                       # ë“±ê¸‰ (S/A/B/C)
    capital_mode: str = "compound"        # ìë³¸ ëª¨ë“œ


def calculate_grade(win_rate: float, profit_factor: float, max_drawdown: float) -> str:
    """ë“±ê¸‰ ê³„ì‚° (S/A/B/C)
    
    Së“±ê¸‰: ìŠ¹ë¥  80%+ AND PF 3.0+ AND MDD â‰¤10%
    Aë“±ê¸‰: ìŠ¹ë¥  70%+ AND PF 2.0+ AND MDD â‰¤15%
    Bë“±ê¸‰: ìŠ¹ë¥  60%+ AND PF 1.5+ AND MDD â‰¤20%
    Cë“±ê¸‰: ë‚˜ë¨¸ì§€
    """
    mdd = abs(max_drawdown)
    
    if win_rate >= 80 and profit_factor >= 3.0 and mdd <= 10:
        return "ğŸ†S"
    elif win_rate >= 70 and profit_factor >= 2.0 and mdd <= 15:
        return "ğŸ¥‡A"
    elif win_rate >= 60 and profit_factor >= 1.5 and mdd <= 20:
        return "ğŸ¥ˆB"
    else:
        return "ğŸ¥‰C"


def _worker_run_single(strategy_class, params, df_pattern, df_entry, slippage, fee):
    """ë©€í‹°í”„ë¡œì„¸ì‹± ì§€ì›ì„ ìœ„í•œ ë…ë¦½í˜• ì›Œì»¤ í•¨ìˆ˜"""
    try:
        # ë°©í–¥ ì²˜ë¦¬
        leverage = params.get('leverage', 3)
        if isinstance(leverage, list): leverage = leverage[0]
        leverage = int(leverage)
        
        direction = params.get('direction', 'Both')
        if isinstance(direction, list): direction = direction[0]
        
        filter_tf = params.get('filter_tf', '4h')
        if isinstance(filter_tf, list): filter_tf = filter_tf[0]
        
        # ì „ëµ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
        strategy = strategy_class()
        
        # ì´ ë¹„ìš©
        total_cost = slippage + fee
        
        # ë°±í…ŒìŠ¤íŠ¸ ì‹¤í–‰ (íŒŒë¼ë¯¸í„°í™” ì™„ë£Œ)
        trades = strategy.run_backtest(
            df_pattern=df_pattern,
            df_entry=df_entry,
            slippage=total_cost,
            atr_mult=params.get('atr_mult', DEFAULT_PARAMS.get('atr_mult', 1.5)),
            trail_start_r=params.get('trail_start_r', DEFAULT_PARAMS.get('trail_start_r', 0.8)),
            trail_dist_r=params.get('trail_dist_r', DEFAULT_PARAMS.get('trail_dist_r', 0.5)),
            pattern_tolerance=params.get('pattern_tolerance', DEFAULT_PARAMS.get('pattern_tolerance', 0.03)),
            entry_validity_hours=params.get('entry_validity_hours', DEFAULT_PARAMS.get('entry_validity_hours', 12.0)),
            pullback_rsi_long=params.get('pullback_rsi_long', DEFAULT_PARAMS.get('pullback_rsi_long', 35)),
            pullback_rsi_short=params.get('pullback_rsi_short', DEFAULT_PARAMS.get('pullback_rsi_short', 65)),
            max_adds=params.get('max_adds', DEFAULT_PARAMS.get('max_adds', 1)),
            filter_tf=filter_tf,
            rsi_period=params.get('rsi_period', DEFAULT_PARAMS.get('rsi_period', 14)),
            atr_period=params.get('atr_period', DEFAULT_PARAMS.get('atr_period', 14)),
            macd_fast=params.get('macd_fast', DEFAULT_PARAMS.get('macd_fast', 12)),
            macd_slow=params.get('macd_slow', DEFAULT_PARAMS.get('macd_slow', 26)),
            macd_signal=params.get('macd_signal', DEFAULT_PARAMS.get('macd_signal', 9)),
            ema_period=params.get('ema_period', DEFAULT_PARAMS.get('ema_period', 20)),
            enable_pullback=params.get('enable_pullback', False)
        )

        
        if not trades:
            return None
            
        min_trades = params.get('min_trades', 1)
        if len(trades) < min_trades:
            return None
            
        # ë°©í–¥ í•„í„°ë§
        if direction != 'Both':
            trades = [t for t in trades if t['type'] == direction]
            if len(trades) < min_trades: return None
            
        # ë ˆë²„ë¦¬ì§€ ì ìš©
        for t in trades:
            t['pnl'] = t['pnl'] * leverage
            
        # ë©”íŠ¸ë¦­ ê³„ì‚° (ê³µìš© ì •ì  ë©”ì„œë“œ í˜¸ì¶œ)
        metrics = BacktestOptimizer.calculate_metrics(trades)
        
        # MDD í•„í„°
        max_mdd_limit = params.get('max_mdd', 100.0)
        if max_mdd_limit < 100.0 and abs(metrics['max_drawdown']) > max_mdd_limit:
            return None
            
        return OptimizationResult(
            params=params,
            trades=len(trades),
            win_rate=metrics['win_rate'],
            total_return=metrics['total_return'],
            simple_return=metrics['simple_return'],
            compound_return=metrics['compound_return'],
            max_drawdown=metrics['max_drawdown'],
            sharpe_ratio=metrics['sharpe_ratio'],
            profit_factor=metrics['profit_factor'],
            avg_trades_per_day=metrics.get('avg_trades_per_day', 0.0),
            stability=metrics.get('stability', "âš ï¸"),
            grade=calculate_grade(metrics['win_rate'], metrics['profit_factor'], metrics['max_drawdown'])
        )
    except Exception:
        return None



    # _calculate_metrics_standalone removed and unified inside BacktestOptimizer



class BacktestOptimizer:
    """íŒŒë¼ë¯¸í„° ê·¸ë¦¬ë“œ ì„œì¹˜ ìµœì í™”"""
    
    # TF ë§¤í•‘ì€ ìƒë‹¨ì—ì„œ importí•œ TF_MAPPING ì‚¬ìš©
    
    def __init__(self, strategy_class, df: pd.DataFrame = None):
        """
        Args:
            strategy_class: X7PlusStrategy ë“± ì „ëµ í´ë˜ìŠ¤
            df: ë°±í…ŒìŠ¤íŠ¸ìš© ë°ì´í„°í”„ë ˆì„
        """
        self.strategy_class = strategy_class
        self.df = df
        self.results: List[OptimizationResult] = []
        self.progress_callback: Optional[Callable] = None
        self.cancelled = False
    
    def set_data(self, df: pd.DataFrame) -> None:
        """ë°ì´í„° ì„¤ì •"""
        self.df = df
    
    def set_progress_callback(self, callback: Callable) -> None:
        """ì§„í–‰ë¥  ì½œë°± ì„¤ì •"""
        self.progress_callback = callback
    
    def cancel(self) -> None:
        """ìµœì í™” ì·¨ì†Œ"""
        self.cancelled = True
        
    def _resample(self, df: pd.DataFrame, target_tf: str, quiet: bool = False) -> pd.DataFrame:
        """15m â†’ Target TF ë¦¬ìƒ˜í”Œë§ (ê³µìš© í•¨ìˆ˜ ì‚¬ìš©)"""
        # ê³µìš© utils.data_utils.resample_data ì‚¬ìš©
        if shared_resample:
            return shared_resample(df, target_tf, add_indicators=True)
        
        # Fallback: ë¡œì»¬ êµ¬í˜„
        rule = TF_RESAMPLE_MAP.get(target_tf, target_tf)
        df = df.copy()
        if 'datetime' not in df.columns:
            if pd.api.types.is_numeric_dtype(df['timestamp']):
                df['datetime'] = pd.to_datetime(df['timestamp'], unit='ms')
            else:
                df['datetime'] = pd.to_datetime(df['timestamp'])
        df = df.set_index('datetime')
        resampled = df.resample(rule).agg({
            'timestamp': 'first', 'open': 'first', 'high': 'max',
            'low': 'min', 'close': 'last', 'volume': 'sum'
        }).dropna().reset_index()
        try:
            from utils.indicators import IndicatorGenerator
            resampled = IndicatorGenerator.add_all_indicators(resampled)
            if 'rsi' not in resampled.columns and 'rsi_14' in resampled.columns:
                resampled['rsi'] = resampled['rsi_14']
            if 'atr' not in resampled.columns and 'atr_14' in resampled.columns:
                resampled['atr'] = resampled['atr_14']
        except Exception as e:
            if not quiet: logger.info(f"âš ï¸ ì§€í‘œ ì¬ê³„ì‚° ì‹¤íŒ¨: {e}")
        if not quiet: logger.info(f"ğŸ“Š [OPT] ì§€í‘œ ì¬ê³„ì‚°: {target_tf} ({len(resampled)}ìº”ë“¤)")
        return resampled
    
    def run_optimization(self, df: pd.DataFrame, grid: Dict, max_workers: int = 4, 
                         metric: str = 'WinRate', task_callback: Callable = None, 
                         capital_mode: str = 'compound') -> List[OptimizationResult]:
        """ê·¸ë¦¬ë“œ ì„œì¹˜ ìµœì í™” ì‹¤í–‰"""
        self.df = df
        self.results = []
        self.cancelled = False
        self.capital_mode = capital_mode.lower()
        if self.df is None or self.df.empty:
            raise ValueError("ë°ì´í„°ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
        
        # [FIX] df íƒ€ì„ìŠ¤íƒ¬í”„ ë³€í™˜ (í•œ ë²ˆë§Œ ìˆ˜í–‰)
        df = self.df.copy()
        if not pd.api.types.is_datetime64_any_dtype(df['timestamp']):
            first_ts = df['timestamp'].iloc[0]
            if isinstance(first_ts, (int, float, np.number)) and first_ts > 100000000000:
                df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')
            else:
                df['timestamp'] = pd.to_datetime(df['timestamp'])
        self.df = df

        self.cancelled = False
        self.results = []
        
        # ë¦¬ìƒ˜í”Œë§ ìºì‹œ ì´ˆê¸°í™”
        self._resample_cache = {}
        
        # ëª¨ë“  íŒŒë¼ë¯¸í„° ì¡°í•© ìƒì„±
        keys = list(param_grid.keys())
        values = list(param_grid.values())
        combinations = list(itertools.product(*values))
        total = len(combinations)
        
        # [NEW] n_cores ì²˜ë¦¬
        if n_cores is None:
            import multiprocessing
            n_cores = multiprocessing.cpu_count()
        
        # [NEW] ì§€í‘œ ì„ í–‰ ê³„ì‚° (ThreadPool ê²½í•© ë°©ì§€)
        all_trend_tfs = set(param_grid.get('trend_interval', []))
        all_entry_tfs = set(param_grid.get('entry_tf', []))
        
        for tf in all_trend_tfs:
            key = f"p_{tf}"
            if key not in self._resample_cache:
                self._resample_cache[key] = self._resample(df, tf)
                
        for tf in all_entry_tfs:
            key = f"e_{tf}"
            if key not in self._resample_cache:
                if tf and tf not in ['15min', '15m']:
                    self._resample_cache[key] = self._resample(df, tf)
                else:
                    self._resample_cache[key] = df.copy()
        
        logger.info(f"ğŸ”¬ ìµœì í™” ì‹œì‘: {total}ê°œ ì¡°í•©, {n_cores}ì½”ì–´ (ProcessPool) ì‚¬ìš©")
        
        # ë³‘ë ¬ ì²˜ë¦¬ (ProcessPoolExecutor)
        from concurrent.futures import ProcessPoolExecutor, as_completed
        
        with ProcessPoolExecutor(max_workers=n_cores) as executor:
            # TFë³„ ë¯¸ë¦¬ ë¦¬ìƒ˜í”Œë§ëœ DFë“¤ì„ ë§µìœ¼ë¡œ ì¤€ë¹„
            # (ë©€í‹°í”„ë¡œì„¸ì‹± ì‹œ íŒŒë¼ë¯¸í„°ë¡œ ë§¤ë²ˆ DFë¥¼ í†µì§¸ë¡œ ì „ë‹¬í•˜ë©´ ì˜¤ë²„í—¤ë“œê°€ í¬ì§€ë§Œ, 
            #  ì—¬ê¸°ì„œëŠ” pickleë¡œ ì „ë‹¬ë¨)
            
            futures = []
            for combo in combinations:
                params = dict(zip(keys, combo))
                
                # í•´ë‹¹ ì¡°í•©ì— ë§ëŠ” cached df ì¶”ì¶œ
                trend_tf = params.get('trend_interval', '4h')
                if isinstance(trend_tf, list): trend_tf = trend_tf[0]
                entry_tf = params.get('entry_tf')
                if isinstance(entry_tf, list): entry_tf = entry_tf[0]
                if not entry_tf:
                    try:
                        from GUI.constants import TF_MAPPING
                    except ImportError:
                        # Fallback if GUI package not found or structure differs
                        TF_MAPPING = {'1h': '15m', '4h': '1h', '1d': '4h'}
                    entry_tf = TF_MAPPING.get(trend_tf, '15min')
                
                df_pattern = self._resample_cache.get(f"p_{trend_tf}")
                df_entry = self._resample_cache.get(f"e_{entry_tf}")
                
                # Backtest ì‹¤í–‰
                # [NEW] MultiSymbolBacktestë¥¼ ì‚¬ìš©í•˜ì—¬ ì •ë°€ í…ŒìŠ¤íŠ¸
                from core.multi_symbol_backtest import MultiSymbolBacktest
                msb = MultiSymbolBacktest(
                    exchange=params.get('exchange', 'bybit'),
                    symbols=[symbol],
                    initial_capital=1000.0,
                    leverage=leverage,
                    preset_params=params,
                    capital_mode=self.capital_mode # [NEW]
                )
                
                futures.append(executor.submit(
                    _worker_run_single,
                    self.strategy_class,
                    params,
                    df_pattern,
                    df_entry,
                    slippage,
                    fee
                ))
            
            for i, future in enumerate(as_completed(futures)):
                if self.cancelled:
                    logger.info("âŒ ìµœì í™” ì·¨ì†Œë¨")
                    executor.shutdown(wait=False, cancel_futures=True)
                    break
                
                try:
                    result = future.result()
                    if result:
                        # === í•„í„°ë§ ì¡°ê±´ ===
                        # 1. MDD â‰¤ 25% (ë ˆë²„ë¦¬ì§€ ì ìš© ì „ ê¸°ì¤€)
                        # 2. PF â‰¥ 1.0 (ìˆ˜ìµ > ì†ì‹¤)
                        # 3. ìµœì†Œ ê±°ë˜ìˆ˜ â‰¥ 10
                        passes_filter = (
                            abs(result.max_drawdown) <= 25.0 and
                            result.profit_factor >= 1.0 and
                            result.trades >= 10
                        )
                        
                        if passes_filter:
                            self.results.append(result)
                            if task_callback:
                                task_callback(result)
                except Exception as e:
                    # í”„ë¡œì„¸ìŠ¤ ì˜¤ë¥˜ ë¡œê·¸
                    pass
                
                # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
                if self.progress_callback:
                    progress = int((i + 1) / total * 100)
                    self.progress_callback(progress)
        
        # ê²°ê³¼ ì •ë ¬ ë° ìƒì„¸ ë¶„ë¥˜ (v2)
        if self.results:
            # 1. ì§€ì •ëœ ë©”íŠ¸ë¦­ìœ¼ë¡œ ì „ì²´ ì •ë ¬
            self.results.sort(key=lambda x: getattr(x, metric, 0), reverse=True)
            
            # 2. [NEW] ëŒ€í‘œ ìœ í˜• ë§¤ì¹­ (ì›ë³¸ ë¦¬ìŠ¤íŠ¸ëŠ” ìœ ì§€í•˜ê³  íƒœê¹…ë§Œ ìˆ˜í–‰)
            # ìƒìœ„ 1000ê°œ ê²°ê³¼ ì¤‘ ì¤‘ë³µ ì—†ëŠ” ëŒ€í‘œ ìœ í˜•ë“¤ ì„ ì •
            top_results = self.results[:1000]
            unique_for_classification = self.filter_unique_results(top_results, max_count=100)
            representatives = self._classify_results(unique_for_classification)
            
            # ëŒ€í‘œ ìœ í˜•ë“¤ì„ self.results ìƒë‹¨ì— ë°°ì¹˜í•˜ê³  ë‚˜ë¨¸ì§€ëŠ” ìˆœì„œ ìœ ì§€
            rep_keys = [str(r.params) for r in representatives]
            final_list = representatives + [r for r in self.results if str(r.params) not in rep_keys]
            
            self.results = final_list[:2000] # ë©”ëª¨ë¦¬ ê´€ë¦¬ë¥¼ ìœ„í•´ ìƒìœ„ 2000ê°œë¡œ ì œí•œ


        # ë¦¬ìƒ˜í”Œë§ ìºì‹œ ì •ë¦¬ (ë©”ëª¨ë¦¬ í•´ì œ)
        self._resample_cache = {}
        
        logger.info(f"âœ… ìµœì í™” ì™„ë£Œ: {len(self.results)}ê°œ ëŒ€í‘œ ê²°ê³¼ ë„ì¶œ")
        return self.results
    
    def _run_single(self, params: Dict, slippage: float, fee: float = 0.00055) -> Optional[OptimizationResult]:
        """ë‹¨ì¼ íŒŒë¼ë¯¸í„° ì¡°í•©ìœ¼ë¡œ ë°±í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        try:
            # íŒŒë¼ë¯¸í„° ì¶”ì¶œ (ë¦¬ìŠ¤íŠ¸ì¼ ê²½ìš° ë‹¨ì¼ ê°’ìœ¼ë¡œ ë³€í™˜)
            filter_tf = params.get('filter_tf', '4h')
            if isinstance(filter_tf, list): filter_tf = filter_tf[0]
            
            trend_tf = params.get('trend_interval', '1h')
            if isinstance(trend_tf, list): trend_tf = trend_tf[0]
            
            # Entry TF: paramsì— ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ TF_MAPPING
            entry_tf = params.get('entry_tf')
            if isinstance(entry_tf, list): entry_tf = entry_tf[0]
            if not entry_tf:
                entry_tf = TF_MAPPING.get(trend_tf, '15min')
            
            # [NEW] ë¦¬ìƒ˜í”Œë§ ìºì‹œ ì‚¬ìš© (ì„±ëŠ¥ ëŒ€í­ í–¥ìƒ)
            if not hasattr(self, '_resample_cache'): self._resample_cache = {}
            
            # df_pattern ìºì‹œ í‚¤
            p_key = f"p_{trend_tf}"
            if p_key not in self._resample_cache:
                self._resample_cache[p_key] = self._resample(self.df, trend_tf)
            df_pattern = self._resample_cache[p_key]
            
            # df_entry ìºì‹œ í‚¤
            e_key = f"e_{entry_tf}"
            if e_key not in self._resample_cache:
                if entry_tf and entry_tf not in ['15min', '15m']:
                    self._resample_cache[e_key] = self._resample(self.df, entry_tf)
                else:
                    self._resample_cache[e_key] = self.df.copy()
            df_entry = self._resample_cache[e_key]
            
            # ë°°ìœ¨/ë°©í–¥ ì²˜ë¦¬
            leverage = params.get('leverage', 3)
            if isinstance(leverage, list): leverage = leverage[0]
            leverage = int(leverage)
            
            direction = params.get('direction', 'Both')
            if isinstance(direction, list): direction = direction[0]
            
            # ì „ëµ ìƒì„± ì‹œ íŒŒë¼ë¯¸í„° ì „ë‹¬
            init_params = {}
            if 'trend_interval' in params:
               init_params['trend_interval'] = params['trend_interval']
            
            # ê³„ì‚°ëœ entry_intervalë„ ì „ë‹¬ (ì „ëµ ë‚´ë¶€ ë¦¬ìƒ˜í”Œë§ìš©)
            init_params['entry_interval'] = entry_tf
            
            # ì „ëµ ì¸ìŠ¤í„´ìŠ¤ ìƒì„± (Core)
            # strategy_classëŠ” AlphaX7Coreë¼ê³  ê°€ì • (ë˜ëŠ” í˜¸í™˜)
            # AlphaX7CoreëŠ” initì— dfë¥¼ ë°›ì§€ ì•ŠìŒ. stateless.
            try:
                strategy = self.strategy_class()
                # paramsì— 'rsi_period'ê°€ ìˆìœ¼ë©´ ì „ë‹¬í•´ì•¼ í•¨
            except Exception:
                # ë ˆê±°ì‹œ í˜¸í™˜ (í˜¹ì‹œ ë‹¤ë¥¸ ì „ëµì„ ì“¸ ê²½ìš°)
                strategy = self.strategy_class(df=df, **init_params)
                if hasattr(strategy, 'prepare_data'):
                    strategy.prepare_data()
            
            # âœ… ì´ ë¹„ìš© ê³„ì‚° (ìŠ¬ë¦¬í”¼ì§€ + ìˆ˜ìˆ˜ë£Œ)
            # AlphaX7CoreëŠ” 'slippage' ì¸ìë¥¼ ì°¨ê°í•  ë•Œ 2ë°°ë¥¼ ì ìš©í•˜ë¯€ë¡œ (pnl - slippage*2)
            # ì™•ë³µ ìˆ˜ìˆ˜ë£Œì™€ ìŠ¬ë¦¬í”¼ì§€ë¥¼ í•©ì‚°í•˜ì—¬ ì „ë‹¬í•˜ë©´ ë¨.
            # ì˜ˆ: ìŠ¬ë¦¬í”¼ì§€ 0.05%, ìˆ˜ìˆ˜ë£Œ 0.05% -> í•© 0.1% -> ë¡œì§ìƒ 2ë°°ì¸ 0.2%(ì™•ë³µ) ë¹„ìš© ì²˜ë¦¬
            total_cost = slippage + fee
            
            # ê¸°ë³¸ íŒŒë¼ë¯¸í„°ì™€ ë³‘í•© (DEFAULT_PARAMS ì°¸ì¡°)
            backtest_params = {
                'slippage': total_cost,  # ì´ ë¹„ìš© ì ìš©
                'atr_mult': params.get('atr_mult', DEFAULT_PARAMS.get('atr_mult', 1.5)),
                'trail_start_r': params.get('trail_start_r', DEFAULT_PARAMS.get('trail_start_r', 0.8)),
                'trail_dist_r': params.get('trail_dist_r', DEFAULT_PARAMS.get('trail_dist_r', 0.5)),
                'pattern_tolerance': params.get('pattern_tolerance', DEFAULT_PARAMS.get('pattern_tolerance', 0.03)),
                'entry_validity_hours': params.get('entry_validity_hours', DEFAULT_PARAMS.get('entry_validity_hours', 12.0)),
                'pullback_rsi_long': params.get('pullback_rsi_long', DEFAULT_PARAMS.get('pullback_rsi_long', 35)),
                'pullback_rsi_short': params.get('pullback_rsi_short', DEFAULT_PARAMS.get('pullback_rsi_short', 65)),
                'max_adds': params.get('max_adds', DEFAULT_PARAMS.get('max_adds', 1))
            }
            
            # ğŸ“Š ë””ë²„ê¹… ë¡œê·¸
            if params.get('trend_interval') == '1d' and params.get('atr_mult') == 1.5:
                logger.info(f"ğŸ“Š [OPT] slippage={total_cost:.4f}, atr_mult={backtest_params['atr_mult']}, trail_start_r={backtest_params['trail_start_r']}, trail_dist_r={backtest_params['trail_dist_r']}")
            
            # ì „ëµ ì‹¤í–‰ ì‹œ ì „ë‹¬í•  íŒŒë¼ë¯¸í„°
            # X7PlusStrategy.run_backtest_plusì— filter_tf ì „ë‹¬
            backtest_params['filter_tf'] = filter_tf
            
            # ë°±í…ŒìŠ¤íŠ¸ ì‹¤í–‰ (Core Interface)
            if hasattr(strategy, 'run_backtest') and not hasattr(strategy, 'run_backtest_plus'):
                # AlphaX7Core
                trades = strategy.run_backtest(
                    df_pattern=df_pattern,
                    df_entry=df_entry,  # [FIX] ì›ë³¸ 15min ë°ì´í„° ì‚¬ìš©
                    slippage=total_cost,  # [FIX] ì´ ë¹„ìš© ì „ë‹¬
                    atr_mult=backtest_params.get('atr_mult'),
                    trail_start_r=backtest_params.get('trail_start_r'),
                    trail_dist_r=backtest_params.get('trail_dist_r'),
                    pattern_tolerance=backtest_params.get('pattern_tolerance'),
                    entry_validity_hours=backtest_params.get('entry_validity_hours'),
                    pullback_rsi_long=backtest_params.get('pullback_rsi_long'),
                    pullback_rsi_short=backtest_params.get('pullback_rsi_short'),
                    max_adds=backtest_params.get('max_adds'),
                    filter_tf=filter_tf,
                    rsi_period=params.get('rsi_period', DEFAULT_PARAMS.get('rsi_period', 14)),
                    atr_period=params.get('atr_period', DEFAULT_PARAMS.get('atr_period', 14)),
                    macd_fast=params.get('macd_fast', DEFAULT_PARAMS.get('macd_fast', 12)),
                    macd_slow=params.get('macd_slow', DEFAULT_PARAMS.get('macd_slow', 26)),
                    macd_signal=params.get('macd_signal', DEFAULT_PARAMS.get('macd_signal', 9)),
                    ema_period=params.get('ema_period', DEFAULT_PARAMS.get('ema_period', 20)),
                    enable_pullback=params.get('enable_pullback', False)  # [NEW] ë¶ˆíƒ€ê¸° ì˜µì…˜
                )

            else:
                # Legacy Strategy
                backtest_params['filter_tf'] = filter_tf
                trades = strategy.run_backtest_plus(**backtest_params)
            
            # [DEBUG] ê±°ë˜ ìˆ˜ í™•ì¸
            # logger.info(f"[DEBUG-OPT] ê±°ë˜ ìˆ˜: {len(trades) if trades else 0}ê°œ")
            
            # [FIX] 10ê°œëŠ” ë„ˆë¬´ ê°€í˜¹í•¨ (ìµœì†Œ ê±°ë˜ìˆ˜ íŒŒë¼ë¯¸í„°í™”)
            min_trades = params.get('min_trades', 3)
            if not trades or len(trades) < min_trades:
                return None
            
            # 1. ë°©í–¥ í•„í„°ë§
            if direction != 'Both':
                trades = [t for t in trades if t['type'] == direction]
                if len(trades) < 3: return None
            
            # [FIX] Option 2: ë ˆë²„ë¦¬ì§€ ìë™ ìµœì í™” (MDD íƒ€ê²Ÿ ë§ì¶¤)
            # 2. ë ˆë²„ë¦¬ì§€ ì ìš© (ê·¸ë¦¬ë“œì— ì„¤ì •ëœ ì •ìˆ˜ ë°°ìœ¨ ì‚¬ìš©)
            max_mdd_limit = params.get('max_mdd', 20.0)
            if isinstance(max_mdd_limit, list): max_mdd_limit = max_mdd_limit[0]
            
            # ê·¸ë¦¬ë“œì—ì„œ ë„˜ì–´ì˜¨ ë ˆë²„ë¦¬ì§€ (í•­ìƒ ì •ìˆ˜ì—¬ì•¼ í•¨)
            grid_leverage = int(leverage)
            
            # ë ˆë²„ë¦¬ì§€ ì ìš© (PnL ìˆ˜ì •)
            for t in trades:
                t['pnl'] = t['pnl'] * grid_leverage
            
            # ë©”íŠ¸ë¦­ ê³„ì‚° (ë ˆë²„ë¦¬ì§€ ë°˜ì˜ë¨)
            metrics = self._calculate_metrics(trades)
            
            # [FIX] ë ˆë²„ë¦¬ì§€ ì ìš© í›„ MDDê°€ í•œë„ë¥¼ ì´ˆê³¼í•˜ë©´ íƒˆë½ (max_mddê°€ 100ì´ë©´ ì‚¬ì‹¤ìƒ ë¬´ì‹œ)
            if max_mdd_limit < 100.0 and abs(metrics['max_drawdown']) > max_mdd_limit:
                return None
            
            return OptimizationResult(
                params=params,
                trades=len(trades),
                win_rate=metrics['win_rate'],
                total_return=metrics['total_return'],
                simple_return=metrics['simple_return'],
                compound_return=metrics['compound_return'],
                max_drawdown=metrics['max_drawdown'],
                sharpe_ratio=metrics['sharpe_ratio'],
                profit_factor=metrics['profit_factor'],
                avg_trades_per_day=metrics.get('avg_trades_per_day', 0.0),
                stability=metrics.get('stability', "âš ï¸"),
                grade=calculate_grade(metrics['win_rate'], metrics['profit_factor'], metrics['max_drawdown'])
            )
            
        except Exception as e:
            logger.warning(f"  âš ï¸ ë°±í…ŒìŠ¤íŠ¸ ì˜¤ë¥˜: {e}")
            return None
    
    @staticmethod
    def calculate_metrics(trades: List[Dict]) -> Dict:
        """
        ê±°ë˜ ê²°ê³¼ì—ì„œ ë©”íŠ¸ë¦­ ê³„ì‚° (í†µí•© ì •ì  ë©”ì„œë“œ)
        
        â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        ğŸ“Š ì§€í‘œ ê³„ì‚° ê³µì‹ (METRICS CALCULATION FORMULAS)
        â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        
        1. win_rate (ìŠ¹ë¥ )
           ê³µì‹: (ìˆ˜ìµ ê±°ë˜ ìˆ˜ / ì „ì²´ ê±°ë˜ ìˆ˜) Ã— 100
           ì˜í–¥: filter_tfâ†‘ â†’ ìŠ¹ë¥ â†‘, atr_multâ†‘ â†’ ìŠ¹ë¥ â†‘
        
        2. simple_return (ë‹¨ë¦¬ ìˆ˜ìµë¥ )
           ê³µì‹: Î£(ê° ê±°ë˜ì˜ PnL%)
           ì˜í–¥: leverageâ†‘ â†’ ìˆ˜ìµâ†‘, trail_start_râ†‘ â†’ ìˆ˜ìµâ†‘
        
        3. compound_return (ë³µë¦¬ ìˆ˜ìµë¥ )
           ê³µì‹: (Î (1 + PnL%/100) - 1) Ã— 100
           ì˜í–¥: leverageâ†‘ â†’ ìˆ˜ìµâ†‘â†‘ (ë³µë¦¬ íš¨ê³¼)
        
        4. max_drawdown (MDD, ìµœëŒ€ ë‚™í­)
           ê³µì‹: max((peak - current) / peak Ã— 100)
           ì˜í–¥: leverageâ†‘ â†’ MDDâ†‘, atr_multâ†‘ â†’ MDDâ†‘
        
        5. sharpe_ratio (ìƒ¤í”„ ë¹„ìœ¨)
           ê³µì‹: (í‰ê·  ìˆ˜ìµ / í‘œì¤€í¸ì°¨) Ã— âˆš(252 Ã— 4)
           ì˜í–¥: leverageâ†‘ â†’ ë³€ë™ì„±â†‘ â†’ ìƒ¤í”„â†“
        
        6. profit_factor (ìˆ˜ìµ íŒ©í„°)
           ê³µì‹: ì´ ìˆ˜ìµ / ì´ ì†ì‹¤
           ì˜í–¥: ì „ì²´ íŒŒë¼ë¯¸í„°ì˜ ë³µí•© íš¨ê³¼
        â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        """
        if not trades:
            return {k: 0 for k in ['win_rate', 'total_return', 'simple_return', 'compound_return', 'max_drawdown', 'sharpe_ratio', 'profit_factor']}
            
        pnls = [t.get('pnl', 0) for t in trades]
        pnl_series = pd.Series(pnls)
        
        # ê¸°ë³¸ ë©”íŠ¸ë¦­
        win_rate = (pnl_series > 0).mean() * 100
        simple_return = pnl_series.sum()
        
        # 1. ëˆ„ì  ìˆ˜ìµë¥  (Compound/Equity) ê³„ì‚°
        equity = 1.0
        cumulative_equity = [1.0]
        for p in pnls:
            equity *= (1 + p / 100)
            if equity <= 0: equity = 0
            cumulative_equity.append(equity)
            if equity == 0: break
        
        compound_return = (equity - 1) * 100
        compound_return = max(-100.0, compound_return)  # ë²”ìœ„ ì œí•œ: -100% ìµœì†Œ
        
        # 2. ìµœëŒ€ ë‚™í­ (MDD %) ê³„ì‚°
        peak = 1.0
        max_drawdown = 0
        for val in cumulative_equity:
            if val > peak: peak = val
            drawdown = (peak - val) / peak * 100 if peak > 1e-9 else 100.0
            if drawdown > max_drawdown: max_drawdown = drawdown
        
        max_drawdown = min(max_drawdown, 100.0)
        
        # 3. ìƒ¤í”„ ë¹„ìœ¨ (Sharpe Ratio, ì—°ê°„í™”)
        if len(pnl_series) > 1 and pnl_series.std() > 1e-9:
            # 1h ì¶”ì„¸ -> 15m ì§„ì… ê¸°ì¤€ (í•˜ë£¨ ì•½ 4~6íšŒ ì§„ì… ê°€ì •)
            sharpe_ratio = (pnl_series.mean() / pnl_series.std()) * np.sqrt(252 * 4)
        else:
            sharpe_ratio = 0
            
        # 4. Profit Factor
        gains = pnl_series[pnl_series > 0].sum()
        losses = abs(pnl_series[pnl_series < 0].sum())
        profit_factor = gains / losses if losses > 0 else float('inf')
        
        # 5. ì•ˆì •ì„± ê³„ì‚°
        n = len(pnls)
        p1 = sum(pnls[:n//3])
        p2 = sum(pnls[n//3:2*n//3])
        p3 = sum(pnls[2*n//3:])
        score = sum([p1 > 0, p2 > 0, p3 > 0])
        stability = "âœ…" * score + "âš ï¸" * (3 - score)

        # 6. ì¼í‰ê·  ê±°ë˜ìˆ˜ ê³„ì‚°
        avg_trades_per_day = 0.0
        if len(trades) >= 2:
            try:
                # entry_time ë˜ëŠ” entry_idx ê¸°ë°˜ ê¸°ê°„ ê³„ì‚°
                first_entry = trades[0].get('entry_time') or trades[0].get('entry_idx', 0)
                last_entry = trades[-1].get('entry_time') or trades[-1].get('entry_idx', len(trades))
                
                if hasattr(first_entry, 'astype'):  # numpy datetime64
                    first_entry = pd.Timestamp(first_entry)
                    last_entry = pd.Timestamp(last_entry)
                
                if isinstance(first_entry, (pd.Timestamp, np.datetime64)):
                    total_days = max((pd.Timestamp(last_entry) - pd.Timestamp(first_entry)).days, 1)
                else:
                    # index ê¸°ë°˜ (ëŒ€ëµ 1ì‹œê°„ë´‰ ê¸°ì¤€ 24ìº”ë“¤ = 1ì¼)
                    total_days = max((last_entry - first_entry) / 24, 1)
                
                avg_trades_per_day = round(len(trades) / total_days, 2)
            except Exception:

                avg_trades_per_day = round(len(trades) / 30, 2)  # ê¸°ë³¸ 30ì¼ ê°€ì •

        return {
            'win_rate': round(win_rate, 2),
            'total_return': round(simple_return, 2),
            'simple_return': round(simple_return, 2),
            'compound_return': round(compound_return, 2),
            'max_drawdown': round(max_drawdown, 2),
            'sharpe_ratio': round(sharpe_ratio, 2),
            'profit_factor': round(profit_factor, 2),
            'stability': stability,
            'avg_trades_per_day': avg_trades_per_day
        }

    def _calculate_metrics(self, trades: List[Dict]) -> Dict:
        """ì¸ìŠ¤í„´ìŠ¤ìš© í•˜ìœ„ í˜¸í™˜ ë©”ì„œë“œ"""
        return self.calculate_metrics(trades)

    def _calculate_stability(self, pnls: List[float]) -> str:
        """3êµ¬ê°„ ì•ˆì •ì„± ì²´í¬ (ê³¼ê±°/ì¤‘ê°„/ìµœê·¼)"""
        n = len(pnls)
        if n < 3: # ìµœì†Œ ê±°ë˜ ìˆ˜ ë¯¸ë‹¬ ì‹œ
            return "âš ï¸"
        
        # êµ¬ê°„ ë¶„í• 
        p1 = sum(pnls[:n//3])
        p2 = sum(pnls[n//3:2*n//3])
        p3 = sum(pnls[2*n//3:])
        
        score = sum([p1 > 0, p2 > 0, p3 > 0])
        
        if score == 3: return "âœ…âœ…âœ…"
        if score == 2: return "âœ…âœ…âš "
        if score == 1: return "âœ…âš âš "
        return "âš âš âš "

    def _classify_results(self, results: List[OptimizationResult]) -> List[OptimizationResult]:
        """ê²°ê³¼ë¥¼ í´ëŸ¬ìŠ¤í„°ë§í•˜ì—¬ ìœ í˜•ë³„ ëŒ€í‘œê°’ ì„ ì • (v2 í•µì‹¬)"""
        if not results:
            return []
        
        # ê²°ê³¼ ë³µì‚¬ ë° ì •ë ¬ ê¸°ì¤€ë³„ í•„í„°ë§
        representatives = []
        seen_params = set()

        def add_rep(res, label):
            param_key = str(res.params)
            if param_key not in seen_params:
                res.strategy_type = label
                representatives.append(res)
                seen_params.add(param_key)

        # 1. ğŸ”¥ê³µê²©í˜•: ìµœê³  ìˆ˜ìµë¥  (MDD 20% ì´ë‚´ ì¤‘ ìµœê³ )
        aggressive = max(results, key=lambda x: x.total_return)
        add_rep(aggressive, "ğŸ”¥ê³µê²©")

        # 2. âš–ê· í˜•í˜•: ìµœê³  ìƒ¤í”„ ì§€ìˆ˜
        balanced = max(results, key=lambda x: x.sharpe_ratio)
        add_rep(balanced, "âš–ê· í˜•")

        # 3. ğŸ›¡ë³´ìˆ˜í˜•: ìµœì € MDD (ìˆ˜ìµì´ 0ë³´ë‹¤ í° ê²ƒ ì¤‘)
        profitable = [r for r in results if r.total_return > 0]
        if profitable:
            conservative = min(profitable, key=lambda x: abs(x.max_drawdown))
            add_rep(conservative, "ğŸ›¡ë³´ìˆ˜")

        # 4. ğŸ¯ê³ ìŠ¹ë¥ í˜•: ìµœê³  ìŠ¹ë¥ 
        high_wr = max(results, key=lambda x: x.win_rate)
        add_rep(high_wr, "ğŸ¯ê³ ìŠ¹ë¥ ")

        # 5. âš¡ê³ ë¹ˆë„í˜•: ìµœë‹¤ ê±°ë˜ íšŸìˆ˜
        high_freq = max(results, key=lambda x: x.trades)
        add_rep(high_freq, "âš¡ê³ ë¹ˆë„")

        # 6. ğŸ¢ì €ë¹ˆë„í˜•: ì¼í‰ê·  ê±°ë˜ ê°€ì¥ ì ì€ ê²ƒ (ìˆ˜ìµ > 0)
        if profitable:
            # avg_trades_per_day ì†ì„±ì´ ì—†ëŠ” ê²½ìš° trades ê¸°ë°˜ ëŒ€ì²´
            low_freq = min(profitable, key=lambda x: getattr(x, 'avg_trades_per_day', x.trades / 30))
            add_rep(low_freq, "ğŸ¢ì €ë¹ˆë„")

        return representatives
    
    def get_best(self, n: int = 10) -> List[OptimizationResult]:
        """ìƒìœ„ Nê°œ ê²°ê³¼ ë°˜í™˜"""
        return self.results[:n]
    
    def analyze_top_results(self, n: int = 100, threshold: float = 0.85) -> Dict:
        """
        ìƒìœ„ ê²°ê³¼ ë¶„ì„ â†’ ì§€ë°°ì  íŒŒë¼ë¯¸í„° ê³ ì • ë° ë²”ìœ„ ì¶•ì†Œ (Iterative Optimizationìš©)
        
        Args:
            n: ë¶„ì„í•  ìƒìœ„ ê²°ê³¼ ìˆ˜
            threshold: ê³ ì • íŒë‹¨ ì„ê³„ê°’ (ì˜ˆ: 0.85 -> 85% ì´ìƒ ê°™ì€ ê°’ì´ë©´ ê³ ì •)
            
        Returns:
            Dict: ì¶•ì†Œëœ íŒŒë¼ë¯¸í„° ê·¸ë¦¬ë“œ
        """
        if not self.results:
            return {}
            
        from collections import Counter
        top_results = sorted(self.results, key=lambda x: getattr(x, 'sharpe_ratio', 0), reverse=True)[:n]
        
        # ë¶„ì„ ëŒ€ìƒ íŒŒë¼ë¯¸í„° (ì§€í‘œ ê´€ë ¨)
        target_params = ['atr_mult', 'trail_start_r', 'trail_dist_r', 'pattern_tolerance', 'entry_validity_hours', 'pullback_rsi_long', 'pullback_rsi_short', 'filter_tf', 'entry_tf', 'leverage']

        
        fixed_params = {}
        reduced_ranges = {}
        
        for param in target_params:
            # í•´ë‹¹ íŒŒë¼ë¯¸í„° ê°’ ì¶”ì¶œ
            values = []
            for res in top_results:
                val = res.params.get(param)
                if val is not None:
                    if isinstance(val, list): val = val[0]
                    values.append(val)
            
            if not values: continue
            
            # ë¹ˆë„ ë¶„ì„
            counts = Counter(values)
            most_common_val, count = counts.most_common(1)[0]
            ratio = count / len(values)
            
            if ratio >= threshold:
                # ì§€ë°°ì ì¸ ê°’ ë°œê²¬ -> ê³ ì •
                fixed_params[param] = [most_common_val]
                logger.info(f"ğŸ“Œ [OPT-ADAPT] '{param}' fixed to {most_common_val} (Dominance: {ratio:.1%})")
            else:
                # ë¶„í¬ ë¶„ì„ -> ë²”ìœ„ ì¶•ì†Œ (ìµœì†Œ~ìµœëŒ€ê°’ ì‚¬ì´ë¥¼ ë‹¤ì‹œ ì´˜ì´˜í•˜ê²Œ)
                min_v = min(values)
                max_v = max(values)
                
                # ê¸°ì¡´ INDICATOR_RANGEë‚˜ ì›ë³¸ ê·¸ë¦¬ë“œì—ì„œ í•´ë‹¹ êµ¬ê°„ì˜ ê°’ë“¤ ì¶”ì¶œ
                # ì—¬ê¸°ì„œëŠ” ê°„ë‹¨íˆ 5ë¶„í• í•˜ì—¬ ì´˜ì´˜í•˜ê²Œ ìƒì„±
                if isinstance(min_v, (int, float)) and not isinstance(min_v, bool):
                     # ìˆ˜ì¹˜í˜• íŒŒë¼ë¯¸í„°
                     step = (max_v - min_v) / 5
                     if step > 0:
                         new_vals = [round(min_v + step * i, 3) for i in range(6)]
                         reduced_ranges[param] = sorted(list(set(new_vals)))
                     else:
                         reduced_ranges[param] = [min_v]
                else:
                    # ì¹´í…Œê³ ë¦¬í˜• (filter_tf ë“±)
                    reduced_ranges[param] = sorted(list(set(values)))
                
                logger.debug(f"ğŸ” [OPT-ADAPT] '{param}' range narrowed: {min_v} ~ {max_v}")

        # ìƒˆë¡œìš´ ê·¸ë¦¬ë“œ ìƒì„±
        new_grid = {}
        # 1. ê³ ì •ëœ ê°’ ì ìš©
        new_grid.update(fixed_params)
        # 2. ì¶•ì†Œëœ ë²”ìœ„ ì ìš©
        new_grid.update(reduced_ranges)
        
        # 3. ê³µí†µ í•„ë“œ ìœ ì§€ (trend_interval, max_mdd ë“±)
        if self.results:
            first_params = self.results[0].params
            for k in ['trend_interval', 'max_mdd', 'direction']:
                if k not in new_grid and k in first_params:
                    val = first_params[k]
                    new_grid[k] = val if isinstance(val, list) else [val]
        
        return new_grid

    def filter_unique_results(self, results: List[OptimizationResult] = None, 
                              max_count: int = 30) -> List[OptimizationResult]:
        """
        ì¤‘ë³µ/ìœ ì‚¬ ê²°ê³¼ ì œê±° + ìƒìœ„ Nê°œ ì„ íƒ
        
        ê¸°ì¤€:
        - ìŠ¹ë¥  1% ì´ë‚´ + MDD 2% ì´ë‚´ = ìœ ì‚¬ ê²°ê³¼
        - ìœ ì‚¬ ê·¸ë£¹ ë‚´ â†’ ë³µí•© ìŠ¤ì½”ì–´ ë†’ì€ 1ê°œë§Œ
        - ìµœì¢… max_countê°œ ë°˜í™˜
        """
        if results is None:
            results = self.results
        
        if not results:
            return []
        
        # ë³µí•© ìŠ¤ì½”ì–´ ê³„ì‚° (ìŠ¹ë¥  > MDD > ìƒ¤í”„ > ìˆ˜ìµë¥ )
        def calc_score(r):
            return (
                r.win_rate * 1.0 +                    # ìŠ¹ë¥  88% â†’ 88ì 
                (100 + r.max_drawdown) * 0.5 +        # MDD -17% â†’ 41.5ì 
                r.sharpe_ratio * 2.0 +                # ìƒ¤í”„ 26 â†’ 52ì 
                min(r.total_return / 100, 50) * 0.2   # ìˆ˜ìµë¥  cap 50
            )
        
        # ìŠ¤ì½”ì–´ ìˆœ ì •ë ¬
        scored = sorted(results, key=calc_score, reverse=True)
        
        # ìœ ì‚¬ ê²°ê³¼ ì œê±°
        unique = []
        for r in scored:
            is_duplicate = False
            for u in unique:
                # MDDëŠ” ë³´í†µ ìŒìˆ˜ì´ë¯€ë¡œ abs()ë¡œ ì°¨ì´ í™•ì¸
                if (abs(r.win_rate - u.win_rate) < 1.0 and
                    abs(r.max_drawdown - u.max_drawdown) < 2.0):
                    is_duplicate = True
                    break
            
            if not is_duplicate:
                unique.append(r)
            
            if len(unique) >= max_count:
                break
        
        logger.info(f"ğŸ”„ [FILTER] {len(results)} â†’ {len(unique)} (ì¤‘ë³µ ì œê±°)")
        return unique

    def to_dataframe(self) -> pd.DataFrame:
        """ê²°ê³¼ë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜"""
        if not self.results:
            return pd.DataFrame()
        
        rows = []
        for r in self.results:
            row = {**r.params}
            row['trades'] = r.trades
            row['win_rate'] = r.win_rate
            row['total_return'] = r.total_return
            row['max_drawdown'] = r.max_drawdown
            row['sharpe_ratio'] = r.sharpe_ratio
            row['profit_factor'] = r.profit_factor
            rows.append(row)
        
        return pd.DataFrame(rows)


# í…ŒìŠ¤íŠ¸
if __name__ == "__main__":
    import os
    import sys
    import pandas as pd
    import traceback
    
    try:
        # 1. ê²½ë¡œ ì„¤ì •
        BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
        if BASE_DIR not in sys.path:
            sys.path.append(BASE_DIR)
        
        from core.strategy_core import AlphaX7Core
        
        # ë°ì´í„° ë¡œë“œ (Parquet ìš°ì„  íƒìƒ‰)
        csv_path = os.path.join(BASE_DIR, 'data', 'cache', 'bybit_btcusdt_15m.parquet')
        if not os.path.exists(csv_path):
            csv_path = os.path.join(BASE_DIR, 'data', 'bybit_BTCUSDT_15m.csv') # Fallback
            
        logger.info(f"ğŸ“Š Testing with: {csv_path}")
        
        if os.path.exists(csv_path):
            if csv_path.endswith('.parquet'):
                df = pd.read_parquet(csv_path)
            else:
                df = pd.read_csv(csv_path)
                
            # íƒ€ì„ìŠ¤íƒ¬í”„ ë³€í™˜
            if 'timestamp' in df.columns and not pd.api.types.is_datetime64_any_dtype(df['timestamp']):
                first_ts = df['timestamp'].iloc[0]
                val = float(first_ts)
                if val > 1e12:
                    df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')
                elif val > 1e8:
                    df['timestamp'] = pd.to_datetime(df['timestamp'], unit='s')
                else:
                    df['timestamp'] = pd.to_datetime(df['timestamp'])
            
            # ìµœê·¼ 5000ê°œë§Œ ì‚¬ìš© (í…ŒìŠ¤íŠ¸ìš©)
            df = df.tail(5000).reset_index(drop=True)
            logger.info(f"Loaded {len(df)} candles. Range: {df['timestamp'].iloc[0]} ~ {df['timestamp'].iloc[-1]}")
            
            # 1. ìµœì í™” ì—”ì§„ ì‹œì‘
            optimizer = BacktestOptimizer(AlphaX7Core, df)
            grid = generate_fast_grid('1h')
            
            logger.info(f"ğŸš€ [Stage 1] Fast Grid Search Starting...")
            results = optimizer.optimize(grid, metric='sharpe_ratio')
            logger.info(f"âœ… Found {len(results)} combinations.")
            
            # 2. ë¶„ì„ ë° ë²”ìœ„ ì¶•ì†Œ (ì‹ ê·œ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸)
            refined_grid = optimizer.analyze_top_results(n=10, threshold=0.7)
            
            # 3. 2ë‹¨ê³„ ì •ë°€ ìµœì í™”
            if refined_grid:
                logger.info(f"âœ¨ [Analysis] Refined Grid calculated: {refined_grid}")
                logger.info(f"ğŸš€ [Stage 2] Iterative Scan Starting...")
                refined_results = optimizer.optimize(refined_grid, metric='sharpe_ratio')
                logger.info(f"ğŸ† Final Best Results: {len(refined_results)}")
                
                for res in refined_results[:5]:
                    logger.info(f" - {res.params}: Sharpe={res.sharpe_ratio:.2f}, WR={res.win_rate:.1f}%")
            else:
                logger.info("âœ¨ [Analysis] No dominant patterns found to refine.")
        else:
            logger.error(f"âŒ No test data found at {csv_path}. Please download data first.")
            
    except Exception:
        logger.info("âŒ Test failed with error:")
        traceback.print_exc()
