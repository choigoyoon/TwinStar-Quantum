# optimizer.py
"""
STAR-U Bot ìµœì í™” ì—”ì§„
- íŒŒë¼ë¯¸í„° ê·¸ë¦¬ë“œ ì„œì¹˜
- ê²°ê³¼ ì •ë ¬ ë° ë­í‚¹
- ìµœì ê°’ ë°˜í™˜
"""
import logging
logger = logging.getLogger(__name__)


import itertools
import pandas as pd
import numpy as np
from typing import Dict, List, Optional, Callable, Any, cast
from dataclasses import dataclass
from pathlib import Path
import multiprocessing as mp

# ë©”íŠ¸ë¦­ ê³„ì‚° (SSOT)
from utils.metrics import (
    assign_grade_by_preset
    # calculate_backtest_metricsëŠ” calculate_metrics() ë‚´ë¶€ì—ì„œ ë™ì  import
)

def optimize_strategy(symbol: str, timeframe: str, exchange: str = 'bybit') -> Optional[dict]:
    """ë°°ì¹˜ ìµœì í™”ì—ì„œ ì‚¬ìš©í•˜ëŠ” ë˜í¼ í•¨ìˆ˜ (BatchOptimizer í˜¸í™˜)"""
    # Circular import ë°©ì§€ë¥¼ ìœ„í•´ ë‚´ë¶€ì—ì„œ ì„í¬íŠ¸
    from core.strategy_core import AlphaX7Core
    from core.data_manager import BotDataManager
    
    dm = BotDataManager(exchange, symbol, {'entry_tf': timeframe})
    if dm.load_historical() and dm.df_entry_full is not None:
        opt = BacktestOptimizer(AlphaX7Core, dm.df_entry_full)
        grid = generate_fast_grid(timeframe)
        results = opt.run_optimization(dm.df_entry_full, grid)
        if results:
            best = results[0]
            return {
                'win_rate': best.win_rate,
                'profit_factor': best.profit_factor,
                'max_drawdown': best.max_drawdown,
                'total_trades': best.trades,
                'best_params': best.params
            }
    return None

import sys
import os

# Logging
from utils.logger import get_module_logger
logger = get_module_logger(__name__)

# TF_MAPPING, TF_RESAMPLE_MAP import
# ìƒìˆ˜ ë° ìœ í‹¸ë¦¬í‹° ì„í¬íŠ¸ (Phase 3 SSOT)
from config.constants.timeframes import TF_MAPPING, TF_RESAMPLE_MAP
from config.parameters import DEFAULT_PARAMS
from utils.data_utils import resample_data as shared_resample


# ==================== CPU ì›Œì»¤ ìë™ ê³„ì‚° ====================

def get_numpy_threads() -> int:
    """
    NumPy/Pandas ë‚´ë¶€ ìŠ¤ë ˆë“œ ìˆ˜ ê°ì§€ (v7.29)

    Returns:
        NumPyê°€ ì‚¬ìš©í•˜ëŠ” ìŠ¤ë ˆë“œ ìˆ˜ (ê¸°ë³¸ê°’: 1)
    """
    # MKL/OpenBLAS í™˜ê²½ ë³€ìˆ˜ í™•ì¸
    mkl_threads = os.environ.get('MKL_NUM_THREADS', None)
    openblas_threads = os.environ.get('OPENBLAS_NUM_THREADS', None)
    omp_threads = os.environ.get('OMP_NUM_THREADS', None)

    if mkl_threads:
        return int(mkl_threads)
    elif openblas_threads:
        return int(openblas_threads)
    elif omp_threads:
        return int(omp_threads)
    else:
        # ê¸°ë³¸ê°’: 1 (ë‹¨ì¼ ìŠ¤ë ˆë“œ ê°€ì •)
        return 1


def get_optimal_workers(mode: str = 'standard', available_memory_gb: float | None = None) -> int:
    """
    ìµœì  ì›Œì»¤ ìˆ˜ ìë™ ê³„ì‚° (v7.29 - ë¬¼ë¦¬ ì½”ì–´ + NumPy ìŠ¤ë ˆë“œ ê³ ë ¤)

    âœ… v7.29 ê°œì„ :
    - ë¬¼ë¦¬ ì½”ì–´ ìš°ì„  ì‚¬ìš© (100% íš¨ìœ¨)
    - í•˜ì´í¼ìŠ¤ë ˆë”© ë³´ì¡° ì‚¬ìš© (35% íš¨ìœ¨, Deep ëª¨ë“œë§Œ)
    - NumPy ë©€í‹°ìŠ¤ë ˆë”© ê³ ë ¤ (n_workers Ã— numpy_threads â‰¤ logical_cores)
    - ë©”ëª¨ë¦¬ ì œì•½ ìš°ì„  ì ìš©

    Args:
        mode: 'quick', 'standard', 'deep'
        available_memory_gb: ì‚¬ìš© ê°€ëŠ¥í•œ ë©”ëª¨ë¦¬ (GB). Noneì´ë©´ ìë™ ê°ì§€

    Returns:
        ì›Œì»¤ ìˆ˜ (1 ~ cpu_count)
    """
    # 1. ì½”ì–´ ê°ì§€
    try:
        import psutil
        physical_cores = psutil.cpu_count(logical=False) or 4
        logical_cores = psutil.cpu_count(logical=True) or 4
        hyperthreading = logical_cores > physical_cores
    except ImportError:
        # psutil ì—†ìœ¼ë©´ mp.cpu_count() ì‚¬ìš© (ë…¼ë¦¬ ì½”ì–´)
        logical_cores = mp.cpu_count() or 4
        physical_cores = logical_cores  # í•˜ì´í¼ìŠ¤ë ˆë”© ì—†ë‹¤ê³  ê°€ì •
        hyperthreading = False

    # 2. NumPy ë©€í‹°ìŠ¤ë ˆë”© ê°ì§€
    numpy_threads = get_numpy_threads()

    # 3. ëª¨ë“œë³„ ê¸°ë³¸ ì›Œì»¤ ìˆ˜ (ë¬¼ë¦¬ ì½”ì–´ ê¸°ë°˜)
    if mode == 'quick':
        base_workers = max(1, physical_cores // 2)  # 50% ì‚¬ìš©
    elif mode == 'standard':
        base_workers = max(2, physical_cores - 1)   # ë¬¼ë¦¬ ì½”ì–´ - 1
    elif mode == 'deep':
        if hyperthreading:
            # ë¬¼ë¦¬ ì½”ì–´ ì „ì²´ + ë…¼ë¦¬ ì½”ì–´ 35% í™œìš©
            ht_bonus = max(1, (logical_cores - physical_cores) // 3)
            base_workers = physical_cores + ht_bonus
        else:
            base_workers = max(2, physical_cores - 1)
    else:
        base_workers = max(2, physical_cores // 2)

    # 4. NumPy ë©€í‹°ìŠ¤ë ˆë”© ê³ ë ¤í•œ ì›Œì»¤ ì¡°ì •
    if numpy_threads > 1:
        # ì´ ìŠ¤ë ˆë“œ = n_workers Ã— numpy_threads â‰¤ logical_cores
        max_workers_by_numpy = logical_cores // numpy_threads
        workers = min(base_workers, max_workers_by_numpy)
    else:
        workers = base_workers

    # 5. ë©”ëª¨ë¦¬ ì œì•½ (v7.28 ê¸°ì¡´ ë¡œì§)
    if available_memory_gb is None:
        try:
            import psutil
            available_memory_gb = psutil.virtual_memory().available / (1024 ** 3)
        except ImportError:
            available_memory_gb = 999.0

    # ë©”ëª¨ë¦¬ ì œì•½ ì ìš©
    if available_memory_gb < 2.0:
        workers = min(workers, 2)
    elif available_memory_gb < 4.0:
        workers = min(workers, 4)
    elif available_memory_gb < 8.0:
        workers = min(workers, 6)

    return max(1, workers)


def get_worker_info(mode: str = 'standard') -> dict:
    """
    ì›Œì»¤ ì •ë³´ ë°˜í™˜ (ë¡œê¹…/GUI í‘œì‹œìš©, v7.29: ë¬¼ë¦¬ ì½”ì–´ + NumPy ìŠ¤ë ˆë“œ ì •ë³´ ì¶”ê°€)

    Returns:
        {
            'total_cores': int,              # ë…¼ë¦¬ ì½”ì–´ (í•˜ì´í¼ìŠ¤ë ˆë”© í¬í•¨)
            'physical_cores': int,           # v7.29 ì‹ ê·œ: ë¬¼ë¦¬ ì½”ì–´
            'hyperthreading': bool,          # v7.29 ì‹ ê·œ: í•˜ì´í¼ìŠ¤ë ˆë”© ì—¬ë¶€
            'numpy_threads': int,            # v7.29 ì‹ ê·œ: NumPy ë‚´ë¶€ ìŠ¤ë ˆë“œ
            'workers': int,
            'total_threads': int,            # v7.29 ì‹ ê·œ: workers Ã— numpy_threads
            'usage_percent': float,
            'description': str,
            'free_cores': int,
            'available_memory_gb': float,
            'memory_limited': bool
        }
    """
    # 1. ì½”ì–´ ì •ë³´ ìˆ˜ì§‘
    try:
        import psutil
        physical_cores = psutil.cpu_count(logical=False) or 4
        logical_cores = psutil.cpu_count(logical=True) or 4
        hyperthreading = logical_cores > physical_cores
        available_memory_gb = psutil.virtual_memory().available / (1024 ** 3)
    except ImportError:
        logical_cores = mp.cpu_count() or 1
        physical_cores = logical_cores
        hyperthreading = False
        available_memory_gb = -1.0

    # 2. NumPy ìŠ¤ë ˆë“œ ì •ë³´
    numpy_threads = get_numpy_threads()

    # 3. ì›Œì»¤ ê³„ì‚°
    workers = get_optimal_workers(mode, available_memory_gb)
    total_threads = workers * numpy_threads
    usage = (total_threads / logical_cores) * 100

    # 4. ë©”ëª¨ë¦¬ ì œí•œ ì—¬ë¶€ íŒë‹¨
    cpu_only_workers = get_optimal_workers(mode, 999.0)  # ë©”ëª¨ë¦¬ ë¬´ì œí•œ
    memory_limited = (workers < cpu_only_workers)

    # 5. ì„¤ëª… ìƒì„±
    descriptions = {
        'quick': f'ë¹ ë¥¸ ëª¨ë“œ (CPU {usage:.0f}% ì‚¬ìš©)',
        'standard': f'í‘œì¤€ ëª¨ë“œ (CPU {usage:.0f}% ì‚¬ìš©)',
        'deep': f'ë”¥ ëª¨ë“œ (CPU {usage:.0f}% ì‚¬ìš©, ìµœëŒ€ ì„±ëŠ¥)',
    }
    desc = descriptions.get(mode, 'ì•Œ ìˆ˜ ì—†ìŒ')

    # 6. NumPy ë©€í‹°ìŠ¤ë ˆë”© ì •ë³´ ì¶”ê°€
    if numpy_threads > 1:
        desc += f' [NumPy: {numpy_threads}ìŠ¤ë ˆë“œ]'

    # 7. ë©”ëª¨ë¦¬ ì œí•œ ì‹œ ì„¤ëª… ì¶”ê°€
    if memory_limited and available_memory_gb > 0:
        desc += f' [ë©”ëª¨ë¦¬ ì œì•½: {available_memory_gb:.1f}GB]'

    return {
        'total_cores': logical_cores,
        'physical_cores': physical_cores,        # v7.29
        'hyperthreading': hyperthreading,        # v7.29
        'numpy_threads': numpy_threads,          # v7.29
        'workers': workers,
        'total_threads': total_threads,          # v7.29
        'usage_percent': usage,
        'description': desc,
        'free_cores': logical_cores - total_threads,
        'available_memory_gb': available_memory_gb,
        'memory_limited': memory_limited
    }


# ==================== ìµœì í™” ìƒìˆ˜ ====================

# ë¦¬ìƒ˜í”Œë§ ê°€ëŠ¥í•œ TF
AVAILABLE_TF = ['15m', '30m', '45m', '1h', '2h', '3h', '4h', '6h', '12h', '1d', '1w']

# ì¶”ì„¸ TFë³„ ìë™ íƒìƒ‰ ë²”ìœ„ (v2.0 - í•„í„° ê°•í™”)
TF_AUTO_RANGE = {
    '1h': {
        'filter_tf': ['4h', '6h', '12h', '1d'],  # 2h ì œê±° (ë„ˆë¬´ ì•½í•¨)
        'entry_tf': ['15m', '30m', '45m']
    },
    '4h': {
        'filter_tf': ['1d', '1w'],  # 6h, 12h ì œê±° (í•„í„° ê°•í™”)
        'entry_tf': ['15m', '30m', '1h', '2h']
    },
    '1d': {
        'filter_tf': ['1w'],
        'entry_tf': ['1h', '2h', '4h', '6h', '12h']
    },
    '1w': {
        'filter_tf': ['1d'],
        'entry_tf': ['4h', '6h', '12h', '1d']
    }
}

# ë°°ìœ¨ ë²”ìœ„
LEVERAGE_RANGE = [1, 2, 3, 5, 7, 10, 15, 20]

# ë°©í–¥ ë²”ìœ„
DIRECTION_RANGE = ['Both', 'Long', 'Short']

# ì§€í‘œ ë²”ìœ„ ì„¤ì • (Standard ëª¨ë“œ ê¸°ë³¸ê°’, í•˜ìœ„ í˜¸í™˜ì„±)
INDICATOR_RANGE = {
    'macd_fast': [6, 8, 10, 12],
    'macd_slow': [18, 20, 24, 26, 32],
    'macd_signal': [7, 9, 12],
    'ema_period': [10, 20, 50],

    # ê¸°ì¡´ ìœ ì§€ ë° ìµœì í™”
    'atr_mult': [1.0, 1.5, 2.0, 2.2],
    'atr_period': [7, 14, 21],
    'rsi_period': [7, 14, 21],
    'trail_start_r': [0.5, 0.7, 1.0],
    'trail_dist_r': [0.2, 0.35, 0.5],
    'pullback_rsi_long': [35, 40, 45],
    'pullback_rsi_short': [55, 60, 65],
    'pattern_tolerance': [0.03, 0.04, 0.05],
    'entry_validity_hours': [12, 24, 48],
    'max_adds': [0, 1, 2],
}

# ==================== ëª¨ë“œë³„ ì§€í‘œ ë²”ìœ„ ====================

# Quick ëª¨ë“œ (ìµœì†Œ ì¡°í•©, 4ê°œ) - ìŠ¹ë¥  80%+ & ë§¤ë§¤ë¹ˆë„ 0.5íšŒ/ì¼ ëª©í‘œ
# âœ… DEFAULT_PARAMS í¬í•¨: atr_mult=1.25, rsi_period=14, entry_validity_hours=6
INDICATOR_RANGE_QUICK = {
    'macd_fast': [8, 12],
    'macd_slow': [20, 26],
    'macd_signal': [9],
    'ema_period': [20, 50],
    'atr_mult': [1.25, 2.5],             # 2ê°œ - ìµœì ê°’(1.25) + ë³´ìˆ˜ê°’(2.5)
    'atr_period': [14],
    'rsi_period': [14],                  # 1ê°œ - í‘œì¤€ê°’ (ê³ ì •)
    'trail_start_r': [0.7, 1.0],
    'trail_dist_r': [0.35, 0.5],
    'pullback_rsi_long': [40],
    'pullback_rsi_short': [60],
    'pattern_tolerance': [0.05],
    'entry_validity_hours': [6, 48],     # 2ê°œ - ìµœì ê°’(6) + ì €ë¹ˆë„(48)
    'max_adds': [0, 1],
}
# í•µì‹¬ ì¡°í•©: 2 (atr_mult) Ã— 1 (rsi_period) Ã— 2 (entry_validity_hours) = 4ê°œ

# Standard ëª¨ë“œ (ê· í˜•, 36ê°œ) - ìŠ¹ë¥  75%+ & ë§¤ë§¤ë¹ˆë„ 1-2íšŒ/ì¼ ëª©í‘œ
# âœ… DEFAULT_PARAMS í¬í•¨: atr_mult=1.25, rsi_period=14, entry_validity_hours=6
INDICATOR_RANGE_STANDARD = {
    'macd_fast': [6, 8, 10, 12],
    'macd_slow': [18, 20, 24, 26],
    'macd_signal': [7, 9, 12],
    'ema_period': [10, 20, 30, 50],
    'atr_mult': [1.25, 1.5, 2.0, 2.5],       # 4ê°œ - ìµœì ê°’(1.25) í¬í•¨
    'atr_period': [7, 14, 21],
    'rsi_period': [7, 14, 21],               # 3ê°œ - ë‹¨ê¸°/í‘œì¤€/ì¥ê¸° ê· í˜•
    'trail_start_r': [0.5, 0.7, 1.0, 1.2],
    'trail_dist_r': [0.2, 0.35, 0.5, 0.7],
    'pullback_rsi_long': [35, 40, 45],
    'pullback_rsi_short': [55, 60, 65],
    'pattern_tolerance': [0.03, 0.04, 0.05],
    'entry_validity_hours': [6, 12, 24],     # 3ê°œ - ìµœì ê°’(6) í¬í•¨
    'max_adds': [0, 1, 2],
}
# í•µì‹¬ ì¡°í•©: 4 (atr_mult) Ã— 3 (rsi_period) Ã— 3 (entry_validity_hours) = 36ê°œ

# Deep ëª¨ë“œ (ì™„ì „ íƒìƒ‰, 252ê°œ) - ë‹¤ì–‘í•œ ìŠ¤íƒ€ì¼ íƒìƒ‰ (ê³µê²©Ã—3, ê· í˜•, ë³´ìˆ˜, ê³ ìŠ¹ë¥ , ì €ë¹ˆë„)
# âœ… DEFAULT_PARAMS í¬í•¨: atr_mult=1.25, rsi_period=14, entry_validity_hours=6
INDICATOR_RANGE_DEEP = {
    'atr_mult': [1.0, 1.25, 1.5, 2.0, 2.5, 3.0],  # 6ê°œ - ìµœì ê°’(1.25) í¬í•¨, 3.5 ì œê±°
    'rsi_period': [5, 7, 11, 14, 21, 25, 30],     # 7ê°œ - ì „ì²´ ë²”ìœ„
    'entry_validity_hours': [6, 12, 24, 36, 48, 72],  # 6ê°œ - ìµœì ê°’(6) í¬í•¨
}
# í•µì‹¬ ì¡°í•©: 6 (atr_mult) Ã— 7 (rsi_period) Ã— 6 (entry_validity_hours) = 252ê°œ


def get_indicator_range(mode: str = 'standard') -> Dict:
    """
    ëª¨ë“œì— ë”°ë¥¸ ì§€í‘œ ë²”ìœ„ ë°˜í™˜

    Args:
        mode: 'quick', 'standard', 'deep'

    Returns:
        ì§€í‘œ ë²”ìœ„ ë”•ì…”ë„ˆë¦¬
    """
    mode = mode.lower()

    if mode == 'quick':
        return INDICATOR_RANGE_QUICK.copy()
    elif mode == 'deep':
        return INDICATOR_RANGE_DEEP.copy()
    else:
        return INDICATOR_RANGE_STANDARD.copy()





# ==================== Grid ìƒì„± í•¨ìˆ˜ ====================

def generate_full_grid(trend_tf: str, max_mdd: float = 20.0) -> Dict:
    """
    Standard ëª¨ë“œìš© Grid (~60ê°œ) - ìŠ¹ë¥  & ë§¤ë§¤ë¹ˆë„ ìµœì í™”
    """
    from config.parameters import get_param_range_by_mode, DEFAULT_PARAMS

    tf_range = TF_AUTO_RANGE.get(trend_tf, TF_AUTO_RANGE['1h'])

    # None ë°©ì–´: get_param_range_by_mode() ë°˜í™˜ê°’ None ì²´í¬ + ê¸°ë³¸ê°’ í´ë°±
    filter_tf = get_param_range_by_mode('filter_tf', 'standard') or [DEFAULT_PARAMS.get('filter_tf', '4h')]
    atr_mult = get_param_range_by_mode('atr_mult', 'standard') or [DEFAULT_PARAMS.get('atr_mult', 1.5)]
    trail_start_r = get_param_range_by_mode('trail_start_r', 'standard') or [DEFAULT_PARAMS.get('trail_start_r', 0.8)]
    trail_dist_r = get_param_range_by_mode('trail_dist_r', 'standard') or [DEFAULT_PARAMS.get('trail_dist_r', 0.1)]
    entry_validity_hours = get_param_range_by_mode('entry_validity_hours', 'standard') or [DEFAULT_PARAMS.get('entry_validity_hours', 6.0)]

    return {
        'trend_interval': [trend_tf],
        'filter_tf': filter_tf,                                              # 3ê°œ ['4h', '6h', '12h']
        'entry_tf': [tf_range['entry_tf'][0]],                               # 1ê°œ (15m)
        'leverage': [1],                                                      # 1ê°œ (ê³ ì •)
        'direction': ['Both'],                                                # 1ê°œ (ê³ ì •)
        'max_mdd': [max_mdd],                                                 # 1ê°œ (ê³ ì •)
        'atr_mult': atr_mult,                                                 # 4ê°œ [1.25, 1.5, 2.0, 2.5]
        'trail_start_r': trail_start_r,                                       # 4ê°œ [1.0, 1.5, 2.0, 2.5]
        'trail_dist_r': trail_dist_r,                                         # 2ê°œ [0.2, 0.3]
        'pattern_tolerance': [0.05],                                          # 1ê°œ (ê³ ì •)
        'entry_validity_hours': entry_validity_hours,                         # 5ê°œ [6, 12, 24, 48, 72]
        'pullback_rsi_long': [40],                                            # 1ê°œ (ê³ ì •)
        'pullback_rsi_short': [60],                                           # 1ê°œ (ê³ ì •)
        # Total: 3Ã—1Ã—1Ã—1Ã—1Ã—4Ã—4Ã—2Ã—1Ã—5Ã—1Ã—1 = 120ê°œ âœ…
    }



def generate_quick_grid(trend_tf: str, max_mdd: float = 20.0) -> Dict:
    """Quick ëª¨ë“œìš© ìµœì†Œ Grid (~8ê°œ) - ìŠ¹ë¥  80% & ë§¤ë§¤ë¹ˆë„ 0.5íšŒ/ì¼ ëª©í‘œ"""
    from config.parameters import get_param_range_by_mode, DEFAULT_PARAMS

    tf_range = TF_AUTO_RANGE.get(trend_tf, TF_AUTO_RANGE['1h'])

    # None ë°©ì–´: get_param_range_by_mode() ë°˜í™˜ê°’ None ì²´í¬ + ê¸°ë³¸ê°’ í´ë°±
    filter_tf = get_param_range_by_mode('filter_tf', 'quick') or [DEFAULT_PARAMS.get('filter_tf', '4h')]
    atr_mult = get_param_range_by_mode('atr_mult', 'quick') or [DEFAULT_PARAMS.get('atr_mult', 1.5)]
    trail_start_r = get_param_range_by_mode('trail_start_r', 'quick') or [DEFAULT_PARAMS.get('trail_start_r', 0.8)]
    trail_dist_r = get_param_range_by_mode('trail_dist_r', 'quick') or [DEFAULT_PARAMS.get('trail_dist_r', 0.1)]
    entry_validity_hours = get_param_range_by_mode('entry_validity_hours', 'quick') or [DEFAULT_PARAMS.get('entry_validity_hours', 6.0)]

    return {
        'trend_interval': [trend_tf],
        'filter_tf': filter_tf,                                                # 2ê°œ ['12h', '1d']
        'entry_tf': [tf_range['entry_tf'][0]],                                # 1ê°œ (15m ê³ ì •)
        'leverage': [1],                                                       # 1ê°œ (ê³ ì •)
        'direction': ['Both'],                                                 # 1ê°œ (ê³ ì •)
        'max_mdd': [max_mdd],                                                  # 1ê°œ (ê³ ì •)
        'atr_mult': atr_mult,                                                  # 2ê°œ [1.25, 2.0]
        'trail_start_r': trail_start_r,                                        # 2ê°œ [1.0, 1.5]
        'trail_dist_r': trail_dist_r,                                          # 1ê°œ [0.2]
        'pattern_tolerance': [0.05],                                           # 1ê°œ (ê³ ì •)
        'entry_validity_hours': entry_validity_hours,                          # 2ê°œ [48, 72]
        'pullback_rsi_long': [40],                                             # 1ê°œ (ê³ ì •)
        'pullback_rsi_short': [60],                                            # 1ê°œ (ê³ ì •)
        # Total: 2Ã—1Ã—1Ã—1Ã—1Ã—2Ã—2Ã—1Ã—1Ã—2Ã—1Ã—1 = 8ê°œ âœ…
    }



def generate_standard_grid(trend_tf: str, max_mdd: float = 20.0) -> Dict:
    """
    [DEPRECATED v7.21] Standard ëª¨ë“œ ì œê±°ë¨

    Standard ëª¨ë“œëŠ” Quick/Deepìœ¼ë¡œ ì¶©ë¶„í•˜ë©° Metaê°€ ê°€ì¥ íš¨ìœ¨ì ì…ë‹ˆë‹¤.
    í•˜ìœ„ í˜¸í™˜ì„±ì„ ìœ„í•´ Quick ê·¸ë¦¬ë“œë¡œ fallbackí•©ë‹ˆë‹¤.

    Args:
        trend_tf: íƒ€ì„í”„ë ˆì„
        max_mdd: ìµœëŒ€ MDD

    Returns:
        Quick ëª¨ë“œ ê·¸ë¦¬ë“œ (í•˜ìœ„ í˜¸í™˜ì„±)
    """
    import warnings
    warnings.warn(
        "generate_standard_grid()ëŠ” v7.21ì—ì„œ deprecatedë˜ì—ˆìŠµë‹ˆë‹¤. "
        "Meta ëª¨ë“œë¥¼ ì‚¬ìš©í•˜ê±°ë‚˜ Quick/Deep ëª¨ë“œë¥¼ ì„ íƒí•˜ì„¸ìš”.",
        DeprecationWarning,
        stacklevel=2
    )
    return generate_quick_grid(trend_tf, max_mdd)

def generate_deep_grid(trend_tf: str, max_mdd: float = 20.0) -> Dict:
    """Deep ëª¨ë“œìš© ì •ë°€ Grid (~1,080ê°œ) - ì „ìˆ˜ ì¡°ì‚¬"""
    from config.parameters import get_param_range_by_mode, DEFAULT_PARAMS

    tf_range = TF_AUTO_RANGE.get(trend_tf, TF_AUTO_RANGE['1h'])

    # None ë°©ì–´: get_param_range_by_mode() ë°˜í™˜ê°’ None ì²´í¬ + ê¸°ë³¸ê°’ í´ë°±
    filter_tf = get_param_range_by_mode('filter_tf', 'deep') or [DEFAULT_PARAMS.get('filter_tf', '4h')]
    atr_mult = get_param_range_by_mode('atr_mult', 'deep') or [DEFAULT_PARAMS.get('atr_mult', 1.5)]
    trail_start_r = get_param_range_by_mode('trail_start_r', 'deep') or [DEFAULT_PARAMS.get('trail_start_r', 0.8)]
    trail_dist_r = get_param_range_by_mode('trail_dist_r', 'deep') or [DEFAULT_PARAMS.get('trail_dist_r', 0.1)]
    entry_validity_hours = get_param_range_by_mode('entry_validity_hours', 'deep') or [DEFAULT_PARAMS.get('entry_validity_hours', 6.0)]

    return {
        'trend_interval': [trend_tf],
        'filter_tf': filter_tf,                                               # 5ê°œ ['2h', '4h', '6h', '12h', '1d']
        'entry_tf': [tf_range['entry_tf'][0]],                               # 1ê°œ (15m ê³ ì •)
        'leverage': [1],                                                      # 1ê°œ (ê³ ì •)
        'direction': ['Both'],                                                # 1ê°œ (ê³ ì •)
        'max_mdd': [max_mdd],                                                 # 1ê°œ (ê³ ì •)
        'atr_mult': atr_mult,                                                 # 6ê°œ [1.0, 1.25, 1.5, 2.0, 2.5, 3.0]
        'trail_start_r': trail_start_r,                                       # 6ê°œ [0.8, 1.0, 1.5, 2.0, 2.5, 3.0]
        'trail_dist_r': trail_dist_r,                                         # 4ê°œ [0.15, 0.2, 0.25, 0.3]
        'pattern_tolerance': [0.05],                                          # 1ê°œ (ê³ ì •)
        'entry_validity_hours': entry_validity_hours,                         # 7ê°œ [6, 12, 24, 36, 48, 72, 96]
        'pullback_rsi_long': [40],                                            # 1ê°œ (ê³ ì •)
        'pullback_rsi_short': [60],                                           # 1ê°œ (ê³ ì •)
        # Total: 5Ã—1Ã—1Ã—1Ã—1Ã—6Ã—6Ã—4Ã—1Ã—7Ã—1Ã—1 = 1,080ê°œ âœ…
    }


def generate_adaptive_grid(trend_tf: str, max_mdd: float = 20.0, sample_ratio: float = 0.33) -> Dict:
    """
    Adaptive ìƒ˜í”Œë§ Grid ìƒì„± (v7.29 - ì„±ëŠ¥ ìµœì í™”)

    ì „ëµ:
    - í•µì‹¬ íŒŒë¼ë¯¸í„° (atr_mult, filter_tf): 100% ê²€ì‚¬
    - ë³´ì¡° íŒŒë¼ë¯¸í„° (trail_start_r, trail_dist_r, entry_validity_hours): ê³„ì¸µ ìƒ˜í”Œë§
    - ëª©í‘œ: 1,080ê°œ â†’ 360ê°œ (33% ê²€ì‚¬, -67%)

    Args:
        trend_tf: ì¶”ì„¸ íƒ€ì„í”„ë ˆì„
        max_mdd: ìµœëŒ€ ë‚™í­ í—ˆìš©ì¹˜
        sample_ratio: ìƒ˜í”Œë§ ë¹„ìœ¨ (ê¸°ë³¸ê°’: 0.33 = 33%)

    Returns:
        Adaptive ìƒ˜í”Œë§ëœ íŒŒë¼ë¯¸í„° ê·¸ë¦¬ë“œ

    Examples:
        # ê¸°ë³¸ 33% ìƒ˜í”Œë§
        grid = generate_adaptive_grid('1h')  # 360ê°œ ì¡°í•©

        # 50% ìƒ˜í”Œë§ (ë” ì •ë°€)
        grid = generate_adaptive_grid('1h', sample_ratio=0.5)  # 540ê°œ ì¡°í•©
    """
    from config.parameters import get_param_range_by_mode, DEFAULT_PARAMS

    tf_range = TF_AUTO_RANGE.get(trend_tf, TF_AUTO_RANGE['1h'])

    # ì „ì²´ ë²”ìœ„ ê°€ì ¸ì˜¤ê¸°
    filter_tf_full = get_param_range_by_mode('filter_tf', 'deep') or [DEFAULT_PARAMS.get('filter_tf', '4h')]
    atr_mult_full = get_param_range_by_mode('atr_mult', 'deep') or [DEFAULT_PARAMS.get('atr_mult', 1.5)]
    trail_start_r_full = get_param_range_by_mode('trail_start_r', 'deep') or [DEFAULT_PARAMS.get('trail_start_r', 0.8)]
    trail_dist_r_full = get_param_range_by_mode('trail_dist_r', 'deep') or [DEFAULT_PARAMS.get('trail_dist_r', 0.1)]
    entry_validity_hours_full = get_param_range_by_mode('entry_validity_hours', 'deep') or [DEFAULT_PARAMS.get('entry_validity_hours', 6.0)]

    # âœ… ê³„ì¸µ ìƒ˜í”Œë§ (ì¤‘ìš”ë„ ê¸°ë°˜)
    # Level 1: atr_mult (ê°€ì¥ ì¤‘ìš”, MDD ì§ì ‘ ì˜í–¥) â†’ 100% ê²€ì‚¬
    atr_mult = atr_mult_full  # 6ê°œ ì „ì²´

    # Level 2: filter_tf (ì¶”ì„¸ í•„í„°) â†’ 100% ê²€ì‚¬
    filter_tf = filter_tf_full  # 5ê°œ ì „ì²´

    # Level 3: trail_start_r (ìˆ˜ìµ ë³´í˜¸) â†’ 50% ìƒ˜í”Œë§
    trail_start_r = [trail_start_r_full[i] for i in range(0, len(trail_start_r_full), 2)]  # 6ê°œ â†’ 3ê°œ

    # Level 4: trail_dist_r (ìµì ˆ íƒ€ì´ë°) â†’ 50% ìƒ˜í”Œë§
    trail_dist_r = [trail_dist_r_full[i] for i in range(0, len(trail_dist_r_full), 2)]  # 4ê°œ â†’ 2ê°œ

    # Level 5: entry_validity_hours (ë§¤ë§¤ ë¹ˆë„) â†’ 30% ìƒ˜í”Œë§
    entry_validity_hours = [entry_validity_hours_full[0], entry_validity_hours_full[-1]]  # 7ê°œ â†’ 2ê°œ (ì–‘ ë)

    return {
        'trend_interval': [trend_tf],
        'filter_tf': filter_tf,                        # 5ê°œ (100%)
        'entry_tf': [tf_range['entry_tf'][0]],        # 1ê°œ
        'leverage': [1],                               # 1ê°œ
        'direction': ['Both'],                         # 1ê°œ
        'max_mdd': [max_mdd],                         # 1ê°œ
        'atr_mult': atr_mult,                         # 6ê°œ (100%)
        'trail_start_r': trail_start_r,               # 3ê°œ (50%)
        'trail_dist_r': trail_dist_r,                 # 2ê°œ (50%)
        'pattern_tolerance': [0.05],                  # 1ê°œ
        'entry_validity_hours': entry_validity_hours, # 2ê°œ (30%)
        'pullback_rsi_long': [40],                    # 1ê°œ
        'pullback_rsi_short': [60],                   # 1ê°œ
        # Total: 5Ã—1Ã—1Ã—1Ã—1Ã—6Ã—3Ã—2Ã—1Ã—2Ã—1Ã—1 = 360ê°œ (-67%) âœ…
    }


def generate_grid_by_mode(
    trend_tf: str,
    mode: str = 'meta',  # v7.21: ê¸°ë³¸ê°’ 'meta'ë¡œ ë³€ê²½
    max_mdd: float = 20.0,
    use_indicator_ranges: bool = False  # ê¸°ë³¸ê°’ Falseë¡œ ë³€ê²½ (ì¤‘ë³µ ë°©ì§€)
) -> Dict:
    """
    ëª¨ë“œì— ë”°ë¼ ì ì ˆí•œ ê·¸ë¦¬ë“œ ìƒì„± (í†µí•© í•¨ìˆ˜)

    Args:
        trend_tf: ì¶”ì„¸ íƒ€ì„í”„ë ˆì„
        mode: 'meta', 'quick', 'deep' (v7.21: standard ì œê±°)
        max_mdd: ìµœëŒ€ ë‚™í­ í—ˆìš©ì¹˜
        use_indicator_ranges: Trueë©´ ëª¨ë“œë³„ ì§€í‘œ ë²”ìœ„ ì‚¬ìš©, Falseë©´ ê¸°ì¡´ ê·¸ë¦¬ë“œ ìœ ì§€

    Returns:
        íŒŒë¼ë¯¸í„° ê·¸ë¦¬ë“œ

    Examples:
        Meta ëª¨ë“œ (20ì´ˆ, ~3,000ê°œ) - ê¶Œì¥:
            grid = generate_grid_by_mode('1h', 'meta')

        Quick ëª¨ë“œ (2ë¶„, ~8ê°œ):
            grid = generate_grid_by_mode('1h', 'quick')

        Deep ëª¨ë“œ (2ë¶„, ~1,080ê°œ):
            grid = generate_grid_by_mode('1h', 'deep')
    """
    mode = mode.lower()

    # Standard ëª¨ë“œ deprecated ê²½ê³  (v7.21)
    if mode == 'standard':
        import warnings
        warnings.warn(
            "Standard ëª¨ë“œëŠ” v7.21ì—ì„œ ì œê±°ë˜ì—ˆìŠµë‹ˆë‹¤. Quick ëª¨ë“œë¡œ fallbackí•©ë‹ˆë‹¤.",
            DeprecationWarning,
            stacklevel=2
        )
        mode = 'quick'

    # ê¸°ì¡´ ê·¸ë¦¬ë“œ í•¨ìˆ˜ ì‚¬ìš© (í•˜ìœ„ í˜¸í™˜ì„±)
    if mode == 'quick':
        grid = generate_quick_grid(trend_tf, max_mdd)
    elif mode == 'deep':
        grid = generate_deep_grid(trend_tf, max_mdd)
    else:
        grid = generate_standard_grid(trend_tf, max_mdd)

    # ëª¨ë“œë³„ ì§€í‘œ ë²”ìœ„ ì ìš© (ì„ íƒì )
    if use_indicator_ranges:
        indicator_range = get_indicator_range(mode)

        # ì§€í‘œ ë²”ìœ„ ë³‘í•© (ê¸°ì¡´ grid ìš°ì„ , ëˆ„ë½ëœ ì§€í‘œë§Œ ì¶”ê°€)
        for key, values in indicator_range.items():
            if key not in grid:
                grid[key] = values

    return grid


# ==================== ëª¨ë“œë³„ ê²°ê³¼ ê°œìˆ˜ ìƒìˆ˜ ====================
MODE_RESULT_COUNT = {
    'quick': 1,      # ìµœì  1ê°œ
    'standard': 3,   # ê³µê²©, ê· í˜•, ë³´ìˆ˜
    'deep': 5,       # ê³µê²©Ã—3, ê· í˜•, ë³´ìˆ˜ (+ ê³ ìŠ¹ë¥ , ì €ë¹ˆë„ = ìµœëŒ€ 7ê°œ)
}


def is_admin_mode() -> bool:
    """
    ê´€ë¦¬ì ê¶Œí•œ ì²´í¬ (Windows)
    Deep ëª¨ë“œ ì‚¬ìš© ì‹œ ê´€ë¦¬ì ê¶Œí•œ í•„ìš”
    
    Returns:
        True if running as admin, False otherwise
    """
    try:
        import ctypes
        return ctypes.windll.shell32.IsUserAnAdmin() != 0
    except Exception:
        # Windowsê°€ ì•„ë‹Œ ê²½ìš° ë˜ëŠ” ì²´í¬ ì‹¤íŒ¨ ì‹œ True ë°˜í™˜ (ì œí•œ ì—†ìŒ)
        return True


def get_mode_from_grid(grid: Dict) -> str:
    """
    Grid ì¡°í•© ìˆ˜ì— ë”°ë¼ ìë™ìœ¼ë¡œ ëª¨ë“œ ê²°ì •
    
    Args:
        grid: íŒŒë¼ë¯¸í„° ê·¸ë¦¬ë“œ
    
    Returns:
        'quick', 'standard', or 'deep'
    """
    total, _ = estimate_combinations(grid)
    
    if total <= 200:
        return 'quick'
    elif total <= 10000:
        return 'standard'
    else:
        return 'deep'


def validate_deep_mode() -> tuple:
    """
    Deep ëª¨ë“œ ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ ê²€ì¦
    
    Returns:
        (can_use: bool, message: str)
    """
    if not is_admin_mode():
        return False, "âš ï¸ Deep ëª¨ë“œëŠ” ê´€ë¦¬ì ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤. ê´€ë¦¬ìë¡œ ì‹¤í–‰í•´ì£¼ì„¸ìš”."
    
    # ë©”ëª¨ë¦¬ ì²´í¬ (ìµœì†Œ 8GB ê¶Œì¥)
    try:
        import psutil
        available_gb = psutil.virtual_memory().available / (1024**3)
        if available_gb < 4:
            return False, f"âš ï¸ Deep ëª¨ë“œëŠ” ìµœì†Œ 4GB ë©”ëª¨ë¦¬ê°€ í•„ìš”í•©ë‹ˆë‹¤. (í˜„ì¬: {available_gb:.1f}GB)"
    except ImportError:
        pass  # psutil ì—†ìœ¼ë©´ ì²´í¬ ìŠ¤í‚µ
    
    return True, "âœ… Deep ëª¨ë“œ ì‚¬ìš© ê°€ëŠ¥"



def generate_fast_grid(trend_tf: str, max_mdd: float = 20.0) -> Dict:
    """
    ë¹ ë¥¸ íƒìƒ‰ìš© ì¶•ì†Œ Grid ìƒì„±
    - INDICATOR_RANGEì—ì„œ ì„±ê¸´(Sparse) í˜•íƒœë¡œ ìƒ˜í”Œë§
    
    Args:
        trend_tf: ì¶”ì„¸ íƒ€ì„í”„ë ˆì„
        max_mdd: ìµœëŒ€ í—ˆìš© MDD (%)
    
    Returns:
        ì¶•ì†Œëœ íŒŒë¼ë¯¸í„° grid dict
    """
    tf_range = TF_AUTO_RANGE.get(trend_tf, TF_AUTO_RANGE['1h'])
    
    # INDICATOR_RANGEì—ì„œ ì§•ê²€ë‹¤ë¦¬ì‹ìœ¼ë¡œ ì„ íƒ (ë°ì´í„° ìˆ˜ ëŒ€í­ ê°ì†Œ)
    grid = {
        'trend_interval': [trend_tf],
        'filter_tf': [tf_range['filter_tf'][0]],      # ìµœì  í›„ë³´ 1ê°œ
        'entry_tf': [tf_range['entry_tf'][0]],        # ìµœì  í›„ë³´ 1ê°œ
        'leverage': [3, 10],                          # 2ë‹¨ê³„ ìƒëµ
        'direction': ['Both'],                         # ê¸°ë³¸ ë°©í–¥
        'max_mdd': [max_mdd],
        'atr_mult': [1.25, 1.35, 1.5],                 # [MOD] ë³´ìˆ˜ì  ë²”ìœ„ë¡œ ì œí•œ
        'trail_start_r': INDICATOR_RANGE['trail_start_r'][::3], # [0.5, 0.8, 1.1]
        'trail_dist_r': INDICATOR_RANGE['trail_dist_r'][::3],   # [0.1, 0.25, 0.4]
    }
    
    return grid


def estimate_combinations(grid: Dict) -> tuple:
    """
    íŒŒë¼ë¯¸í„° ì¡°í•© ìˆ˜ ë° ì˜ˆìƒ ì‹œê°„ ê³„ì‚°
    
    Args:
        grid: íŒŒë¼ë¯¸í„° grid dict
    
    Returns:
        (ì¡°í•©ìˆ˜, ì˜ˆìƒì‹œê°„ë¶„)
    """
    total = 1
    for key, values in grid.items():
        if isinstance(values, list):
            total *= len(values)
    
    # ë°±í…ŒìŠ¤íŠ¸ 1íšŒë‹¹ ì•½ 0.05ì´ˆ ê°€ì •
    estimated_seconds = total * 0.05
    estimated_minutes = estimated_seconds / 60
    
    return (total, round(estimated_minutes, 1))


@dataclass
class OptimizationResult:
    """
    ìµœì í™” ê²°ê³¼ ë°ì´í„°
    
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    ğŸ“Š ì§€í‘œë³„ ì˜í–¥ ê´€ê³„ (METRICS IMPACT REFERENCE)
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    [ì…ë ¥ íŒŒë¼ë¯¸í„°] â†’ [ì˜í–¥ ì§€í‘œ]
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    â€¢ atr_mult (ATR ë°°ìˆ˜)
      â†’ max_drawdown: ATRâ†‘ = ë„“ì€ SL = MDDâ†‘
      â†’ win_rate: ATRâ†‘ = ì—¬ìœ ìˆëŠ” SL = ìŠ¹ë¥ â†‘ (ì¡°ê¸° ì²­ì‚° ë°©ì§€)
      â†’ trades: ì˜í–¥ ì ìŒ
    
    â€¢ trail_start_r (íŠ¸ë ˆì¼ë§ ì‹œì‘ Rë°°ìˆ˜)
      â†’ simple_return/compound_return: ì‹œì‘â†‘ = ë” ë§ì´ ìˆ˜ìµ í™•ë³´ í›„ íŠ¸ë ˆì¼ë§
      â†’ win_rate: ì‹œì‘â†‘ = ìµì ˆ í™•ë¥ â†‘
      â†’ max_drawdown: ê°„ì ‘ ì˜í–¥
    
    â€¢ trail_dist_r (íŠ¸ë ˆì¼ë§ ê±°ë¦¬ Rë°°ìˆ˜)
      â†’ max_drawdown: ê±°ë¦¬â†‘ = ì²­ì‚° ëŠ¦ìŒ = MDDâ†‘
      â†’ simple_return: ê±°ë¦¬â†‘ = ìˆ˜ìµ ë” ì¶”êµ¬ = ìˆ˜ìµâ†‘ or ë°˜ë‚©
    
    â€¢ leverage (ë ˆë²„ë¦¬ì§€)
      â†’ simple_return/compound_return: ë ˆë²„ë¦¬ì§€â†‘ = ìˆ˜ìµë¥ â†‘ (ë¹„ë¡€)
      â†’ max_drawdown: ë ˆë²„ë¦¬ì§€â†‘ = MDDâ†‘ (ë¹„ë¡€)
      â†’ sharpe_ratio: ë³€ë™ì„±â†‘ = ìƒ¤í”„â†“
    
    â€¢ direction (ë°©í–¥: Long/Short/Both)
      â†’ trades: Both = ê±°ë˜â†‘â†‘
      â†’ win_rate: ì‹œì¥ ìƒí™©ì— ë”°ë¼ ë³€ë™
    
    â€¢ filter_tf (í•„í„° íƒ€ì„í”„ë ˆì„)
      â†’ win_rate: ìƒìœ„TF í•„í„° = ì‹ í˜¸ í’ˆì§ˆâ†‘ = ìŠ¹ë¥ â†‘
      â†’ trades: ì—„ê²©í•œ í•„í„° = ê±°ë˜â†“
    
    â€¢ entry_tf (ì§„ì… íƒ€ì„í”„ë ˆì„)
      â†’ trades: ì‘ì€TF = ê¸°íšŒâ†‘ = ê±°ë˜â†‘
      â†’ win_rate: íƒ€ì´ë° ì •í™•ë„ì— ì˜í–¥
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    
    [ì§€í‘œ ê³„ì‚° ìœ„ì¹˜]
    â€¢ win_rate: _calculate_metrics() â†’ (ìˆ˜ìµê±°ë˜/ì „ì²´ê±°ë˜) Ã— 100
    â€¢ max_drawdown: _calculate_metrics() â†’ ìµœê³ ì  ëŒ€ë¹„ ìµœëŒ€ í•˜ë½í­
    â€¢ sharpe_ratio: _calculate_metrics() â†’ (í‰ê· ìˆ˜ìµ/í‘œì¤€í¸ì°¨) Ã— âˆš252
    â€¢ simple_return: _calculate_metrics() â†’ Î£(ê° ê±°ë˜ ìˆ˜ìµë¥ )
    â€¢ compound_return: _calculate_metrics() â†’ Î (1+ìˆ˜ìµë¥ ) - 1
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """
    params: Dict                          # ì‚¬ìš©ëœ íŒŒë¼ë¯¸í„°
    trades: int                           # ë§¤ë§¤ íšŸìˆ˜ â†’ direction, filter_tf, entry_tf ì˜í–¥
    win_rate: float                       # ìŠ¹ë¥ (%) â†’ atr_mult, filter_tf ì˜í–¥
    total_return: float                   # [DEPRECATED] simple_return ë˜ëŠ” compound_return ì‚¬ìš©
    simple_return: float = 0.0            # ë‹¨ë¦¬ ìˆ˜ìµë¥  â†’ leverage, trail_* ì˜í–¥
    compound_return: float = 0.0          # ë³µë¦¬ ìˆ˜ìµë¥  â†’ leverage, trail_* ì˜í–¥
    max_drawdown: float = 0.0             # MDD(%) â†’ atr_mult, leverage, trail_dist_r ì˜í–¥
    sharpe_ratio: float = 0.0             # ìƒ¤í”„ë¹„ìœ¨ â†’ leverage ì˜í–¥ (ë³€ë™ì„±)
    profit_factor: float = 0.0            # ìˆ˜ìµíŒ©í„° â†’ ì „ì²´ì  íŒŒë¼ë¯¸í„° ì˜í–¥
    avg_trades_per_day: float = 0.0       # ì¼í‰ê·  ê±°ë˜ìˆ˜
    stability: str = "âš ï¸"                 # 3êµ¬ê°„ ì•ˆì •ì„± ì§€í‘œ
    strategy_type: str = ""               # ì „ëµ ìœ í˜• (ğŸ”¥ê³µê²©, âš–ê· í˜•, ğŸ›¡ë³´ìˆ˜)
    grade: str = ""                       # ë“±ê¸‰ (S/A/B/C)
    capital_mode: str = "compound"        # ìë³¸ ëª¨ë“œ
    avg_pnl: float = 0.0                  # [NEW] í‰ê·  PnL (%)
    cagr: float = 0.0                     # [NEW] ì—°ê°„ ë³µë¦¬ ìˆ˜ìµë¥  (%)
    passes_filter: bool = True            # [NEW] í•„í„° í†µê³¼ ì—¬ë¶€ (MDD, ìŠ¹ë¥ , ê±°ë˜ìˆ˜)
    symbol: str = ""                      # [NEW] ì‹¬ë³¼ (ë°±í…ŒìŠ¤íŠ¸ìš©)
    timeframe: str = ""                   # [NEW] íƒ€ì„í”„ë ˆì„ (ë°±í…ŒìŠ¤íŠ¸ìš©)
    final_capital: float = 0.0            # [NEW] ìµœì¢… ìë³¸ (ë°±í…ŒìŠ¤íŠ¸ìš©)
    backtest_start_time: Optional[pd.Timestamp] = None  # [NEW] ë°±í…ŒìŠ¤íŠ¸ ì‹œì‘ ì‹œê°„ (v7.22)
    backtest_end_time: Optional[pd.Timestamp] = None    # [NEW] ë°±í…ŒìŠ¤íŠ¸ ì¢…ë£Œ ì‹œê°„ (v7.22)
    backtest_duration_days: int = 0       # [NEW] ë°±í…ŒìŠ¤íŠ¸ ê¸°ê°„ (ì¼) (v7.22)


# calculate_grade() í•¨ìˆ˜ ì œê±° (utils.metrics.assign_grade_by_preset()ë¡œ ëŒ€ì²´)
# ì´ì „ ìœ„ì¹˜: ë¼ì¸ 376-393
# ìƒˆë¡œìš´ ë“±ê¸‰ ì‹œìŠ¤í…œì€ í”„ë¦¬ì…‹ë³„ ëª©í‘œ ê¸°ì¤€ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.


def extract_timestamps_from_trades(trades: List[Dict]) -> tuple[Optional[pd.Timestamp], Optional[pd.Timestamp], int]:
    """ê±°ë˜ ë¦¬ìŠ¤íŠ¸ì—ì„œ íƒ€ì„ìŠ¤íƒ¬í”„ ì¶”ì¶œ

    Args:
        trades: ë°±í…ŒìŠ¤íŠ¸ ê±°ë˜ ë¦¬ìŠ¤íŠ¸

    Returns:
        (start_time, end_time, duration_days)
        - start_time: ì²« ê±°ë˜ ì§„ì… ì‹œê°„
        - end_time: ë§ˆì§€ë§‰ ê±°ë˜ ì²­ì‚° ì‹œê°„
        - duration_days: ë°±í…ŒìŠ¤íŠ¸ ê¸°ê°„ (ì¼)

    Example:
        >>> trades = [{'entry_time': '2024-01-01', 'exit_time': '2024-01-02'}, ...]
        >>> start, end, days = extract_timestamps_from_trades(trades)
        >>> print(f"Period: {start} ~ {end} ({days} days)")
    """
    if not trades or len(trades) == 0:
        return None, None, 0

    try:
        # ì²« ê±°ë˜ ì§„ì… ì‹œê°„
        start_time = pd.to_datetime(trades[0]['entry_time'])

        # ë§ˆì§€ë§‰ ê±°ë˜ ì²­ì‚° ì‹œê°„
        end_time = pd.to_datetime(trades[-1]['exit_time'])

        # ê¸°ê°„ ê³„ì‚° (ì¼)
        duration = (end_time - start_time).days

        return start_time, end_time, duration

    except (KeyError, ValueError, TypeError) as e:
        logger.debug(f"Failed to extract timestamps: {e}")
        return None, None, 0


def _worker_run_single(strategy_class, params, df_pattern, df_entry, slippage, fee):
    """ë©€í‹°í”„ë¡œì„¸ì‹± ì§€ì›ì„ ìœ„í•œ ë…ë¦½í˜• ì›Œì»¤ í•¨ìˆ˜"""
    try:
        # ë°©í–¥ ì²˜ë¦¬
        leverage = params.get('leverage', 3)
        if isinstance(leverage, list): leverage = leverage[0]
        leverage = int(leverage)
        
        direction = params.get('direction', 'Both')
        if isinstance(direction, list): direction = direction[0]
        
        filter_tf = params.get('filter_tf', '4h')
        if isinstance(filter_tf, list): filter_tf = filter_tf[0]
        
        # ì „ëµ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
        # AlphaX7CoreëŠ” use_mtf=True, strategy_type íŒŒë¼ë¯¸í„° í•„ìš”
        use_mtf = params.get('use_mtf', True)  # ê¸°ë³¸ê°’ True
        strategy_type = params.get('strategy_type', 'macd')  # ê¸°ë³¸ê°’ 'macd'
        try:
            strategy = strategy_class(use_mtf=use_mtf, strategy_type=strategy_type)
        except TypeError:
            # use_mtf/strategy_type íŒŒë¼ë¯¸í„°ê°€ ì—†ëŠ” ì „ëµ í´ë˜ìŠ¤
            try:
                strategy = strategy_class(use_mtf=use_mtf)
            except TypeError:
                strategy = strategy_class()
        
        # ì´ ë¹„ìš©
        total_cost = slippage + fee
        
        # ë°±í…ŒìŠ¤íŠ¸ ì‹¤í–‰ (íŒŒë¼ë¯¸í„°í™” ì™„ë£Œ)
        trades = strategy.run_backtest(
            df_pattern=df_pattern,
            df_entry=df_entry,
            slippage=total_cost,
            atr_mult=params.get('atr_mult', DEFAULT_PARAMS.get('atr_mult', 1.5)),
            trail_start_r=params.get('trail_start_r', DEFAULT_PARAMS.get('trail_start_r', 0.8)),
            trail_dist_r=params.get('trail_dist_r', DEFAULT_PARAMS.get('trail_dist_r', 0.5)),
            pattern_tolerance=params.get('pattern_tolerance', DEFAULT_PARAMS.get('pattern_tolerance', 0.03)),
            entry_validity_hours=params.get('entry_validity_hours', DEFAULT_PARAMS.get('entry_validity_hours', 12.0)),
            pullback_rsi_long=params.get('pullback_rsi_long', DEFAULT_PARAMS.get('pullback_rsi_long', 35)),
            pullback_rsi_short=params.get('pullback_rsi_short', DEFAULT_PARAMS.get('pullback_rsi_short', 65)),
            max_adds=params.get('max_adds', DEFAULT_PARAMS.get('max_adds', 1)),
            filter_tf=filter_tf,
            rsi_period=params.get('rsi_period', DEFAULT_PARAMS.get('rsi_period', 14)),
            atr_period=params.get('atr_period', DEFAULT_PARAMS.get('atr_period', 14)),
            macd_fast=params.get('macd_fast', DEFAULT_PARAMS.get('macd_fast', 12)),
            macd_slow=params.get('macd_slow', DEFAULT_PARAMS.get('macd_slow', 26)),
            macd_signal=params.get('macd_signal', DEFAULT_PARAMS.get('macd_signal', 9)),
            ema_period=params.get('ema_period', DEFAULT_PARAMS.get('ema_period', 20)),
            enable_pullback=params.get('enable_pullback', False)
        )

        
        if not trades:
            return None
            
        min_trades = params.get('min_trades', 1)
        if len(trades) < min_trades:
            return None
            
        # ë°©í–¥ í•„í„°ë§
        if direction != 'Both':
            trades = [t for t in trades if t['type'] == direction]
            if len(trades) < min_trades: return None
            
        # ë ˆë²„ë¦¬ì§€ ì ìš©
        for t in trades:
            t['pnl'] = t['pnl'] * leverage
            
        # ë©”íŠ¸ë¦­ ê³„ì‚° (ê³µìš© ì •ì  ë©”ì„œë“œ í˜¸ì¶œ)
        metrics = BacktestOptimizer.calculate_metrics(trades)

        # MDD í•„í„°
        max_mdd_limit = params.get('max_mdd', 100.0)
        if max_mdd_limit < 100.0 and abs(metrics['max_drawdown']) > max_mdd_limit:
            return None

        # ë“±ê¸‰ í• ë‹¹ (strategy_typeì€ ë‚˜ì¤‘ì— _classify_results()ì—ì„œ í• ë‹¹)
        # ì—¬ê¸°ì„œëŠ” ê· í˜•í˜• ê¸°ì¤€ìœ¼ë¡œ ì„ì‹œ ë“±ê¸‰ ë¶€ì—¬
        grade = assign_grade_by_preset(
            preset_type='balanced',
            metrics={
                'win_rate': metrics['win_rate'],
                'profit_factor': metrics['profit_factor'],
                'mdd': metrics['max_drawdown'],
                'sharpe_ratio': metrics['sharpe_ratio'],
                'compound_return': metrics['compound_return']
            }
        )

        # [NEW] íƒ€ì„ìŠ¤íƒ¬í”„ ì¶”ì¶œ (v7.22)
        start_time, end_time, duration_days = extract_timestamps_from_trades(trades)

        return OptimizationResult(
            params=params,
            trades=len(trades),
            win_rate=metrics['win_rate'],
            total_return=metrics['total_return'],
            simple_return=metrics['simple_return'],
            compound_return=metrics['compound_return'],
            max_drawdown=metrics['max_drawdown'],
            sharpe_ratio=metrics['sharpe_ratio'],
            profit_factor=metrics['profit_factor'],
            avg_trades_per_day=metrics.get('avg_trades_per_day', 0.0),
            stability=metrics.get('stability', "âš ï¸"),
            grade=grade,
            avg_pnl=metrics.get('avg_pnl', 0.0),
            cagr=metrics.get('cagr', 0.0),
            backtest_start_time=start_time,      # [NEW] v7.22
            backtest_end_time=end_time,          # [NEW] v7.22
            backtest_duration_days=duration_days  # [NEW] v7.22
        )
    except Exception as e:
        # ë””ë²„ê¹…: ì˜ˆì™¸ ë¡œê¹…
        import traceback
        logger.debug(f"Worker failed: {e}")
        logger.debug(traceback.format_exc())
        return None



    # _calculate_metrics_standalone removed and unified inside BacktestOptimizer



class BacktestOptimizer:
    """íŒŒë¼ë¯¸í„° ê·¸ë¦¬ë“œ ì„œì¹˜ ìµœì í™”"""
    
    # TF ë§¤í•‘ì€ ìƒë‹¨ì—ì„œ importí•œ TF_MAPPING ì‚¬ìš©
    
    def __init__(
        self,
        strategy_class,
        df: Optional[pd.DataFrame] = None,
        strategy_type: str = 'macd',
        exchange: str = 'bybit'
    ):
        """
        Args:
            strategy_class: X7PlusStrategy ë“± ì „ëµ í´ë˜ìŠ¤
            df: ë°±í…ŒìŠ¤íŠ¸ìš© ë°ì´í„°í”„ë ˆì„
            strategy_type: ì „ëµ ìœ í˜• ('macd' or 'adx')
            exchange: ê±°ë˜ì†Œëª… (v7.23 ì¶”ê°€, ìˆ˜ìˆ˜ë£Œ ê¸°ë°˜ ë²”ìœ„ ìë™ ì¡°ì •)
        """
        self.strategy_class = strategy_class
        self.df = df
        self.strategy_type = strategy_type
        self.exchange = exchange  # v7.23: ê±°ë˜ì†Œë³„ ìµœì í™”
        self.results: List[OptimizationResult] = []
        self.progress_callback: Optional[Callable] = None
        self.cancelled = False
    
    def set_data(self, df: pd.DataFrame) -> None:
        """ë°ì´í„° ì„¤ì •"""
        self.df = df
    
    def set_progress_callback(self, callback: Optional[Callable]) -> None:
        """ì§„í–‰ë¥  ì½œë°± ì„¤ì •"""
        self.progress_callback = callback
    
    def cancel(self) -> None:
        """ìµœì í™” ì·¨ì†Œ"""
        self.cancelled = True
        
    def _resample(self, df: pd.DataFrame, target_tf: str, quiet: bool = False) -> pd.DataFrame:
        """15m â†’ Target TF ë¦¬ìƒ˜í”Œë§ (ê³µìš© í•¨ìˆ˜ ì‚¬ìš©)"""
        # [FIX v7.26] ë™ì¼ íƒ€ì„í”„ë ˆì„ì´ë©´ ë¦¬ìƒ˜í”Œë§ ê±´ë„ˆë›°ê¸°
        # DataFrameì´ ì´ë¯¸ target_tfì¸ì§€ í™•ì¸ (ìº”ë“¤ ìˆ˜ë¡œ ì¶”ì •)
        if len(df) <= 55000:  # 1h ì´ìƒ íƒ€ì„í”„ë ˆì„ (15mì´ë©´ 203,823ê°œ)
            if not quiet:
                logger.info(f"[OPT] ë¦¬ìƒ˜í”Œë§ ê±´ë„ˆë›°ê¸°: ì´ë¯¸ {target_tf} ë°ì´í„° ({len(df)}ê°œ)")
            # ì§€í‘œë§Œ ì¶”ê°€
            if 'rsi' not in df.columns:
                from utils.indicators import add_all_indicators
                df = add_all_indicators(df.copy())
            return df

        # ê³µìš© utils.data_utils.resample_data ì‚¬ìš©
        if shared_resample:
            return shared_resample(df, target_tf, add_indicators=True)
        
        # Fallback: ë¡œì»¬ êµ¬í˜„
        rule = TF_RESAMPLE_MAP.get(target_tf, target_tf)
        df = df.copy()
        if 'datetime' not in df.columns:
            if pd.api.types.is_numeric_dtype(df['timestamp']):
                df['datetime'] = pd.to_datetime(df['timestamp'], unit='ms', utc=True)
            else:
                df['datetime'] = pd.to_datetime(df['timestamp'])
        df = df.set_index('datetime')
        resampled = df.resample(rule).agg({
            'timestamp': 'first', 'open': 'first', 'high': 'max',
            'low': 'min', 'close': 'last', 'volume': 'sum'
        }).dropna().reset_index()
        try:
            from utils.indicators import IndicatorGenerator
            resampled = IndicatorGenerator.add_all_indicators(resampled)
            if 'rsi' not in resampled.columns and 'rsi_14' in resampled.columns:
                resampled['rsi'] = resampled['rsi_14']
            if 'atr' not in resampled.columns and 'atr_14' in resampled.columns:
                resampled['atr'] = resampled['atr_14']
        except Exception as e:
            if not quiet: logger.info(f"âš ï¸ ì§€í‘œ ì¬ê³„ì‚° ì‹¤íŒ¨: {e}")
        if not quiet: logger.info(f"ğŸ“Š [OPT] ì§€í‘œ ì¬ê³„ì‚°: {target_tf} ({len(resampled)}ìº”ë“¤)")
        return resampled
    
    def run_optimization(self, df: Optional[pd.DataFrame], grid: Dict, max_workers: int = 4,
                         metric: str = 'WinRate', task_callback: Optional[Callable] = None,
                         capital_mode: str = 'compound', n_cores: Optional[int] = None,
                         mode: str = 'standard', skip_filter: bool = False,
                         progress_callback: Optional[Callable[[int, int], None]] = None) -> List[OptimizationResult]:
        """
        ê·¸ë¦¬ë“œ ì„œì¹˜ ìµœì í™” ì‹¤í–‰
        
        Args:
            df: ë°±í…ŒìŠ¤íŠ¸ìš© ë°ì´í„°í”„ë ˆì„
            grid: íŒŒë¼ë¯¸í„° ê·¸ë¦¬ë“œ
            max_workers: ìµœëŒ€ ì›Œì»¤ ìˆ˜ (deprecated, n_cores ì‚¬ìš©)
            metric: ì •ë ¬ ê¸°ì¤€ ë©”íŠ¸ë¦­
            task_callback: ì‘ì—… ì½œë°±
            capital_mode: ìë³¸ ëª¨ë“œ ('simple' or 'compound')
            n_cores: CPU ì½”ì–´ ìˆ˜
            mode: ìµœì í™” ëª¨ë“œ ('quick'=1ê°œ, 'standard'=3ê°œ, 'deep'=5ê°œ+)
        
        Returns:
            ìµœì í™” ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        """
        self.df = df
        self.results = []
        self.cancelled = False
        self.capital_mode = capital_mode.lower()
        if self.df is None or self.df.empty:
            raise ValueError("ë°ì´í„°ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
        
        # âœ… v7.28: ì €ì‚¬ì–‘ PC ìµœì í™” - ë¶ˆí•„ìš”í•œ ë³µì‚¬ ì œê±°
        # df ë³µì‚¬ ëŒ€ì‹  inplace ë³€í™˜ (ë©”ëª¨ë¦¬ ì ˆì•½)
        if not pd.api.types.is_datetime64_any_dtype(self.df['timestamp']):
            first_ts = self.df['timestamp'].iloc[0]
            if isinstance(first_ts, (int, float, np.number)) and first_ts > 100000000000:
                self.df['timestamp'] = pd.to_datetime(self.df['timestamp'], unit='ms', utc=True)
            else:
                self.df['timestamp'] = pd.to_datetime(self.df['timestamp'])
        df = self.df  # ì°¸ì¡°ë§Œ ìœ ì§€ (ë³µì‚¬ ì•ˆ í•¨)

        self.cancelled = False
        self.results = []
        
        # ë¦¬ìƒ˜í”Œë§ ìºì‹œ ì´ˆê¸°í™”
        self._resample_cache = {}
        
        # ëª¨ë“  íŒŒë¼ë¯¸í„° ì¡°í•© ìƒì„±
        keys = list(grid.keys())
        values = list(grid.values())
        combinations = list(itertools.product(*values))
        total = len(combinations)
        
        # [NEW] n_cores ì²˜ë¦¬
        if n_cores is None:
            import multiprocessing
            n_cores = multiprocessing.cpu_count()
        
        # [NEW] ì§€í‘œ ì„ í–‰ ê³„ì‚° (ThreadPool ê²½í•© ë°©ì§€)
        all_trend_tfs = set(grid.get('trend_interval', []))
        all_entry_tfs = set(grid.get('entry_tf', []))
        
        for tf in all_trend_tfs:
            key = f"p_{tf}"
            if key not in self._resample_cache:
                self._resample_cache[key] = self._resample(df, tf)
                
        for tf in all_entry_tfs:
            key = f"e_{tf}"
            if key not in self._resample_cache:
                if tf and tf not in ['15min', '15m']:
                    self._resample_cache[key] = self._resample(df, tf)
                else:
                    self._resample_cache[key] = df.copy()
        
        logger.info(f"Optimization started: {total} combinations, {n_cores} cores (ProcessPool)")
        
        # ë³‘ë ¬ ì²˜ë¦¬ (ProcessPoolExecutor)
        from concurrent.futures import ProcessPoolExecutor, as_completed
        
        with ProcessPoolExecutor(max_workers=n_cores) as executor:
            # TFë³„ ë¯¸ë¦¬ ë¦¬ìƒ˜í”Œë§ëœ DFë“¤ì„ ë§µìœ¼ë¡œ ì¤€ë¹„
            # (ë©€í‹°í”„ë¡œì„¸ì‹± ì‹œ íŒŒë¼ë¯¸í„°ë¡œ ë§¤ë²ˆ DFë¥¼ í†µì§¸ë¡œ ì „ë‹¬í•˜ë©´ ì˜¤ë²„í—¤ë“œê°€ í¬ì§€ë§Œ, 
            #  ì—¬ê¸°ì„œëŠ” pickleë¡œ ì „ë‹¬ë¨)
            
            futures = []
            for combo in combinations:
                params = dict(zip(keys, combo))

                # strategy_type ì¶”ê°€ (v7.22.1)
                params['strategy_type'] = self.strategy_type

                # í•´ë‹¹ ì¡°í•©ì— ë§ëŠ” cached df ì¶”ì¶œ
                trend_tf = params.get('trend_interval', '4h')
                if isinstance(trend_tf, list): trend_tf = trend_tf[0]
                entry_tf = params.get('entry_tf')
                if isinstance(entry_tf, list): entry_tf = entry_tf[0]
                if not entry_tf:
                    # [FIX v7.26] DEFAULT_PARAMSì—ì„œ entry_tf ê°€ì ¸ì˜¤ê¸° (15m â†’ 1h)
                    entry_tf = DEFAULT_PARAMS.get('entry_tf', '15m')
                
                df_pattern = self._resample_cache.get(f"p_{trend_tf}")
                df_entry = self._resample_cache.get(f"e_{entry_tf}")

                # [FIX] ìºì‹œ miss ì‹œ ë™ì  ë¦¬ìƒ˜í”Œë§ (v7.22)
                if df_pattern is None:
                    df_pattern = self._resample(df, trend_tf, quiet=True)
                    self._resample_cache[f"p_{trend_tf}"] = df_pattern

                if df_entry is None:
                    if entry_tf and entry_tf not in ['15min', '15m']:
                        df_entry = self._resample(df, entry_tf, quiet=True)
                    else:
                        df_entry = df.copy()
                    self._resample_cache[f"e_{entry_tf}"] = df_entry

                # íŒŒë¼ë¯¸í„°ì—ì„œ ê°’ ì¶”ì¶œ
                _symbol = params.get('symbol', 'BTCUSDT')
                _leverage = params.get('leverage', 3)
                if isinstance(_leverage, list): _leverage = _leverage[0]
                _slippage = params.get('slippage', DEFAULT_PARAMS['slippage'])
                _fee = params.get('fee', DEFAULT_PARAMS['fee'])

                futures.append(executor.submit(
                    _worker_run_single,
                    self.strategy_class,
                    params,
                    df_pattern,
                    df_entry,
                    _slippage,
                    _fee
                ))
            
            completed = 0
            for i, future in enumerate(as_completed(futures)):
                if self.cancelled:
                    logger.info("âŒ ìµœì í™” ì·¨ì†Œë¨")
                    executor.shutdown(wait=False, cancel_futures=True)
                    break

                completed += 1

                # ì§„í–‰ë¥  ì½œë°± í˜¸ì¶œ (v7.26.2)
                if progress_callback:
                    progress_callback(completed, total)

                try:
                    # íƒ€ì„ì•„ì›ƒ 10ì´ˆ ì„¤ì • (Deep ëª¨ë“œ ëŒ€ì‘)
                    result = future.result(timeout=10)

                    # [DEBUG] None ë°˜í™˜ ë¡œê·¸ ì¶”ê°€
                    if result is None:
                        # logger.debug(f"Worker returned None (likely 0 trades or filtered out)")
                        pass

                    if result:
                        # === í•„í„°ë§ ì¡°ê±´ (v3.0 - SSOT ê¸°ë°˜ ì‚¬ìš©ì ëª©í‘œ) ===
                        # ì „ëµ: ê³ í’ˆì§ˆ ê²°ê³¼ë§Œ ìˆ˜ì§‘ â†’ ì •ë ¬ë¡œ ìµœì  ì¡°í•© ì°¾ê¸°
                        # SSOT: config.parameters.OPTIMIZATION_FILTER
                        # 1. ìŠ¹ë¥  â‰¥ 80%
                        # 2. MDD â‰¤ 20%
                        # 3. ì „ì²´ ë‹¨ë¦¬ ìˆ˜ìµë¥  â‰¥ 0.5%
                        # 4. ì¼í‰ê·  ê±°ë˜ ë¹ˆë„ â‰¥ 0.5íšŒ/ì¼
                        # 5. ì ˆëŒ€ ìµœì†Œ ê±°ë˜ìˆ˜ â‰¥ 10ê°œ
                        from config.parameters import OPTIMIZATION_FILTER

                        # ê±°ë˜ ë¹ˆë„ ê³„ì‚° (avg_trades_per_dayëŠ” ì´ë¯¸ resultì— ìˆìŒ)
                        avg_trades_per_day = result.avg_trades_per_day

                        # v7.22: skip_filter í”Œë˜ê·¸ ì²´í¬
                        if skip_filter:
                            # Coarse Grid: í•„í„° ìš°íšŒ, ëª¨ë“  ê²°ê³¼ ìˆ˜ì§‘
                            self.results.append(result)
                            if task_callback:
                                task_callback(result)
                        else:
                            # í‘œì¤€ í•„í„° ì ìš©
                            passes_filter = (
                                result.win_rate >= OPTIMIZATION_FILTER['min_win_rate'] and
                                abs(result.max_drawdown) <= OPTIMIZATION_FILTER['max_mdd'] and
                                result.simple_return >= OPTIMIZATION_FILTER['min_total_return'] and
                                avg_trades_per_day >= OPTIMIZATION_FILTER['min_trades_per_day'] and
                                result.trades >= OPTIMIZATION_FILTER['min_absolute_trades']
                            )

                            if passes_filter:
                                self.results.append(result)
                                if task_callback:
                                    task_callback(result)
                except Exception as e:
                    # í”„ë¡œì„¸ìŠ¤ ì˜¤ë¥˜ ë¡œê·¸
                    pass
                
                # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
                if self.progress_callback:
                    progress = int((i + 1) / total * 100)
                    self.progress_callback(progress)
        
        # ê²°ê³¼ ì •ë ¬ ë° ìƒì„¸ ë¶„ë¥˜ (v2)
        if self.results:
            # 1. ì§€ì •ëœ ë©”íŠ¸ë¦­ìœ¼ë¡œ ì „ì²´ ì •ë ¬
            self.results.sort(key=lambda x: getattr(x, metric, 0), reverse=True)

            # 2. [NEW] v7.22: Coarse ëª¨ë“œëŠ” ë¶„ë¥˜ ê±´ë„ˆë›°ê¸° (ëª¨ë“  ê²°ê³¼ ë°˜í™˜)
            if mode == 'coarse':
                logger.info(f"âš ï¸ [Coarse Mode] Skipping classification, returning all results")
                # ìƒìœ„ 500ê°œë¡œ ì œí•œ (ë©”ëª¨ë¦¬ ê´€ë¦¬)
                self.results = self.results[:500]
            else:
                # 2. [NEW] ëŒ€í‘œ ìœ í˜• ë§¤ì¹­ (ì›ë³¸ ë¦¬ìŠ¤íŠ¸ëŠ” ìœ ì§€í•˜ê³  íƒœê¹…ë§Œ ìˆ˜í–‰)
                # ìƒìœ„ 1000ê°œ ê²°ê³¼ ì¤‘ ì¤‘ë³µ ì—†ëŠ” ëŒ€í‘œ ìœ í˜•ë“¤ ì„ ì •
                top_results = self.results[:1000]
                unique_for_classification = self.filter_unique_results(top_results, max_count=100)
                representatives = self._classify_results(unique_for_classification, mode=mode)

                # ëŒ€í‘œ ìœ í˜•ë“¤ì„ self.results ìƒë‹¨ì— ë°°ì¹˜í•˜ê³  ë‚˜ë¨¸ì§€ëŠ” ìˆœì„œ ìœ ì§€
                rep_keys = [str(r.params) for r in representatives]
                final_list = representatives + [r for r in self.results if str(r.params) not in rep_keys]

                self.results = final_list[:2000] # ë©”ëª¨ë¦¬ ê´€ë¦¬ë¥¼ ìœ„í•´ ìƒìœ„ 2000ê°œë¡œ ì œí•œ


        # ë¦¬ìƒ˜í”Œë§ ìºì‹œ ì •ë¦¬ (ë©”ëª¨ë¦¬ í•´ì œ)
        self._resample_cache = {}

        logger.info(f"âœ… ìµœì í™” ì™„ë£Œ: {len(self.results)}ê°œ ê²°ê³¼ ë°˜í™˜")
        return self.results

    def save_results_to_csv(
        self,
        exchange: str,
        symbol: str,
        timeframe: str,
        mode: str = 'deep',
        output_dir: str = 'data/optimization_results'
    ) -> str:
        """
        ìµœì í™” ê²°ê³¼ë¥¼ CSVë¡œ ì €ì¥

        Args:
            exchange: ê±°ë˜ì†Œ
            symbol: ì‹¬ë³¼
            timeframe: íƒ€ì„í”„ë ˆì„
            mode: ìµœì í™” ëª¨ë“œ
            output_dir: ì¶œë ¥ ë””ë ‰í† ë¦¬

        Returns:
            ì €ì¥ëœ CSV íŒŒì¼ ê²½ë¡œ
        """
        from datetime import datetime

        if not self.results:
            raise ValueError("ì €ì¥í•  ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤")

        # 1. DataFrame ìƒì„±
        rows = []
        for rank, result in enumerate(self.results, 1):
            row = {
                'rank': rank,
                'score': result.profit_factor * (result.win_rate / 100) if result.win_rate else 0,
                'win_rate': result.win_rate,
                'profit_factor': result.profit_factor,
                'mdd': result.max_drawdown,
                'sharpe': result.sharpe_ratio,
                'sortino': getattr(result, 'sortino_ratio', 0),
                'calmar': getattr(result, 'calmar_ratio', 0),
                'trades': result.trades,
                'total_return': result.simple_return,
                **result.params  # ëª¨ë“  íŒŒë¼ë¯¸í„° ì»¬ëŸ¼ìœ¼ë¡œ ì¶”ê°€
            }
            rows.append(row)

        df = pd.DataFrame(rows)

        # 2. íŒŒì¼ëª… ìƒì„±
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        filename = f"{exchange}_{symbol}_{timeframe}_{mode}_{timestamp}.csv"

        # 3. ì €ì¥
        output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)
        csv_path = output_path / filename

        df.to_csv(csv_path, index=False, encoding='utf-8')

        logger.info(f"CSV ì €ì¥ ì™„ë£Œ: {csv_path} ({len(df)} rows)")
        return str(csv_path)
    
    def _run_single(self, params: Dict, slippage: float, fee: float) -> Optional[OptimizationResult]:
        """ë‹¨ì¼ íŒŒë¼ë¯¸í„° ì¡°í•©ìœ¼ë¡œ ë°±í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        if self.df is None:
            return None
            
        assert self.df is not None, "self.df cannot be None here"
        
        try:
            # íŒŒë¼ë¯¸í„° ì¶”ì¶œ (ë¦¬ìŠ¤íŠ¸ì¼ ê²½ìš° ë‹¨ì¼ ê°’ìœ¼ë¡œ ë³€í™˜)
            filter_tf = params.get('filter_tf', '4h')
            if isinstance(filter_tf, list): filter_tf = filter_tf[0]
            
            trend_tf = params.get('trend_interval', '1h')
            if isinstance(trend_tf, list): trend_tf = trend_tf[0]
            
            # Entry TF: paramsì— ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ TF_MAPPING
            entry_tf = params.get('entry_tf')
            if isinstance(entry_tf, list): entry_tf = entry_tf[0]
            if not entry_tf:
                entry_tf = TF_MAPPING.get(trend_tf, '15min')
            
            # [NEW] ë¦¬ìƒ˜í”Œë§ ìºì‹œ ì‚¬ìš© (ì„±ëŠ¥ ëŒ€í­ í–¥ìƒ)
            if not hasattr(self, '_resample_cache'): self._resample_cache = {}
            
            # df_pattern ìºì‹œ í‚¤
            p_key = f"p_{trend_tf}"
            if p_key not in self._resample_cache:
                self._resample_cache[p_key] = self._resample(self.df, trend_tf)
            df_pattern = self._resample_cache[p_key]
            
            # df_entry ìºì‹œ í‚¤
            e_key = f"e_{entry_tf}"
            if e_key not in self._resample_cache:
                if entry_tf and entry_tf not in ['15min', '15m']:
                    self._resample_cache[e_key] = self._resample(self.df, entry_tf)
                else:
                    self._resample_cache[e_key] = self.df.copy()
            df_entry = self._resample_cache[e_key]
            
            # ë°°ìœ¨/ë°©í–¥ ì²˜ë¦¬
            leverage = params.get('leverage', 3)
            if isinstance(leverage, list): leverage = leverage[0]
            leverage = int(leverage)
            
            direction = params.get('direction', 'Both')
            if isinstance(direction, list): direction = direction[0]
            
            # ì „ëµ ìƒì„± ì‹œ íŒŒë¼ë¯¸í„° ì „ë‹¬
            init_params = {}
            if 'trend_interval' in params:
               init_params['trend_interval'] = params['trend_interval']
            
            # ê³„ì‚°ëœ entry_intervalë„ ì „ë‹¬ (ì „ëµ ë‚´ë¶€ ë¦¬ìƒ˜í”Œë§ìš©)
            init_params['entry_interval'] = entry_tf
            
            # ì „ëµ ì¸ìŠ¤í„´ìŠ¤ ìƒì„± (Core)
            # strategy_classëŠ” AlphaX7Coreë¼ê³  ê°€ì • (ë˜ëŠ” í˜¸í™˜)
            # AlphaX7CoreëŠ” initì— dfë¥¼ ë°›ì§€ ì•ŠìŒ. stateless.
            try:
                strategy = self.strategy_class()
                # paramsì— 'rsi_period'ê°€ ìˆìœ¼ë©´ ì „ë‹¬í•´ì•¼ í•¨
            except Exception:
                # ë ˆê±°ì‹œ í˜¸í™˜ (í˜¹ì‹œ ë‹¤ë¥¸ ì „ëµì„ ì“¸ ê²½ìš°)
                strategy = self.strategy_class(df=df, **init_params)
                if hasattr(strategy, 'prepare_data'):
                    strategy.prepare_data()
            
            # âœ… ì´ ë¹„ìš© ê³„ì‚° (ìŠ¬ë¦¬í”¼ì§€ + ìˆ˜ìˆ˜ë£Œ)
            # [v7.26] ì§„ì… ë¹„ìš© (Limit/Maker)
            # ì²­ì‚° ë¹„ìš©ì€ strategy_core.pyì—ì„œ BACKTEST_EXIT_COSTë¡œ ìë™ ì°¨ê° (0.065%)
            # ë”°ë¼ì„œ ì—¬ê¸°ì„œëŠ” ì§„ì… ë¹„ìš©ë§Œ ì „ë‹¬ (ê¸°ë³¸: 0.0002 = 0.02%)
            entry_cost = slippage + fee

            # ê¸°ë³¸ íŒŒë¼ë¯¸í„°ì™€ ë³‘í•© (DEFAULT_PARAMS ì°¸ì¡°)
            backtest_params = {
                'slippage': entry_cost,  # DEPRECATED: ëª…ì¹­ í˜¼ë™, ì‹¤ì œë¡œëŠ” ì§„ì… ë¹„ìš©
                'atr_mult': params.get('atr_mult', DEFAULT_PARAMS.get('atr_mult', 1.5)),
                'trail_start_r': params.get('trail_start_r', DEFAULT_PARAMS.get('trail_start_r', 0.8)),
                'trail_dist_r': params.get('trail_dist_r', DEFAULT_PARAMS.get('trail_dist_r', 0.5)),
                'pattern_tolerance': params.get('pattern_tolerance', DEFAULT_PARAMS.get('pattern_tolerance', 0.03)),
                'entry_validity_hours': params.get('entry_validity_hours', DEFAULT_PARAMS.get('entry_validity_hours', 12.0)),
                'pullback_rsi_long': params.get('pullback_rsi_long', DEFAULT_PARAMS.get('pullback_rsi_long', 35)),
                'pullback_rsi_short': params.get('pullback_rsi_short', DEFAULT_PARAMS.get('pullback_rsi_short', 65)),
                'max_adds': params.get('max_adds', DEFAULT_PARAMS.get('max_adds', 1))
            }
            
            # ğŸ“Š ë””ë²„ê¹… ë¡œê·¸
            if params.get('trend_interval') == '1d' and params.get('atr_mult') == 1.5:
                logger.info(f"ğŸ“Š [OPT] entry_cost={entry_cost:.4f}, atr_mult={backtest_params['atr_mult']}, trail_start_r={backtest_params['trail_start_r']}, trail_dist_r={backtest_params['trail_dist_r']}")
            
            # ì „ëµ ì‹¤í–‰ ì‹œ ì „ë‹¬í•  íŒŒë¼ë¯¸í„°
            # X7PlusStrategy.run_backtest_plusì— filter_tf ì „ë‹¬
            backtest_params['filter_tf'] = filter_tf
            
            # ë°±í…ŒìŠ¤íŠ¸ ì‹¤í–‰ (Core Interface)
            if hasattr(strategy, 'run_backtest') and not hasattr(strategy, 'run_backtest_plus'):
                # AlphaX7Core
                trades = strategy.run_backtest(
                    df_pattern=df_pattern,
                    df_entry=df_entry,  # [FIX] ì›ë³¸ 15min ë°ì´í„° ì‚¬ìš©
                    slippage=entry_cost,  # [v7.26] ì§„ì… ë¹„ìš© ì „ë‹¬
                    atr_mult=backtest_params.get('atr_mult'),
                    trail_start_r=backtest_params.get('trail_start_r'),
                    trail_dist_r=backtest_params.get('trail_dist_r'),
                    pattern_tolerance=backtest_params.get('pattern_tolerance'),
                    entry_validity_hours=backtest_params.get('entry_validity_hours'),
                    pullback_rsi_long=backtest_params.get('pullback_rsi_long'),
                    pullback_rsi_short=backtest_params.get('pullback_rsi_short'),
                    max_adds=backtest_params.get('max_adds'),
                    filter_tf=filter_tf,
                    rsi_period=params.get('rsi_period', DEFAULT_PARAMS.get('rsi_period', 14)),
                    atr_period=params.get('atr_period', DEFAULT_PARAMS.get('atr_period', 14)),
                    macd_fast=params.get('macd_fast', DEFAULT_PARAMS.get('macd_fast', 12)),
                    macd_slow=params.get('macd_slow', DEFAULT_PARAMS.get('macd_slow', 26)),
                    macd_signal=params.get('macd_signal', DEFAULT_PARAMS.get('macd_signal', 9)),
                    ema_period=params.get('ema_period', DEFAULT_PARAMS.get('ema_period', 20)),
                    enable_pullback=params.get('enable_pullback', False)  # [NEW] ë¶ˆíƒ€ê¸° ì˜µì…˜
                )

            else:
                # Legacy Strategy
                backtest_params['filter_tf'] = filter_tf
                trades = strategy.run_backtest_plus(**backtest_params)
            
            # [DEBUG] ê±°ë˜ ìˆ˜ í™•ì¸
            # logger.info(f"[DEBUG-OPT] ê±°ë˜ ìˆ˜: {len(trades) if trades else 0}ê°œ")
            
            # [FIX] 10ê°œëŠ” ë„ˆë¬´ ê°€í˜¹í•¨ (ìµœì†Œ ê±°ë˜ìˆ˜ íŒŒë¼ë¯¸í„°í™”)
            min_trades = params.get('min_trades', 3)
            if not trades or len(trades) < min_trades:
                return None
            
            # 1. ë°©í–¥ í•„í„°ë§
            if direction != 'Both':
                trades = [t for t in trades if t['type'] == direction]
                if len(trades) < 3: return None
            
            # [FIX] Option 2: ë ˆë²„ë¦¬ì§€ ìë™ ìµœì í™” (MDD íƒ€ê²Ÿ ë§ì¶¤)
            # 2. ë ˆë²„ë¦¬ì§€ ì ìš© (ê·¸ë¦¬ë“œì— ì„¤ì •ëœ ì •ìˆ˜ ë°°ìœ¨ ì‚¬ìš©)
            max_mdd_limit = params.get('max_mdd', 20.0)
            if isinstance(max_mdd_limit, list): max_mdd_limit = max_mdd_limit[0]
            
            # ê·¸ë¦¬ë“œì—ì„œ ë„˜ì–´ì˜¨ ë ˆë²„ë¦¬ì§€ (í•­ìƒ ì •ìˆ˜ì—¬ì•¼ í•¨)
            grid_leverage = int(leverage)
            
            # ë ˆë²„ë¦¬ì§€ ì ìš© (PnL ìˆ˜ì •)
            for t in trades:
                t['pnl'] = t['pnl'] * grid_leverage
            
            # ë©”íŠ¸ë¦­ ê³„ì‚° (ë ˆë²„ë¦¬ì§€ ë°˜ì˜ë¨)
            metrics = self._calculate_metrics(trades)
            
            # [FIX] ë ˆë²„ë¦¬ì§€ ì ìš© í›„ MDDê°€ í•œë„ë¥¼ ì´ˆê³¼í•˜ë©´ íƒˆë½ (max_mddê°€ 100ì´ë©´ ì‚¬ì‹¤ìƒ ë¬´ì‹œ)
            if max_mdd_limit < 100.0 and abs(metrics['max_drawdown']) > max_mdd_limit:
                return None

            # ë“±ê¸‰ í• ë‹¹ (ê· í˜•í˜• ê¸°ì¤€ìœ¼ë¡œ ì„ì‹œ ë“±ê¸‰ ë¶€ì—¬)
            grade = assign_grade_by_preset(
                preset_type='balanced',
                metrics={
                    'win_rate': metrics['win_rate'],
                    'profit_factor': metrics['profit_factor'],
                    'mdd': metrics['max_drawdown'],
                    'sharpe_ratio': metrics['sharpe_ratio'],
                    'compound_return': metrics['compound_return']
                }
            )

            return OptimizationResult(
                params=params,
                trades=len(trades),
                win_rate=metrics['win_rate'],
                total_return=metrics['total_return'],
                simple_return=metrics['simple_return'],
                compound_return=metrics['compound_return'],
                max_drawdown=metrics['max_drawdown'],
                sharpe_ratio=metrics['sharpe_ratio'],
                profit_factor=metrics['profit_factor'],
                avg_trades_per_day=metrics.get('avg_trades_per_day', 0.0),
                stability=metrics.get('stability', "âš ï¸"),
                grade=grade,
                avg_pnl=metrics.get('avg_pnl', 0.0),
                cagr=metrics.get('cagr', 0.0)
            )
            
        except Exception as e:
            logger.warning(f"  âš ï¸ ë°±í…ŒìŠ¤íŠ¸ ì˜¤ë¥˜: {e}")
            return None
    
    @staticmethod
    def calculate_mdd(equity_curve: List[float]) -> float:
        """
        Equity Curveì—ì„œ MDD ê³„ì‚°
        Args:
            equity_curve: ìì‚° ê³¡ì„  (List[float])
        Returns:
            MDD (%)
        """
        if not equity_curve:
            return 0.0
            
        peak = equity_curve[0]
        max_drawdown = 0.0
        
        for val in equity_curve:
            if val > peak:
                peak = val
            
            if peak > 1e-9:
                drawdown = (peak - val) / peak * 100
                if drawdown > max_drawdown:
                    max_drawdown = drawdown
                    
        return min(max_drawdown, 100.0)

    @staticmethod
    def calculate_metrics(trades: List[Dict]) -> Dict:
        """
        ê±°ë˜ ê²°ê³¼ì—ì„œ ë©”íŠ¸ë¦­ ê³„ì‚° (SSOT ì™„ì „ í†µí•© v7.24)

        â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        ğŸ“Š ì§€í‘œ ê³„ì‚° ê³µì‹ (METRICS CALCULATION FORMULAS)
        â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

        1. win_rate (ìŠ¹ë¥ )
           ê³µì‹: (ìˆ˜ìµ ê±°ë˜ ìˆ˜ / ì „ì²´ ê±°ë˜ ìˆ˜) Ã— 100
           ì˜í–¥: filter_tfâ†‘ â†’ ìŠ¹ë¥ â†‘, atr_multâ†‘ â†’ ìŠ¹ë¥ â†‘

        2. simple_return (ë‹¨ë¦¬ ìˆ˜ìµë¥ )
           ê³µì‹: Î£(ê° ê±°ë˜ì˜ PnL%)
           ì˜í–¥: leverageâ†‘ â†’ ìˆ˜ìµâ†‘, trail_start_râ†‘ â†’ ìˆ˜ìµâ†‘

        3. compound_return (ë³µë¦¬ ìˆ˜ìµë¥ )
           ê³µì‹: (Î (1 + PnL%/100) - 1) Ã— 100
           ì˜í–¥: leverageâ†‘ â†’ ìˆ˜ìµâ†‘â†‘ (ë³µë¦¬ íš¨ê³¼)

        4. max_drawdown (MDD, ìµœëŒ€ ë‚™í­)
           ê³µì‹: max((peak - current) / peak Ã— 100)
           ì˜í–¥: leverageâ†‘ â†’ MDDâ†‘, atr_multâ†‘ â†’ MDDâ†‘

        5. sharpe_ratio (ìƒ¤í”„ ë¹„ìœ¨)
           ê³µì‹: (í‰ê·  ìˆ˜ìµ / í‘œì¤€í¸ì°¨) Ã— âˆš(252 Ã— 4)
           ì˜í–¥: leverageâ†‘ â†’ ë³€ë™ì„±â†‘ â†’ ìƒ¤í”„â†“

        6. profit_factor (ìˆ˜ìµ íŒ©í„°)
           ê³µì‹: ì´ ìˆ˜ìµ / ì´ ì†ì‹¤
           ì˜í–¥: ì „ì²´ íŒŒë¼ë¯¸í„°ì˜ ë³µí•© íš¨ê³¼
        â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

        Note:
            v7.24ë¶€í„° utils.metrics.calculate_backtest_metrics()ë¥¼ ì§ì ‘ í˜¸ì¶œí•©ë‹ˆë‹¤.
            í´ë¨í•‘ ì—†ì´ ì‹¤ì œ PnLì„ ì‚¬ìš©í•˜ì—¬ ì •í™•í•œ ë©”íŠ¸ë¦­ì„ ê³„ì‚°í•©ë‹ˆë‹¤.
            ì´ëŠ” MetaOptimizerì™€ ë™ì¼í•œ ë°©ì‹ì´ë©°, SSOT ì›ì¹™ì„ ì™„ì „íˆ ì¤€ìˆ˜í•©ë‹ˆë‹¤.
        """
        if not trades:
            return {k: 0 for k in ['win_rate', 'total_return', 'simple_return', 'compound_return', 'max_drawdown', 'sharpe_ratio', 'profit_factor']}

        # âœ… SSOT ì§ì ‘ í˜¸ì¶œ (í´ë¨í•‘ ì—†ìŒ)
        from utils.metrics import calculate_backtest_metrics

        metrics = calculate_backtest_metrics(trades, leverage=1, capital=100.0)

        # í‚¤ ì´ë¦„ ë³€í™˜ (í•˜ìœ„ í˜¸í™˜ì„± ìœ ì§€)
        result = {
            'win_rate': round(metrics['win_rate'], 2),
            'total_pnl': round(metrics['total_pnl'], 2),
            'simple_return': round(metrics['total_pnl'], 2),
            'compound_return': round(metrics['compound_return'], 2),
            'mdd': round(metrics['mdd'], 2),
            'sharpe_ratio': round(metrics['sharpe_ratio'], 2),
            'profit_factor': round(metrics['profit_factor'], 2),
            'stability': metrics['stability'],
            'avg_trades_per_day': metrics['avg_trades_per_day'],
            'avg_pnl': round(metrics['avg_pnl'], 4),
            'cagr': round(metrics['cagr'], 2)
        }

        # í•˜ìœ„ í˜¸í™˜ì„±: alias ì œê³µ (Deprecated)
        result['total_return'] = result['total_pnl']  # Deprecated: use 'total_pnl'
        result['max_drawdown'] = result['mdd']  # Deprecated: use 'mdd'

        return result

    @staticmethod
    def _calculate_cagr(final_equity: float, trades: List[Dict]) -> float:
        """
        ì—°ê°„ ë³µë¦¬ ì„±ì¥ë¥ (CAGR) ê³„ì‚°

        Wrapper for utils.metrics.calculate_cagr() (SSOT)
        """
        from utils.metrics import calculate_cagr
        return calculate_cagr(trades, final_capital=final_equity, initial_capital=1.0)

    def _calculate_metrics(self, trades: List[Dict]) -> Dict:
        """ì¸ìŠ¤í„´ìŠ¤ìš© í•˜ìœ„ í˜¸í™˜ ë©”ì„œë“œ"""
        return self.calculate_metrics(trades)

    def _calculate_stability(self, pnls: List[float]) -> str:
        """
        3êµ¬ê°„ ì•ˆì •ì„± ì²´í¬ (ê³¼ê±°/ì¤‘ê°„/ìµœê·¼)

        Wrapper for utils.metrics.calculate_stability() (SSOT)
        """
        from utils.metrics import calculate_stability
        return calculate_stability(pnls)

    def _classify_results(self, results: List[OptimizationResult], mode: str = 'standard') -> List[OptimizationResult]:
        """
        ê²°ê³¼ë¥¼ í´ëŸ¬ìŠ¤í„°ë§í•˜ì—¬ ìœ í˜•ë³„ ëŒ€í‘œê°’ ì„ ì • (v3 ê°œì„ )
        
        Args:
            results: ìµœì í™” ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
            mode: 'quick' (1ê°œ), 'standard' (3ê°œ), 'deep' (5ê°œ+)
        
        Returns:
            ëŒ€í‘œ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        """
        if not results:
            return []
        
        # ê²°ê³¼ ë³µì‚¬ ë° ì •ë ¬ ê¸°ì¤€ë³„ í•„í„°ë§
        representatives = []
        seen_params = set()

        def add_rep(res, label):
            param_key = str(res.params)
            if param_key not in seen_params:
                res.strategy_type = label
                # í”„ë¦¬ì…‹ íƒ€ì…ì— ë§ê²Œ ë“±ê¸‰ ì¬í• ë‹¹
                res.grade = assign_grade_by_preset(
                    preset_type=label,
                    metrics={
                        'win_rate': res.win_rate,
                        'profit_factor': res.profit_factor,
                        'mdd': res.max_drawdown,
                        'sharpe_ratio': res.sharpe_ratio,
                        'compound_return': res.compound_return
                    }
                )
                representatives.append(res)
                seen_params.add(param_key)
        
        def add_multiple_reps(sorted_results, label_prefix, count):
            """ìƒìœ„ Nê°œ ê²°ê³¼ë¥¼ ì¶”ê°€ (ì¤‘ë³µ ì œì™¸)"""
            added = 0
            for i, res in enumerate(sorted_results):
                if added >= count:
                    break
                param_key = str(res.params)
                if param_key not in seen_params:
                    res.strategy_type = f"{label_prefix}#{added+1}"
                    # í”„ë¦¬ì…‹ íƒ€ì…ì— ë§ê²Œ ë“±ê¸‰ ì¬í• ë‹¹
                    res.grade = assign_grade_by_preset(
                        preset_type=label_prefix,  # "ğŸ”¥ê³µê²©" ë“±
                        metrics={
                            'win_rate': res.win_rate,
                            'profit_factor': res.profit_factor,
                            'mdd': res.max_drawdown,
                            'sharpe_ratio': res.sharpe_ratio,
                            'compound_return': res.compound_return
                        }
                    )
                    representatives.append(res)
                    seen_params.add(param_key)
                    added += 1

        profitable = [r for r in results if r.total_return > 0]
        
        # ===== Quick ëª¨ë“œ: 1ê°œ (ìµœê³  ìŠ¤ì½”ì–´) =====
        if mode == 'quick':
            # ë³µí•© ìŠ¤ì½”ì–´ ê¸°ì¤€ ìµœê³  1ê°œ
            best = max(results, key=lambda x: (
                x.win_rate * 1.0 + 
                (100 - abs(x.max_drawdown)) * 0.5 + 
                x.sharpe_ratio * 2.0
            ))
            add_rep(best, "ğŸ†ìµœì ")
            return representatives
        
        # ===== Standard ëª¨ë“œ: 3ê°œ (ê³µê²©, ê· í˜•, ë³´ìˆ˜) =====
        if mode == 'standard':
            # 1. ğŸ”¥ê³µê²©í˜•: ìµœê³  ìˆ˜ìµë¥ 
            aggressive = max(results, key=lambda x: x.compound_return)
            add_rep(aggressive, "ğŸ”¥ê³µê²©")
            
            # 2. âš–ê· í˜•í˜•: ìµœê³  ìƒ¤í”„ ì§€ìˆ˜
            balanced = max(results, key=lambda x: x.sharpe_ratio)
            add_rep(balanced, "âš–ê· í˜•")
            
            # 3. ğŸ›¡ë³´ìˆ˜í˜•: ìµœì € MDD (ìˆ˜ìµ > 0 ì¤‘)
            if profitable:
                conservative = min(profitable, key=lambda x: abs(x.max_drawdown))
                add_rep(conservative, "ğŸ›¡ë³´ìˆ˜")
            
            return representatives
        
        # ===== Deep ëª¨ë“œ: 5ê°œ+ (ê³µê²©Ã—3, ê· í˜•, ë³´ìˆ˜) =====
        # 1. ğŸ”¥ê³µê²©í˜• Top 3: ìµœê³  ìˆ˜ìµë¥  ìƒìœ„ 3ê°œ
        sorted_by_return = sorted(results, key=lambda x: x.compound_return, reverse=True)
        add_multiple_reps(sorted_by_return, "ğŸ”¥ê³µê²©", 3)
        
        # 2. âš–ê· í˜•í˜•: ìµœê³  ìƒ¤í”„ ì§€ìˆ˜
        balanced = max(results, key=lambda x: x.sharpe_ratio)
        add_rep(balanced, "âš–ê· í˜•")
        
        # 3. ğŸ›¡ë³´ìˆ˜í˜•: ìµœì € MDD (ìˆ˜ìµ > 0 ì¤‘)
        if profitable:
            conservative = min(profitable, key=lambda x: abs(x.max_drawdown))
            add_rep(conservative, "ğŸ›¡ë³´ìˆ˜")
        
        # 4. ğŸ¯ê³ ìŠ¹ë¥ í˜•: ìµœê³  ìŠ¹ë¥ 
        high_wr = max(results, key=lambda x: x.win_rate)
        add_rep(high_wr, "ğŸ¯ê³ ìŠ¹ë¥ ")
        
        # 5. ğŸ¢ì €ë¹ˆë„í˜•: ì¼í‰ê·  ê±°ë˜ ê°€ì¥ ì ì€ ê²ƒ (ìˆ˜ìµ > 0)
        if profitable:
            low_freq = min(profitable, key=lambda x: getattr(x, 'avg_trades_per_day', x.trades / 30))
            add_rep(low_freq, "ğŸ¢ì €ë¹ˆë„")
        
        return representatives
    
    def get_best(self, n: int = 10) -> List[OptimizationResult]:
        """ìƒìœ„ Nê°œ ê²°ê³¼ ë°˜í™˜"""
        return self.results[:n]
    
    def analyze_top_results(self, n: int = 100, threshold: float = 0.85) -> Dict:
        """
        ìƒìœ„ ê²°ê³¼ ë¶„ì„ â†’ ì§€ë°°ì  íŒŒë¼ë¯¸í„° ê³ ì • ë° ë²”ìœ„ ì¶•ì†Œ (Iterative Optimizationìš©)
        
        Args:
            n: ë¶„ì„í•  ìƒìœ„ ê²°ê³¼ ìˆ˜
            threshold: ê³ ì • íŒë‹¨ ì„ê³„ê°’ (ì˜ˆ: 0.85 -> 85% ì´ìƒ ê°™ì€ ê°’ì´ë©´ ê³ ì •)
            
        Returns:
            Dict: ì¶•ì†Œëœ íŒŒë¼ë¯¸í„° ê·¸ë¦¬ë“œ
        """
        if not self.results:
            return {}
            
        from collections import Counter
        top_results = sorted(self.results, key=lambda x: getattr(x, 'sharpe_ratio', 0), reverse=True)[:n]
        
        # ë¶„ì„ ëŒ€ìƒ íŒŒë¼ë¯¸í„° (ì§€í‘œ ê´€ë ¨)
        target_params = ['atr_mult', 'trail_start_r', 'trail_dist_r', 'pattern_tolerance', 'entry_validity_hours', 'pullback_rsi_long', 'pullback_rsi_short', 'filter_tf', 'entry_tf', 'leverage']

        
        fixed_params = {}
        reduced_ranges = {}
        
        for param in target_params:
            # í•´ë‹¹ íŒŒë¼ë¯¸í„° ê°’ ì¶”ì¶œ
            values = []
            for res in top_results:
                val = res.params.get(param)
                if val is not None:
                    if isinstance(val, list): val = val[0]
                    values.append(val)
            
            if not values: continue
            
            # ë¹ˆë„ ë¶„ì„
            counts = Counter(values)
            most_common_val, count = counts.most_common(1)[0]
            ratio = count / len(values)
            
            if ratio >= threshold:
                # ì§€ë°°ì ì¸ ê°’ ë°œê²¬ -> ê³ ì •
                fixed_params[param] = [most_common_val]
                logger.info(f"ğŸ“Œ [OPT-ADAPT] '{param}' fixed to {most_common_val} (Dominance: {ratio:.1%})")
            else:
                # ë¶„í¬ ë¶„ì„ -> ë²”ìœ„ ì¶•ì†Œ (ìµœì†Œ~ìµœëŒ€ê°’ ì‚¬ì´ë¥¼ ë‹¤ì‹œ ì´˜ì´˜í•˜ê²Œ)
                min_v = min(values)
                max_v = max(values)
                
                # ê¸°ì¡´ INDICATOR_RANGEë‚˜ ì›ë³¸ ê·¸ë¦¬ë“œì—ì„œ í•´ë‹¹ êµ¬ê°„ì˜ ê°’ë“¤ ì¶”ì¶œ
                # ì—¬ê¸°ì„œëŠ” ê°„ë‹¨íˆ 5ë¶„í• í•˜ì—¬ ì´˜ì´˜í•˜ê²Œ ìƒì„±
                if isinstance(min_v, (int, float)) and not isinstance(min_v, bool):
                     # ìˆ˜ì¹˜í˜• íŒŒë¼ë¯¸í„°
                     step = (max_v - min_v) / 5
                     if step > 0:
                         new_vals = [round(min_v + step * i, 3) for i in range(6)]
                         reduced_ranges[param] = sorted(list(set(new_vals)))
                     else:
                         reduced_ranges[param] = [min_v]
                else:
                    # ì¹´í…Œê³ ë¦¬í˜• (filter_tf ë“±)
                    reduced_ranges[param] = sorted(list(set(values)))
                
                logger.debug(f"ğŸ” [OPT-ADAPT] '{param}' range narrowed: {min_v} ~ {max_v}")

        # ìƒˆë¡œìš´ ê·¸ë¦¬ë“œ ìƒì„±
        new_grid = {}
        # 1. ê³ ì •ëœ ê°’ ì ìš©
        new_grid.update(fixed_params)
        # 2. ì¶•ì†Œëœ ë²”ìœ„ ì ìš©
        new_grid.update(reduced_ranges)
        
        # 3. ê³µí†µ í•„ë“œ ìœ ì§€ (trend_interval, max_mdd ë“±)
        if self.results:
            first_params = self.results[0].params
            for k in ['trend_interval', 'max_mdd', 'direction']:
                if k not in new_grid and k in first_params:
                    val = first_params[k]
                    new_grid[k] = val if isinstance(val, list) else [val]
        
        return new_grid

    def filter_unique_results(self, results: Optional[List[OptimizationResult]] = None, 
                              max_count: int = 30) -> List[OptimizationResult]:
        """
        ì¤‘ë³µ/ìœ ì‚¬ ê²°ê³¼ ì œê±° + ìƒìœ„ Nê°œ ì„ íƒ
        
        ê¸°ì¤€:
        - ìŠ¹ë¥  1% ì´ë‚´ + MDD 2% ì´ë‚´ = ìœ ì‚¬ ê²°ê³¼
        - ìœ ì‚¬ ê·¸ë£¹ ë‚´ â†’ ë³µí•© ìŠ¤ì½”ì–´ ë†’ì€ 1ê°œë§Œ
        - ìµœì¢… max_countê°œ ë°˜í™˜
        """
        if results is None:
            results = self.results
        
        if not results:
            return []
        
        # ë³µí•© ìŠ¤ì½”ì–´ ê³„ì‚° (ìŠ¹ë¥  > MDD > ìƒ¤í”„ > ìˆ˜ìµë¥ )
        def calc_score(r):
            return (
                r.win_rate * 1.0 +                    # ìŠ¹ë¥  88% â†’ 88ì 
                (100 + r.max_drawdown) * 0.5 +        # MDD -17% â†’ 41.5ì 
                r.sharpe_ratio * 2.0 +                # ìƒ¤í”„ 26 â†’ 52ì 
                min(r.total_return / 100, 50) * 0.2   # ìˆ˜ìµë¥  cap 50
            )
        
        # ìŠ¤ì½”ì–´ ìˆœ ì •ë ¬
        scored = sorted(results, key=calc_score, reverse=True)
        
        # ìœ ì‚¬ ê²°ê³¼ ì œê±°
        unique = []
        for r in scored:
            is_duplicate = False
            for u in unique:
                # MDDëŠ” ë³´í†µ ìŒìˆ˜ì´ë¯€ë¡œ abs()ë¡œ ì°¨ì´ í™•ì¸
                if (abs(r.win_rate - u.win_rate) < 1.0 and
                    abs(r.max_drawdown - u.max_drawdown) < 2.0):
                    is_duplicate = True
                    break
            
            if not is_duplicate:
                unique.append(r)
            
            if len(unique) >= max_count:
                break
        
        logger.info(f"ğŸ”„ [FILTER] {len(results)} â†’ {len(unique)} (ì¤‘ë³µ ì œê±°)")
        return unique

    def to_dataframe(self) -> pd.DataFrame:
        """ê²°ê³¼ë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜"""
        if not self.results:
            return pd.DataFrame()
        
        rows = []
        for r in self.results:
            row = {**r.params}
            row['trades'] = r.trades
            row['win_rate'] = r.win_rate
            row['total_return'] = r.total_return
            row['max_drawdown'] = r.max_drawdown
            row['sharpe_ratio'] = r.sharpe_ratio
            row['profit_factor'] = r.profit_factor
            rows.append(row)
        
        return pd.DataFrame(rows)

    # ==================== v7.22: Coarse-to-Fine API ====================

    def run_coarse_grid_optimization(
        self,
        df: pd.DataFrame,
        trend_tf: str,
        metric: str = 'sharpe_ratio',
        n_cores: Optional[int] = None
    ) -> List[OptimizationResult]:
        """
        Coarse Grid ìµœì í™” (ë„“ì€ ë²”ìœ„ íƒìƒ‰)

        3Â³ Ã— 3 Ã— 3 = 243ê°œ ì¡°í•©:
        - atr_mult: [1.0, 2.0, 3.0]
        - filter_tf: ['4h', '12h', '1d']
        - trail_start_r: [1.0, 2.0, 3.0]
        - trail_dist_r: [0.015, 0.020, 0.030]
        - entry_validity_hours: [6, 48, 96]

        Args:
            df: ë°±í…ŒìŠ¤íŠ¸ ë°ì´í„°
            trend_tf: ì¶”ì„¸ íƒ€ì„í”„ë ˆì„
            metric: ìµœì í™” ë©”íŠ¸ë¦­ ('sharpe_ratio', 'profit_factor', ë“±)
            n_cores: CPU ì½”ì–´ ìˆ˜ (Noneì´ë©´ ìë™)

        Returns:
            OptimizationResult ë¦¬ìŠ¤íŠ¸ (ì •ë ¬ë¨)
        """
        logger.info(f"ğŸ” [Coarse] Starting Coarse Grid optimization...")

        # v7.23: ê±°ë˜ì†Œë³„ ìˆ˜ìˆ˜ë£Œ ë° íŒŒë¼ë¯¸í„° ë²”ìœ„ ìë™ ì¡°ì •
        from config.constants.trading import get_total_cost
        from config.parameters import (
            get_atr_range_by_exchange,
            get_filter_tf_range_by_exchange
        )

        # 1. ê±°ë˜ì†Œë³„ ìˆ˜ìˆ˜ë£Œ ê³„ì‚°
        total_cost = get_total_cost(self.exchange)

        # 2. ê±°ë˜ì†Œë³„ íŒŒë¼ë¯¸í„° ë²”ìœ„
        atr_range = get_atr_range_by_exchange(self.exchange, mode='coarse')
        filter_range = get_filter_tf_range_by_exchange(self.exchange, mode='coarse')

        logger.info(f"ğŸ“Š [{self.exchange.upper()}] Total Cost: {total_cost*100:.3f}%")
        logger.info(f"  ATR Range: {atr_range}")
        logger.info(f"  Filter Range: {filter_range}")

        # Coarse Grid ì •ì˜ (ê±°ë˜ì†Œë³„ ì¡°ì •)
        # MACD: len(atr_range) Ã— len(filter_range) Ã— 3 Ã— 3 Ã— 3 ì¡°í•©
        # ADX: ìœ„ ì¡°í•© Ã— 3 Ã— 3 ì¶”ê°€
        coarse_grid = {
            'trend_interval': [trend_tf],
            'atr_mult': atr_range,           # ê±°ë˜ì†Œë³„ ë²”ìœ„
            'filter_tf': filter_range,        # ê±°ë˜ì†Œë³„ ë²”ìœ„
            'trail_start_r': [1.0, 2.0, 3.0],
            'trail_dist_r': [0.015, 0.020, 0.030],
            'entry_validity_hours': [6.0, 48.0, 96.0],
            'slippage': [total_cost],         # ê±°ë˜ì†Œë³„ ìˆ˜ìˆ˜ë£Œ
            'fee': [0]  # slippageì— ì´ë¯¸ í¬í•¨ë˜ì–´ ìˆìœ¼ë¯€ë¡œ 0ìœ¼ë¡œ ì„¤ì •
        }

        # ADX ì „ëµì´ë©´ ADX íŒŒë¼ë¯¸í„° ì¶”ê°€
        if self.strategy_type == 'adx':
            coarse_grid['adx_period'] = [10, 14, 18]         # 3ê°œ (ë¹ ë¦„, í‘œì¤€, ëŠë¦¼)
            coarse_grid['adx_threshold'] = [20.0, 25.0, 30.0]  # 3ê°œ (Wilder 1978 í‘œì¤€ ë²”ìœ„ 25Â±5)

        # ì¡°í•© ìˆ˜ í™•ì¸
        import itertools
        combinations = list(itertools.product(
            *[coarse_grid[k] for k in coarse_grid.keys()]
        ))
        logger.info(f"ğŸ“Š [Coarse] Grid size: {len(combinations)} combinations")

        # âš ï¸ WORKAROUND: ì„ì‹œë¡œ í•„í„° ê°’ì„ ì™„í™”í•œ í›„ ì‹¤í–‰
        from config import parameters
        original_filter = parameters.OPTIMIZATION_FILTER.copy()

        # í•„í„° ì™„ì „ ë¹„í™œì„±í™”
        parameters.OPTIMIZATION_FILTER = {
            'min_win_rate': 0.0,
            'max_mdd': 999.0,
            'min_total_return': -9999.0,
            'min_trades_per_day': 0.0,
            'min_absolute_trades': 0
        }
        logger.info(f"âš ï¸ [Coarse] Filter temporarily disabled")

        try:
            # ê¸°ì¡´ run_optimization í˜¸ì¶œ
            results = self.run_optimization(
                df=df,
                grid=coarse_grid,
                metric=metric,
                n_cores=n_cores,
                mode='coarse',  # â† 'coarse' ëª¨ë“œ ì‚¬ìš© (ë¶„ë¥˜ ê±´ë„ˆë›°ê¸°)
                skip_filter=True  # â† [FIX] í•„í„° ì™„ì „ ìš°íšŒ (ë¼ì¸ 1808 ì™„í™”ì™€ ì¼ê´€ì„±)
            )
        finally:
            # í•„í„° ë³µì›
            parameters.OPTIMIZATION_FILTER = original_filter
            logger.info(f"âœ“ [Coarse] Filter restored")

        logger.info(f"âœ“ [Coarse] Complete: {len(results)} results")
        return results

    def run_fine_grid_optimization(
        self,
        df: pd.DataFrame,
        trend_tf: str,
        coarse_results: List[OptimizationResult],
        top_n: int = 20,
        metric: str = 'sharpe_ratio',
        n_cores: Optional[int] = None
    ) -> List[OptimizationResult]:
        """
        Fine Grid ìµœì í™” (ì •ë°€ íƒìƒ‰)

        coarse_results ìƒìœ„ top_nê°œì—ì„œ ë°±ë¶„ìœ„ìˆ˜ ì¶”ì¶œ:
        - 10~90% ë²”ìœ„ë¡œ 3ë‹¨ê³„ ê·¸ë¦¬ë“œ ìƒì„±
        - ì•½ 27ê°œ ì¡°í•© (3Â³)

        Args:
            df: ë°±í…ŒìŠ¤íŠ¸ ë°ì´í„°
            trend_tf: ì¶”ì„¸ íƒ€ì„í”„ë ˆì„
            coarse_results: Coarse Grid ê²°ê³¼
            top_n: ìƒìœ„ Nê°œ ì‚¬ìš© (ê¸°ë³¸ê°’ 20, ì „ì²´ì˜ ~8%)
            metric: ìµœì í™” ë©”íŠ¸ë¦­
            n_cores: CPU ì½”ì–´ ìˆ˜

        Returns:
            OptimizationResult ë¦¬ìŠ¤íŠ¸ (ì •ë ¬ë¨)
        """
        logger.info(f"ğŸ¯ [Fine] Starting Fine Grid optimization...")

        if not coarse_results:
            logger.warning(f"âŒ [Fine] No coarse results provided")
            return []

        # ìƒìœ„ Nê°œ ì¶”ì¶œ
        top_results = coarse_results[:top_n]
        logger.info(f"ğŸ“Š [Fine] Analyzing top {len(top_results)} results...")

        # ë°±ë¶„ìœ„ìˆ˜ ê¸°ë°˜ ë²”ìœ„ ì¶”ì¶œ
        fine_grid = self._extract_fine_ranges(top_results, trend_tf)

        # ì¡°í•© ìˆ˜ í™•ì¸
        import itertools
        combinations = list(itertools.product(
            *[fine_grid[k] for k in fine_grid.keys()]
        ))
        logger.info(f"ğŸ“Š [Fine] Grid size: {len(combinations)} combinations")

        # ê¸°ì¡´ run_optimization í˜¸ì¶œ
        # [FIX] v7.22.1: Fine Gridë„ í•„í„° ì™„í™” (ADX ì „ëµ ì§€ì›)
        from config import parameters
        original_filter = parameters.OPTIMIZATION_FILTER.copy()

        # í•„í„° ì™„í™” (Fine GridëŠ” Coarseë³´ë‹¤ ì•½ê°„ ì—„ê²©)
        parameters.OPTIMIZATION_FILTER = {
            'min_win_rate': 70.0,  # 70% ì´ìƒ
            'max_mdd': 30.0,       # 30% ì´í•˜
            'min_total_return': 0.0,  # 0% ì´ìƒ
            'min_trades_per_day': 0.3,  # 0.3íšŒ/ì¼ ì´ìƒ
            'min_absolute_trades': 5  # ìµœì†Œ 5ê°œ
        }

        try:
            results = self.run_optimization(
                df=df,
                grid=fine_grid,
                metric=metric,
                n_cores=n_cores,
                mode='standard',
                skip_filter=False  # ì™„í™”ëœ í•„í„° ì‚¬ìš©
            )
        finally:
            # í•„í„° ë³µì›
            parameters.OPTIMIZATION_FILTER = original_filter

        logger.info(f"âœ“ [Fine] Complete: {len(results)} results")
        return results

    def _extract_fine_ranges(
        self,
        top_results: List[OptimizationResult],
        trend_tf: str
    ) -> Dict:
        """
        ìƒìœ„ ê²°ê³¼ì—ì„œ ë°±ë¶„ìœ„ìˆ˜ ê¸°ë°˜ Fine Grid ë²”ìœ„ ì¶”ì¶œ

        Args:
            top_results: ìƒìœ„ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
            trend_tf: ì¶”ì„¸ íƒ€ì„í”„ë ˆì„

        Returns:
            Fine Grid ë”•ì…”ë„ˆë¦¬ (3ê°œ ê°’ì”©)
        """
        from collections import Counter

        # íŒŒë¼ë¯¸í„°ë³„ ê°’ ìˆ˜ì§‘
        atr_mults = [r.params.get('atr_mult', 1.5) for r in top_results]
        trail_starts = [r.params.get('trail_start_r', 1.0) for r in top_results]
        trail_dists = [r.params.get('trail_dist_r', 0.02) for r in top_results]
        entry_hours = [r.params.get('entry_validity_hours', 6.0) for r in top_results]
        filter_tfs = [r.params.get('filter_tf', '4h') for r in top_results]

        # ADX íŒŒë¼ë¯¸í„° ìˆ˜ì§‘ (ADX ì „ëµì¸ ê²½ìš°ë§Œ)
        adx_periods = [r.params.get('adx_period', 14) for r in top_results if 'adx_period' in r.params]
        adx_thresholds = [r.params.get('adx_threshold', 25.0) for r in top_results if 'adx_threshold' in r.params]

        # ìˆ˜ì¹˜í˜•: 10~90% ë°±ë¶„ìœ„ìˆ˜ (3ë‹¨ê³„)
        def percentile_range(values: List[float], steps: int = 3) -> List[float]:
            if not values:
                return []
            p10 = float(np.percentile(values, 10))
            p90 = float(np.percentile(values, 90))
            if p10 == p90:
                # âœ… FIX v7.22.1: ìˆ˜ë ´ ì‹œ Â±20% ë²”ìœ„ë¡œ í™•ì¥ (êµ­ì†Œ íƒìƒ‰)
                center = p10
                if center > 0:
                    # ì–‘ìˆ˜ë©´ ë¹„ìœ¨ ê¸°ë°˜ í™•ì¥
                    return [float(x) for x in np.linspace(center * 0.8, center * 1.2, steps)]
                else:
                    # 0 ê·¼ì²˜ë©´ ì ˆëŒ€ê°’ ê¸°ë°˜ í™•ì¥
                    return [float(x) for x in np.linspace(center - 0.2, center + 0.2, steps)]
            return [float(x) for x in np.linspace(p10, p90, steps)]

        # ì¹´í…Œê³ ë¦¬í˜•: ë¹ˆë„ ìƒìœ„ 3ê°œ
        def top_categories(values: List[str], top_k: int = 3) -> List[str]:
            counts = Counter(values)
            return [v for v, _ in counts.most_common(top_k)]

        fine_grid = {
            'trend_interval': [trend_tf],
            'atr_mult': percentile_range(atr_mults, 3),
            'filter_tf': top_categories(filter_tfs, 3),
            'trail_start_r': percentile_range(trail_starts, 3),
            'trail_dist_r': percentile_range(trail_dists, 3),
            'entry_validity_hours': percentile_range(entry_hours, 3)
        }

        # v7.23: ê±°ë˜ì†Œë³„ ìˆ˜ìˆ˜ë£Œ ì ìš© (Coarseì™€ ì¼ê´€ì„± ë³´ì¥)
        from config.constants.trading import get_total_cost
        total_cost = get_total_cost(self.exchange)
        fine_grid['slippage'] = [total_cost]
        fine_grid['fee'] = [0]

        # ADX íŒŒë¼ë¯¸í„° ì¶”ê°€ (ADX ì „ëµì¸ ê²½ìš°)
        if adx_periods and adx_thresholds:
            fine_grid['adx_period'] = percentile_range(adx_periods, 3)
            fine_grid['adx_threshold'] = percentile_range(adx_thresholds, 3)

        logger.info(f"ğŸ“Š [Fine] Extracted ranges:")
        for k, v in fine_grid.items():
            if k != 'trend_interval':
                logger.info(f"  {k}: {v}")

        return fine_grid


# í…ŒìŠ¤íŠ¸
if __name__ == "__main__":
    # âœ… v7.28: ë©€í‹°í”„ë¡œì„¸ì‹± ìŠ¤íƒ€íŠ¸ ë©”ì„œë“œ ëª…ì‹œ (Windows í˜¸í™˜ì„±)
    import multiprocessing as mp
    try:
        mp.set_start_method('spawn', force=True)
    except RuntimeError:
        # ì´ë¯¸ ì„¤ì •ëœ ê²½ìš° ë¬´ì‹œ
        pass

    import os
    import sys
    import pandas as pd
    import traceback

    try:
        # 1. ê²½ë¡œ ì„¤ì •
        BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
        if BASE_DIR not in sys.path:
            sys.path.append(BASE_DIR)
        
        from core.strategy_core import AlphaX7Core
        
        # ë°ì´í„° ë¡œë“œ (Parquet ìš°ì„  íƒìƒ‰)
        csv_path = os.path.join(BASE_DIR, 'data', 'cache', 'bybit_btcusdt_15m.parquet')
        if not os.path.exists(csv_path):
            csv_path = os.path.join(BASE_DIR, 'data', 'bybit_BTCUSDT_15m.csv') # Fallback
            
        logger.info(f"ğŸ“Š Testing with: {csv_path}")
        
        if os.path.exists(csv_path):
            if csv_path.endswith('.parquet'):
                df = pd.read_parquet(csv_path)
            else:
                df = pd.read_csv(csv_path)
                
            # íƒ€ì„ìŠ¤íƒ¬í”„ ë³€í™˜
            if 'timestamp' in df.columns and not pd.api.types.is_datetime64_any_dtype(df['timestamp']):
                first_ts = df['timestamp'].iloc[0]
                val = float(first_ts)
                if val > 1e12:
                    df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms', utc=True)
                elif val > 1e8:
                    df['timestamp'] = pd.to_datetime(df['timestamp'], unit='s')
                else:
                    df['timestamp'] = pd.to_datetime(df['timestamp'])
            
            # ìµœê·¼ 5000ê°œë§Œ ì‚¬ìš© (í…ŒìŠ¤íŠ¸ìš©)
            df = df.tail(5000).reset_index(drop=True)
            logger.info(f"Loaded {len(df)} candles. Range: {df['timestamp'].iloc[0]} ~ {df['timestamp'].iloc[-1]}")
            
            # 1. ìµœì í™” ì—”ì§„ ì‹œì‘
            optimizer = BacktestOptimizer(AlphaX7Core, df)
            grid = generate_fast_grid('1h')
            
            logger.info(f"ğŸš€ [Stage 1] Fast Grid Search Starting...")
            results = optimizer.run_optimization(df, grid, metric='sharpe_ratio')
            logger.info(f"âœ… Found {len(results)} combinations.")
            
            # 2. ë¶„ì„ ë° ë²”ìœ„ ì¶•ì†Œ (ì‹ ê·œ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸)
            refined_grid = optimizer.analyze_top_results(n=10, threshold=0.7)
            
            # 3. 2ë‹¨ê³„ ì •ë°€ ìµœì í™”
            if refined_grid:
                logger.info(f"âœ¨ [Analysis] Refined Grid calculated: {refined_grid}")
                logger.info(f"ğŸš€ [Stage 2] Iterative Scan Starting...")
                refined_results = optimizer.run_optimization(df, refined_grid, metric='sharpe_ratio')
                logger.info(f"ğŸ† Final Best Results: {len(refined_results)}")
                
                for res in refined_results[:5]:
                    logger.info(f" - {res.params}: Sharpe={res.sharpe_ratio:.2f}, WR={res.win_rate:.1f}%")
            else:
                logger.info("âœ¨ [Analysis] No dominant patterns found to refine.")
        else:
            logger.error(f"âŒ No test data found at {csv_path}. Please download data first.")
            
    except Exception:
        logger.info("âŒ Test failed with error:")
        traceback.print_exc()
