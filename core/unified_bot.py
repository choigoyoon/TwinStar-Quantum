# unified_bot.py
"""
í†µí•© ë§¤ë§¤ ë´‡
- ì „ëµ: strategy_breakeven.py ë¡œì§ ì‚¬ìš©
- ê±°ë˜ì†Œ: BaseExchange ì–´ëŒ‘í„° í†µí•´ ì—°ë™
"""

# [FIX] EXE í˜¸í™˜ ê²½ë¡œ ì²˜ë¦¬
import sys
import os
from pathlib import Path

if getattr(sys, 'frozen', False):
    _BASE_DIR = os.path.dirname(sys.executable)
else:
    _BASE_DIR = os.path.dirname(os.path.abspath(__file__))

def _get_log_path(filename: str) -> str:
    """EXE í˜¸í™˜ ë¡œê·¸ ê²½ë¡œ"""
    try:
        from paths import Paths
        return os.path.join(Paths.LOGS, filename)
    except ImportError:
        log_dir = os.path.join(_BASE_DIR, 'logs')
        os.makedirs(log_dir, exist_ok=True)
        return os.path.join(log_dir, filename)

def _get_config_path(filename: str) -> str:
    """EXE í˜¸í™˜ ì„¤ì • ê²½ë¡œ"""
    try:
        from paths import Paths
        return os.path.join(Paths.CONFIG, filename)
    except ImportError:
        config_dir = os.path.join(_BASE_DIR, 'config')
        os.makedirs(config_dir, exist_ok=True)
        return os.path.join(config_dir, filename)

import time
import logging
import json
import traceback
import signal
import pandas as pd
import queue
import requests
import numpy as np
from datetime import datetime, timedelta
from typing import Optional, Dict, List, Any
import threading

try:
    from license_manager import get_license_manager
except ImportError:
    def get_license_manager():
        return None

# [CRITICAL] ê±°ë˜ì†Œë³„ ì„œë²„ ì‹œê°„ ë™ê¸°í™”
# PC ì‹œê°„ì´ ì„œë²„ë³´ë‹¤ ë¹ ë¥´ë©´(ë¯¸ë˜) API ìš”ì²­ì´ ê±°ë¶€ë¨ (ErrCode: 10002)
_original_time = time.time
EXCHANGE_TIME_OFFSET = 1.0  # ê¸°ë³¸ê°’ 1ì´ˆ (ë´‡ ì‹œì‘ ì‹œ ì—…ë°ì´íŠ¸)

# [NEW] ìƒíƒœ íŒŒì¼ ê²½ë¡œ (UIì™€ ê³µìœ )
# [NEW] ìƒíƒœ íŒŒì¼ ê²½ë¡œ (UIì™€ ê³µìœ ìš© í´ë°±)
# ì‹¤ì œ íŒŒì¼ì€ ì¸ìŠ¤í„´ìŠ¤ì—ì„œ exchange_symbol ì¡°í•©ìœ¼ë¡œ ìƒì„±
def _get_default_state_file_path():
    try:
        from paths import Paths
        return os.path.join(Paths.CACHE, 'bot_state.json')
    except ImportError:
        return os.path.join(_BASE_DIR, 'cache', 'bot_state.json')

DEFAULT_STATE_FILE = _get_default_state_file_path()

def get_server_time_offset(exchange_name: str) -> float:
    """ê±°ë˜ì†Œë³„ ì„œë²„ ì‹œê°„ ì˜¤í”„ì…‹ ê³„ì‚° (ë„¤íŠ¸ì›Œí¬ ì§€ì—° ë³´ì • í¬í•¨)"""
    endpoints = {
        'bybit': 'https://api.bybit.com/v5/market/time',
        'binance': 'https://api.binance.com/api/v3/time',
        'okx': 'https://www.okx.com/api/v5/public/time',
        'bitget': 'https://api.bitget.com/api/v2/public/time',
    }
    
    try:
        url = endpoints.get(exchange_name.lower())
        if not url:
            print(f"[TIME] {exchange_name} not supported, using 1.0s default")
            return 1.0
        
        local_before = _original_time()
        resp = requests.get(url, timeout=5)
        local_after = _original_time()
        
        # ë„¤íŠ¸ì›Œí¬ ì§€ì—° ë³´ì •
        latency = (local_after - local_before) / 2
        local_time = local_before + latency
        
        data = resp.json()
        
        # ê±°ë˜ì†Œë³„ íŒŒì‹± (ì•ˆì „í•œ ì ‘ê·¼)
        try:
            if exchange_name.lower() == 'bybit':
                server_time = int(data['result']['timeSecond'])
            elif exchange_name.lower() == 'binance':
                server_time = int(data['serverTime']) / 1000
            elif exchange_name.lower() == 'okx':
                server_time = int(data['data'][0]['ts']) / 1000
            elif exchange_name.lower() == 'bitget':
                server_time = int(data['data']['serverTime']) / 1000
            else:
                return 1.0
        except (KeyError, IndexError, TypeError):
            logging.error(f"[TIME] {exchange_name} server time structure invalid: {data}")
            return 1.0
        
        offset = local_time - server_time
        print(f"[TIME] {exchange_name} sync: offset={offset:.3f}s, latency={latency*1000:.0f}ms")
        
        # ìµœì†Œ 0.5ì´ˆ ë§ˆì§„ ì¶”ê°€ (ì•ˆì „)
        return max(offset + 0.5, 0.5)
        
    except Exception as e:
        print(f"[TIME] {exchange_name} sync failed: {e}, using 1.0s default")
        return 1.0

def _hooked_time():
    """ì„œë²„ ì‹œê°„ ê¸°ì¤€ìœ¼ë¡œ ë³´ì •ëœ ì‹œê°„ ë°˜í™˜"""
    return _original_time() - EXCHANGE_TIME_OFFSET

time.time = _hooked_time
print(f"[SYSTEM] Time Monkey Patch Applied: Dynamic offset (default {EXCHANGE_TIME_OFFSET}s)")

# [NEW] ì£¼ê¸°ì  ì‹œê°„ ë™ê¸°í™” (30ë¶„ë§ˆë‹¤)
import threading

_sync_timer = None
_current_exchange = None

def start_periodic_sync(exchange_name: str, interval_minutes: int = 30):
    """ì£¼ê¸°ì  ì‹œê°„ ë™ê¸°í™” ì‹œì‘"""
    global _sync_timer, _current_exchange, EXCHANGE_TIME_OFFSET
    _current_exchange = exchange_name
    
    def sync_and_schedule():
        global EXCHANGE_TIME_OFFSET, _sync_timer
        try:
            new_offset = get_server_time_offset(_current_exchange)
            old_offset = EXCHANGE_TIME_OFFSET
            EXCHANGE_TIME_OFFSET = new_offset
            print(f"[TIME] Periodic sync: {old_offset:.3f}s â†’ {new_offset:.3f}s")
        except Exception as e:
            print(f"[TIME] Periodic sync failed: {e}")
        
        # ë‹¤ìŒ ë™ê¸°í™” ì˜ˆì•½
        _sync_timer = threading.Timer(interval_minutes * 60, sync_and_schedule)
        _sync_timer.daemon = True
        _sync_timer.start()
    
    # ì²« ë™ê¸°í™”
    sync_and_schedule()
    print(f"[TIME] Periodic sync started: every {interval_minutes}min for {exchange_name}")

def stop_periodic_sync():
    """ì£¼ê¸°ì  ì‹œê°„ ë™ê¸°í™” ì¤‘ì§€"""
    global _sync_timer
    if _sync_timer:
        _sync_timer.cancel()
        _sync_timer = None
        print("[TIME] Periodic sync stopped")

# ê²½ë¡œ ì„¤ì • - ê°œë°œ í™˜ê²½ ì „ìš©
if not getattr(sys, 'frozen', False):
    sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from exchanges.base_exchange import BaseExchange, Position, Signal
from exchanges.bybit_exchange import BybitExchange
from exchanges.lighter_exchange import LighterExchange

try:
    from exchanges.binance_exchange import BinanceExchange
except ImportError:
    BinanceExchange = None

try:
    from exchanges.ccxt_exchange import CCXTExchange, get_supported_exchanges, SUPPORTED_EXCHANGES
except ImportError:
    CCXTExchange = None
    SUPPORTED_EXCHANGES = {}

# Alpha-X7 Core Strategy
from core.strategy_core import AlphaX7Core, TradeSignal
from utils.preset_manager import load_strategy_params

# License Guard
try:
    from core.license_guard import get_license_guard
    HAS_LICENSE_GUARD = True
except ImportError:
    HAS_LICENSE_GUARD = False
    def get_license_guard():
        return None

# ë¡œê¹… ì„¤ì • (GUI ìŠ¤ë ˆë“œì—ì„œë„ ì‘ë™í•˜ë„ë¡ ëª…ì‹œì  í•¸ë“¤ëŸ¬ ì¶”ê°€)
if sys.platform == 'win32':
    sys.stdout.reconfigure(encoding='utf-8')

# [NEW] TimedRotatingFileHandler import
from logging.handlers import TimedRotatingFileHandler

# ë£¨íŠ¸ ë¡œê±° ê°€ì ¸ì˜¤ê¸°
logger = logging.getLogger()
logger.setLevel(logging.INFO)

# ê¸°ì¡´ í•¸ë“¤ëŸ¬ ì œê±° (ì¤‘ë³µ ë°©ì§€)
for handler in logger.handlers[:]:
    logger.removeHandler(handler)

# íŒŒì¼ í•¸ë“¤ëŸ¬ ì¶”ê°€ (bot_log) - ìë™ ë¡œí…Œì´ì…˜
bot_log_file = _get_log_path("bot_log.log")
file_handler = TimedRotatingFileHandler(
    bot_log_file,
    when='midnight',      # ìì •ì— ìë™ ë¶„ë¦¬
    interval=1,
    backupCount=30,       # 30ì¼ ë³´ê´€
    encoding='utf-8'
)
file_handler.suffix = "%Y%m%d"  # bot_log.log.20251221 í˜•íƒœ
file_handler.setLevel(logging.INFO)
file_handler.setFormatter(logging.Formatter('%(asctime)s - %(levelname)s - %(message)s'))
logger.addHandler(file_handler)

# ì½˜ì†” í•¸ë“¤ëŸ¬ ì¶”ê°€
console_handler = logging.StreamHandler(sys.stdout)
console_handler.setLevel(logging.INFO)
console_handler.setFormatter(logging.Formatter('%(asctime)s - %(levelname)s - %(message)s'))
logger.addHandler(console_handler)

print(f"ğŸ› [LOGGING] Configured: {bot_log_file} (auto-rotate at midnight)", flush=True)

# [NEW] trade ì „ìš© ë¡œê±° (trade_log íŒŒì¼) - ìë™ ë¡œí…Œì´ì…˜
trade_logger = logging.getLogger('trade')
trade_logger.setLevel(logging.INFO)
trade_logger.propagate = False

# ê¸°ì¡´ trade_logger í•¸ë“¤ëŸ¬ ì œê±° (ì¤‘ë³µ ë°©ì§€)
for handler in trade_logger.handlers[:]:
    trade_logger.removeHandler(handler)

trade_log_file = _get_log_path("trade_log.log")
trade_file_handler = TimedRotatingFileHandler(
    trade_log_file,
    when='midnight',
    interval=1,
    backupCount=30,
    encoding='utf-8'
)
trade_file_handler.suffix = "%Y%m%d"
trade_file_handler.setLevel(logging.INFO)
trade_file_handler.setFormatter(logging.Formatter('%(asctime)s - %(message)s'))
trade_logger.addHandler(trade_file_handler)

print(f"ğŸ› [LOGGING] Trade log: {trade_log_file} (auto-rotate at midnight)", flush=True)

# ìƒíƒœ íŒŒì¼ (ë ˆê±°ì‹œ - ìƒˆ Storage í´ë˜ìŠ¤ ì‚¬ìš©)
STATE_FILE = "unified_bot_state.json"
HISTORY_FILE = "trade_history.json"

# ìƒˆ Storage í´ë˜ìŠ¤
try:
    from storage.trade_storage import get_trade_storage
    from storage.state_storage import get_state_storage
    USE_NEW_STORAGE = True
except ImportError:
    USE_NEW_STORAGE = False
    logging.warning("New storage modules not found, using legacy storage")


# TF ë§¤í•‘ (Trend TF â†’ Entry TF) - constantsì—ì„œ import
try:
    # [FIX] EXE í™˜ê²½ì—ì„œëŠ” sys.path ì¡°ì‘ ë¶ˆí•„ìš”
    if not getattr(sys, 'frozen', False):
        sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'GUI'))
    from constants import TF_MAPPING, TF_RESAMPLE_MAP, DEFAULT_PARAMS
    from utils.data_utils import resample_data as shared_resample
except ImportError:
    TF_MAPPING = {'1h': '15min', '4h': '1h', '1d': '4h', '1w': '1d'}
    TF_RESAMPLE_MAP = {
        '15min': '15min', '15m': '15min', '30min': '30min', '30m': '30min',
        '1h': '1h', '1H': '1h', '4h': '4h', '4H': '4h', '1d': '1D', '1D': '1D', '1w': '1W', '1W': '1W'
    }
    DEFAULT_PARAMS = {'atr_mult': 1.25, 'slippage': 0.0005, 'fee': 0.00055}
    shared_resample = None


# TF ë¦¬ìƒ˜í”Œë§ ê·œì¹™ (pandas í˜¸í™˜)
# TF ë¦¬ìƒ˜í”Œë§ ê·œì¹™ (pandas í˜¸í™˜)
TF_RESAMPLE_FIX = {
    '15m': '15min', '30m': '30min', 
    '1h': '1h', '2h': '2h', '4h': '4h',
    '1d': '1D', '1w': '1W'
}

def normalize_tf(tf: str) -> str:
    """TF ë¬¸ìì—´ ì •ê·œí™” ('30' -> '30m', '30min' -> '30m')"""
    if tf.isdigit():
        return tf + 'm'
    if tf.endswith('min'):
        return tf.replace('min', 'm')
    return tf

import sys
from pathlib import Path

# [FIX] Add project root to sys.path for module imports
BASE_DIR = Path(__file__).resolve().parent.parent
if str(BASE_DIR) not in sys.path:
    sys.path.insert(0, str(BASE_DIR))

def load_preset(preset_path: str) -> dict:
    """í”„ë¦¬ì…‹ JSON ë¡œë“œ"""
    if not preset_path or not os.path.exists(preset_path):
        return {}
    try:
        with open(preset_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        return data.get('params', data)
    except Exception as e:
        logging.warning(f"í”„ë¦¬ì…‹ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return {}


def resample_data(df, target_tf: str):
    """Entry TF ë¦¬ìƒ˜í”Œë§ + ì§€í‘œ ì¬ê³„ì‚° (ê³µìš© í•¨ìˆ˜ ì‚¬ìš©)"""
    import pandas as pd
    
    # ê³µìš© í•¨ìˆ˜ ì‚¬ìš©
    if shared_resample:
        return shared_resample(df, target_tf, add_indicators=True)
    
    # Fallback
    if target_tf in ('15min', '15m'):
        return df
    rule = TF_RESAMPLE_MAP.get(target_tf, target_tf)
    df = df.copy()
    if 'datetime' not in df.columns:
        if pd.api.types.is_numeric_dtype(df['timestamp']):
            df['datetime'] = pd.to_datetime(df['timestamp'], unit='ms')
        else:
            df['datetime'] = pd.to_datetime(df['timestamp'])
    df = df.set_index('datetime')
    resampled = df.resample(rule).agg({
        'open': 'first', 'high': 'max', 'low': 'min',
        'close': 'last', 'volume': 'sum'
    }).dropna().reset_index()
    try:
        from indicator_generator import IndicatorGenerator
        resampled = IndicatorGenerator.add_all_indicators(resampled)
        if 'rsi' not in resampled.columns and 'rsi_14' in resampled.columns:
            resampled['rsi'] = resampled['rsi_14']
        if 'atr' not in resampled.columns and 'atr_14' in resampled.columns:
            resampled['atr'] = resampled['atr_14']
    except Exception as e:
        logging.warning(f"ì§€í‘œ ì¬ê³„ì‚° ì‹¤íŒ¨: {e}")
    return resampled


class UnifiedBot:
    """
    í†µí•© ë§¤ë§¤ ë´‡
    - W/M íŒ¨í„´ ê°ì§€ (MACD ê¸°ë°˜)
    - Breakeven + Structure Trailing
    - ë°”ì´ë‚¸ìŠ¤ ê¸°ì¤€ ì‹ í˜¸ ì˜µì…˜ (ì„ íƒì )
    """
    
    # íƒ€ì„í”„ë ˆì„ ë§¤í•‘ (Trend TF â†’ Pattern TF, Entry TF)
    TF_MAP = {
        '1h':  {'trend': '60',   'pattern': '60',   'entry': '15'},   # 1h â†’ 1h/15m
        '4h':  {'trend': '240',  'pattern': '60',   'entry': '15'},   # 4h â†’ 1h/15m
        '1d':  {'trend': '1440', 'pattern': '240',  'entry': '60'},   # 1d â†’ 4h/1h
        '3d':  {'trend': '4320', 'pattern': '1440', 'entry': '240'},  # 3d â†’ 1d/4h
        '1w':  {'trend': '10080','pattern': '1440', 'entry': '240'},  # 1w â†’ 1d/4h
    }
    
    # ì „ëµ íŒŒë¼ë¯¸í„° ê¸°ë³¸ê°’ (JSONì—ì„œ ì˜¤ë²„ë¼ì´ë“œ)
    DEFAULT_PATTERN_TOLERANCE = 0.05
    DEFAULT_ENTRY_VALIDITY_HOURS = 4.0
    DEFAULT_ATR_MULT = 1.25  # [FIX] DEFAULT_PARAMSì™€ í†µì¼ (1.5 â†’ 1.25)
    DEFAULT_TRAIL_START_R = 1.0
    DEFAULT_TRAIL_DIST_R = 0.2
    DEFAULT_RSI_PERIOD = 14  # [FIX] 21 â†’ 14 (Standard)
    DEFAULT_PULLBACK_RSI_LONG = 45  # [FIX] 40 â†’ 45 (Relaxed)
    DEFAULT_PULLBACK_RSI_SHORT = 55  # [FIX] 60 â†’ 55 (Relaxed)
    DEFAULT_MAX_ADDS = 1
    DEFAULT_ENABLE_PULLBACK = True  # ë¶ˆíƒ€ê¸° ON/OFF
    
    # ê¸°íƒ€ ì„¤ì •
    MAX_PRICE_DIFF_PCT = 0.003
    USE_4H_TREND_FILTER = True  # TF í•„í„° ê¸°ë³¸ í™œì„±í™”
    USE_VOLUME_FILTER = True
    
    # [Phase 1.3] í•„ìˆ˜ íŒŒë¼ë¯¸í„° - JSONì—ì„œ ë°˜ë“œì‹œ ì œê³µë˜ì–´ì•¼ í•¨
    REQUIRED_PARAMS = ['atr_mult', 'trail_start_r', 'trail_dist_r']
    
    def _validate_required_params(self, params: dict) -> None:
        """í•„ìˆ˜ íŒŒë¼ë¯¸í„° ê²€ì¦ - ì—†ìœ¼ë©´ ì—ëŸ¬"""
        missing = [k for k in self.REQUIRED_PARAMS if k not in params or params.get(k) is None]
        if missing:
            raise ValueError(
                f"âŒ í•„ìˆ˜ íŒŒë¼ë¯¸í„° ëˆ„ë½: {missing}\n"
                f"ìµœì í™”ë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”."
            )
    
    def __init__(self, exchange: BaseExchange, use_binance_signal: bool = False, simulation_mode: bool = False):
        """
        exchange: ì‹¤ì œ ë§¤ë§¤í•  ê±°ë˜ì†Œ
        use_binance_signal: Trueë©´ ë°”ì´ë‚¸ìŠ¤ ë°ì´í„°ë¡œ ì‹ í˜¸ ê°ì§€ (í˜ì´í¬ ë°©ì§€)
        simulation_mode: Trueë©´ ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œ (ì›¹ì†Œì¼“/ì €ì¥/ë™ê¸°í™” ìŠ¤í‚µ)
        """
        self.is_running = True # [NEW] Graceful stop ì œì–´ ë³€ìˆ˜
        self.simulation_mode = simulation_mode
        self.trade_history = []  # ì‹œë®¬ë ˆì´ì…˜ìš© ê±°ë˜ ê¸°ë¡
        
        # [NEW] License Guard ì´ˆê¸°í™”
        if not simulation_mode and HAS_LICENSE_GUARD:
            self.license_guard = get_license_guard()
        else:
            self.license_guard = None
            
        # [FIX] License Sync from Root Manager (Cache Support)
        if self.license_guard:
            try:
                from license_manager import get_license_manager as get_root_lm
                root_lm = get_root_lm()
                if root_lm:
                    tier = root_lm.get_tier()
                    # Sync if valid
                    if tier not in ['TRIAL', 'EXPIRED']:
                        self.license_guard.tier = tier.lower()
                        self.license_guard.days_left = root_lm.get_days_left()
                        self.license_guard.email = root_lm.get_email()
                        logging.info(f"[LICENSE] Synced with cache: {tier} ({self.license_guard.days_left}d)")
            except Exception as e:
                logging.warning(f"[LICENSE] Sync warning: {e}")
        
        # [FIX] í†µí•© íŒŒë¼ë¯¸í„° ë¡œë” ì‚¬ìš©
        from utils.preset_manager import get_backtest_params
        
        # preset_name ì°¾ê¸°: exchange ê°ì²´ë‚˜ config ë”•ì…”ë„ˆë¦¬ì—ì„œ
        # configëŠ” load_strategy_params()ë¡œ ë¡œë“œë˜ë¯€ë¡œ, ë¨¼ì € ë¡œë“œí•´ì•¼ í•¨
        config = load_strategy_params() # ê¸°ì¡´ config ë¡œë“œ ìœ ì§€
        preset_name = getattr(exchange, 'preset_name', None) or config.get('preset_name', None)
        self.preset_name = preset_name # [NEW] Store for health monitoring
        
        # íŒŒë¼ë¯¸í„° ë¡œë“œ
        self.strategy_params = get_backtest_params(preset_name)
        
        # ë¡œê¹…
        logging.info(f"[INIT] Using preset: {preset_name or 'default'}")
        logging.info(f"[INIT] Params: filter_tf={self.strategy_params.get('filter_tf')}, "
                     f"atr_mult={self.strategy_params.get('atr_mult')}, "
                     f"validity={self.strategy_params.get('entry_validity_hours')}h")
        
        # ë©¤ë²„ ë³€ìˆ˜ ì—…ë°ì´íŠ¸ (í•˜ìœ„ í˜¸í™˜ì„± ìœ ì§€)
        self.PATTERN_TOLERANCE = self.strategy_params.get('pattern_tolerance', 0.03)
        self.ENTRY_VALIDITY_HOURS = self.strategy_params.get('entry_validity_hours', 24.0)
        
        # [Phase 1.3] í•„ìˆ˜ íŒŒë¼ë¯¸í„° ê²€ì¦ ë° ì„¤ì • (fallback ì—†ìŒ)
        self._validate_required_params(self.strategy_params)
        self.ATR_MULT = self.strategy_params['atr_mult']
        self.TRAIL_START_R = self.strategy_params['trail_start_r']
        self.TRAIL_DIST_R = self.strategy_params['trail_dist_r']
        self.RSI_PERIOD = self.strategy_params.get('rsi_period', self.DEFAULT_RSI_PERIOD)
        self.PULLBACK_RSI_LONG = self.strategy_params.get('pullback_rsi_long', self.DEFAULT_PULLBACK_RSI_LONG)
        self.PULLBACK_RSI_SHORT = self.strategy_params.get('pullback_rsi_short', self.DEFAULT_PULLBACK_RSI_SHORT)
        self.MAX_ADDS = self.strategy_params.get('max_adds', self.DEFAULT_MAX_ADDS)
        self.ENABLE_PULLBACK = self.strategy_params.get('enable_pullback', self.DEFAULT_ENABLE_PULLBACK)
        self.FILTER_TF = self.strategy_params.get('filter_tf', '4h')
        
        # [NEW] Multi-Timeframe Filter ì„¤ì •
        self.USE_MTF_FILTER = True # ê¸°ë³¸ê°’ True

        logging.info(f"[Config] ì „ëµ íŒŒë¼ë¯¸í„°: ATR={self.ATR_MULT}, Trail={self.TRAIL_START_R}/{self.TRAIL_DIST_R}, Filter={self.FILTER_TF}")
        
        # [NEW] ì‹¤ì‹œê°„ MDD ê´€ë¦¬
        self.daily_start_balance = 0
        self.daily_pnl = 0
        self.stop_trading = False
        self.max_daily_loss_pct = 10.0 # ì¼ì¼ ì†ì‹¤ í•œë„ 10%
        self.last_day = datetime.now().day
        
        self.exchange = exchange
        self.use_binance_signal = use_binance_signal
        self.signal_exchange = None  # ë°”ì´ë‚¸ìŠ¤ ì‹ í˜¸ìš© (í•„ìš”ì‹œ ìƒì„±)
        self.position = None
        self.notifier = None # í…”ë ˆê·¸ë¨ ì•Œë¦¼
        
        # [NEW] ì—°ì† ë°±í…ŒìŠ¤íŠ¸ ìƒíƒœ (run_backtestì™€ ë™ì¼í•œ êµ¬ì¡°)
        self.bt_state = {
            'position': None,
            'positions': [],
            'current_sl': 0,
            'extreme_price': 0,
            'last_time': None
        }
        
        # íƒ€ì„í”„ë ˆì„ ì„¤ì • (exchange configì—ì„œ ë¡œë“œ, ê¸°ë³¸ê°’ 4h)
        tf_key = getattr(exchange, 'timeframe', None) or '4h'
        self.tf_config = self.TF_MAP.get(tf_key, self.TF_MAP['4h']).copy() # copy to avoid mutating class var
        
        # [FIX] Entry TF Override (í”„ë¦¬ì…‹ param ìš°ì„ )
        if 'entry_tf' in self.strategy_params:
            entry_tf_param = normalize_tf(self.strategy_params['entry_tf'])
            # Map '30m' -> '30' or keep as is if not in map, but TF_MAP uses minutes as string
            # Just store it as string, standardizing in resampling logic
            self.tf_config['entry'] = entry_tf_param
            logging.info(f"[TF] Entry TF Overridden by Preset: {entry_tf_param}")

        logging.info(f"[TF] Timeframe: {tf_key} â†’ Trend={self.tf_config['trend']}, Pattern={self.tf_config['pattern']}, Entry={self.tf_config['entry']}")
        
        # [NEW] ë°©í–¥ ì„¤ì • (Both/Long/Short)
        self.direction = getattr(exchange, 'direction', None) or 'Both'
        logging.info(f"[DIR] Direction: {self.direction}")
        
        # [NEW] ë³µë¦¬ ëª¨ë“œ (API íˆìŠ¤í† ë¦¬ ê¸°ë°˜ ìë³¸ ê°±ì‹ )
        self.use_compounding = config.get('use_compounding', True)  # ê¸°ë³¸ í™œì„±í™”
        
        # [NEW] ì´ˆê¸° ìë³¸ ê³ ì • (ë³µë¦¬ ê³„ì‚° ê¸°ì¤€ì )
        self.initial_capital = self.exchange.amount_usd
        
        self.load_state()
        
        # [FIX] ê±°ë˜ì†Œ ì‹¤ì œ í¬ì§€ì…˜ê³¼ ë™ê¸°í™” (ìœ ë ¹ í¬ì§€ì…˜ ë°©ì§€)
        self._sync_with_exchange_position()
        
        logging.info(f"UnifiedBot initialized: {exchange.name} - {exchange.symbol}")
        logging.info(f"Strategy: RSI Trailing (Trail={self.TRAIL_START_R}R, Dist={self.TRAIL_DIST_R}R)")
        
        if use_binance_signal and exchange.name.lower() != 'binance':
            logging.info(f"[SAFE] Binance Signal Mode ENABLED - Using Binance for signal detection")
        
        # Alpha-X7 Core Strategy
        self.strategy = AlphaX7Core(use_mtf=True)  # MTF í•„í„° í™œì„±í™”
        logging.info(f"Strategy: Alpha-X7 Final (Adaptive + MTF + Plus)")
        
        # ìƒˆ Storage ì¸ìŠ¤í„´ìŠ¤ (ê±°ë˜ì†Œ/ì‹¬ë³¼ë³„ ë¶„ë¦¬)
        if USE_NEW_STORAGE and not self.simulation_mode:
            self.trade_storage = get_trade_storage(exchange.name, exchange.symbol)
            self.state_storage = get_state_storage(exchange.name, exchange.symbol)
            logging.info(f"Using new storage: {exchange.name}/{exchange.symbol}")
            
            # [NEW] ê¸°ì¡´ ê±°ë˜ ê¸°ë¡ ë¡œë“œ ë° ë¡œê¹…
            stats = self.trade_storage.get_stats()
            if stats['total_trades'] > 0:
                logging.info(f"ğŸ“Š ê¸°ì¡´ ê±°ë˜ ê¸°ë¡ ë¡œë”©: {stats['total_trades']}ê±´")
                logging.info(f"   ëˆ„ì  PnL: ${stats['total_pnl_usd']:.2f} ({stats['total_pnl_pct']:.2f}%)")
                logging.info(f"   ìŠ¹ë¥ : {stats['win_rate']:.1f}%")
                
                # ë³µë¦¬ ìë³¸ ê³„ì‚° ë° ì ìš©
                if self.use_compounding:
                    self.exchange.capital = self.initial_capital + stats['total_pnl_usd']
                    logging.info(f"ğŸ’° Capital ë³µì›: ${self.initial_capital:.2f} â†’ ${self.exchange.capital:.2f}")

        # [NEW] ë°ì´í„° ë³´í˜¸ë¥¼ ìœ„í•œ Lock
        self._data_lock = threading.Lock()
        
        # ì§€í‘œ ìºì‹œ ì´ˆê¸°í™”
        self.indicator_cache = {}
        # [FIX] _init_indicator_cache removed from __init__ to prevent premature API call
        # It will be called in run() or manually
        # self._init_indicator_cache()
        
        # [NEW] ì£¼ê¸°ì  ì‹œê°„ ë™ê¸°í™” ì‹œì‘ (30ë¶„ë§ˆë‹¤) - ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œì—ì„œëŠ” ìŠ¤í‚µ
        if not self.simulation_mode:
            start_periodic_sync(exchange.name, interval_minutes=30)
        
        # [NEW] WebSocket ê´€ë ¨ ì†ì„±
        self.use_websocket = config.get('use_websocket', True)  # ê¸°ë³¸ í™œì„±í™”
        self.candle_queue = queue.Queue()  # ë´‰ ë§ˆê° í
        self.last_ws_price = None
        self._ws_started = False
        
        # [NEW] ì§€í‘œ ìºì‹œ (ì‚¬ì „ê³„ì‚°ìš©)
        self.indicator_cache = {
            'df_pattern': None,
            'df_entry': None,
            'last_signal': None,
            'last_update': None,
            'ready': False
        }
        
        # [NEW] ì—°ì† ë°±í…ŒìŠ¤íŠ¸ ìƒíƒœ (í•„ìš” ì‹œ run_backtest í™œìš©)
        self.df_pattern_full = None  # ì „ì²´ 1H ë°ì´í„°
        self.df_entry_full = None  # ì „ì²´ 15m ë°ì´í„°
        
        # [NEW] ìºì‹œ íŒŒì¼ ê²½ë¡œ
        exchange_name = self.exchange.name.lower() if hasattr(self.exchange, 'name') else 'bybit'
        symbol_clean = self.exchange.symbol.lower().replace('/', '').replace('-', '') if hasattr(self.exchange, 'symbol') else 'btcusdt'
        from paths import Paths
        self.state_cache_path = os.path.join(Paths.CACHE, f"{exchange_name}_{symbol_clean}_state.json")
        
        # [NEW] UI ë™ê¸°í™”ìš© ìƒíƒœ íŒŒì¼ (ì¸ìŠ¤í„´ìŠ¤ë³„ ìœ ë‹ˆí¬)
        self.state_file = os.path.join(Paths.CACHE, f"bot_state_{exchange_name}_{symbol_clean}.json")
        logging.info(f"[INIT] State file: {self.state_file}")
        
        # [FIX] ì „ëµ íŒŒë¼ë¯¸í„° ì €ì¥ (í”„ë¦¬ì…‹ ë¡œë“œê°’ ìœ ì§€)
        # self.strategy_paramsëŠ” ìœ„ì—ì„œ get_backtest_params()ë¡œ ì´ë¯¸ ì´ˆê¸°í™”ë¨
        # ë¶ˆí•„ìš”í•œ ë®ì–´ì“°ê¸° ì‚­ì œ
        if 'rsi_period' not in self.strategy_params:
             self.strategy_params['rsi_period'] = self.RSI_PERIOD
        if 'atr_period' not in self.strategy_params:
             self.strategy_params['atr_period'] = getattr(self, 'ATR_PERIOD', 14)
        
        # [NEW] í ê¸°ë°˜ ì‹œê·¸ë„ ê´€ë¦¬ (ë ˆê±°ì‹œ detect_signalìš©)
        from collections import deque
        self.pending_signals = deque(maxlen=100)  # ë©”ëª¨ë¦¬ ì•ˆì „: ìµœëŒ€ 100ê°œ ìœ ì§€
        self.last_pattern_check_time = None
        self._last_pending_count = 0  # ì‹ í˜¸ ë³€í™” ì¶”ì ìš©
        
        # [NEW] ë°±ê·¸ë¼ìš´ë“œ ë°ì´í„° ëª¨ë‹ˆí„°ë§ ìŠ¤ë ˆë“œ
        self._data_monitor_thread = None
        self._data_monitor_stop = threading.Event()
        self._data_monitor_interval = 300  # 5ë¶„ë§ˆë‹¤ ê°­ ì²´í¬

    
    # ========== ë°ì´í„°/ìµœì í™” ê²€ì¦ ==========
    
    def _check_data_exists(self) -> dict:
        """ë°ì´í„° íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸"""
        from paths import Paths
        import os
        
        exchange_name = self.exchange.name.lower() if hasattr(self.exchange, 'name') else 'bybit'
        symbol_clean = self.exchange.symbol.lower().replace('/', '').replace('-', '') if hasattr(self.exchange, 'symbol') else 'btcusdt'
        
        required = {
            "15m": os.path.join(Paths.CACHE, f"{exchange_name}_{symbol_clean}_15m.parquet"),
            "1h": os.path.join(Paths.CACHE, f"{exchange_name}_{symbol_clean}_1h.parquet"),
        }
        
        missing = []
        for tf, path in required.items():
            if not os.path.exists(path):
                missing.append(tf)
            else:
                # íŒŒì¼ í¬ê¸°ë„ ì²´í¬ (ìµœì†Œ 10KB)
                try:
                    if os.path.getsize(path) < 10240:
                        missing.append(tf)
                except OSError:
                    missing.append(tf)
        
        return {
            "ready": len(missing) == 0,
            "missing": missing,
            "paths": required,
            "exchange": exchange_name,
            "symbol": symbol_clean
        }
    
    def _check_optimize_exists(self) -> dict:
        """ìµœì í™” ê²°ê³¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸"""
        from paths import Paths
        import os
        
        exchange_name = self.exchange.name.lower() if hasattr(self.exchange, 'name') else 'bybit'
        symbol_clean = self.exchange.symbol.lower().replace('/', '').replace('-', '') if hasattr(self.exchange, 'symbol') else 'btcusdt'
        
        # ìµœì í™” í”„ë¦¬ì…‹ ê²½ë¡œ
        preset_path = os.path.join(Paths.PRESETS, f"{exchange_name}_{symbol_clean}_optimized.json")
        
        # ê¸°ë³¸ í”„ë¦¬ì…‹ë„ í™•ì¸
        default_preset = os.path.join(Paths.PRESETS, "default.json")
        
        return {
            "ready": os.path.exists(preset_path) or os.path.exists(default_preset),
            "optimized_path": preset_path,
            "has_optimized": os.path.exists(preset_path),
            "has_default": os.path.exists(default_preset),
            "exchange": exchange_name,
            "symbol": symbol_clean
        }
    
    def get_readiness_status(self) -> dict:
        """ë´‡ ì‹œì‘ ì¤€ë¹„ ìƒíƒœ ì „ì²´ í™•ì¸"""
        data_check = self._check_data_exists()
        opt_check = self._check_optimize_exists()
        
        return {
            "ready": data_check["ready"] and opt_check["ready"],
            "data": data_check,
            "optimize": opt_check,
            "message": self._get_readiness_message(data_check, opt_check)
        }
    
    def _get_readiness_message(self, data: dict, opt: dict) -> str:
        """ì¤€ë¹„ ìƒíƒœ ë©”ì‹œì§€"""
        if data["ready"] and opt["ready"]:
            return "âœ… ë´‡ ì‹œì‘ ì¤€ë¹„ ì™„ë£Œ"
        
        msgs = []
        if not data["ready"]:
            msgs.append(f"ğŸ“Š ë°ì´í„° í•„ìš”: {', '.join(data['missing'])}")
        if not opt["ready"]:
            msgs.append("âš™ï¸ ìµœì í™” í•„ìš”")
        
        return " | ".join(msgs)
    
    # ========== ì§€í‘œ ìºì‹œ ë©”ì„œë“œ ==========
    
    def _init_indicator_cache(self):
        """ë´‡ ì‹œì‘ ì‹œ ì´ˆê¸° ìº”ë“¤+ì§€í‘œ ë¡œë“œ + ë°±í…ŒìŠ¤íŠ¸ ìƒíƒœ ì´ˆê¸°í™”"""
        try:
            sig_exchange = self._get_signal_exchange()
            pattern_tf = self.tf_config.get('pattern', '60')
            entry_tf = self.tf_config.get('entry', '15')
            
            df_pattern = sig_exchange.get_klines(pattern_tf, 300)
            df_entry = sig_exchange.get_klines(entry_tf, 500)
            
            if df_pattern is None or df_entry is None:
                logging.warning("[CACHE] Failed to load initial data")
                return
            
            try:
                from indicator_generator import IndicatorGenerator
                df_pattern = IndicatorGenerator.add_all_indicators(df_pattern)
                df_entry = IndicatorGenerator.add_all_indicators(df_entry)
            except ImportError:
                logging.warning("[CACHE] IndicatorGenerator not available")
            
            self.indicator_cache['df_pattern'] = df_pattern
            self.indicator_cache['df_entry'] = df_entry
            logging.info(f"[CACHE] Init: pattern={len(df_pattern)}, entry={len(df_entry)}")
            
            # 1. ì „ì²´ ë°ì´í„° ë¡œë“œ (Parquet)
            if self._load_full_historical_data():
                # 2. REST APIë¡œ ìµœì‹  Gap ë³´ì¶© [FIX]
                logging.info("[INIT] Checking for data gap before startup...")
                self._backfill_missing_candles()
                
                # 3. ì´ˆê¸° ë°±í…ŒìŠ¤íŠ¸ ë° ìƒíƒœ ë³µêµ¬
                self._run_backtest_to_now()
                
                # 4. ê±°ë˜ì†Œ í¬ì§€ì…˜ê³¼ ë™ê¸°í™”
                self.sync_position()
            else:
                logging.warning("[INIT] Using websocket-only mode (no historical data)")
                
        except Exception as e:
            logging.error(f"[CACHE] Init error: {e}")
    
    def _load_full_historical_data(self) -> bool:
        """Parquetì—ì„œ ì „ì²´ íˆìŠ¤í† ë¦¬ ë¡œë“œ (Entry TF ë¦¬ìƒ˜í”Œë§ í¬í•¨)"""
        try:
            from paths import Paths
            
            cache_dir = Path(Paths.CACHE)
            exchange_name = self.exchange.name.lower()
            symbol_clean = self.exchange.symbol.lower().replace('/', '')
            
            # 1. ì›ë³¸ 15m ë°ì´í„° ë¡œë“œ
            entry_file = cache_dir / f"{exchange_name}_{symbol_clean}_15m.parquet"
            if entry_file.exists():
                df_original = pd.read_parquet(entry_file)
                # Timestamp ë³€í™˜/ì •ê·œí™”
                if 'timestamp' in df_original.columns:
                    if pd.api.types.is_numeric_dtype(df_original['timestamp']):
                        df_original['timestamp'] = pd.to_datetime(df_original['timestamp'], unit='ms')
                    else:
                        df_original['timestamp'] = pd.to_datetime(df_original['timestamp'])
                    df_original = df_original.set_index('timestamp')
                
                logging.info(f"[INIT] Loaded {len(df_original)} 15m candles from Parquet")
                
                # ì›ë³¸ ë°ì´í„° ì„¤ì •
                self.df_entry_full = df_original.copy()
                if 'timestamp' not in self.df_entry_full.columns:
                    self.df_entry_full = self.df_entry_full.reset_index()
                    if 'index' in self.df_entry_full.columns:
                        self.df_entry_full = self.df_entry_full.rename(columns={'index': 'timestamp'})
                
                # íŒŒìƒ ë°ì´í„° ìƒì„± (Resampled, Indicators)
                self._process_historical_data()
                return True
            else:
                logging.warning(f"[INIT] 15m parquet not found: {entry_file}")
                
                # [NEW] REST APIë¡œ ìë™ ìˆ˜ì§‘ (Safety Net)
                logging.info("[DATA] ğŸ”„ Parquet missing. Fetching baseline from REST API...")
                df_rest = self._fetch_historical_from_rest(limit=1000)
                
                if df_rest is not None and len(df_rest) > 0:
                    self.df_entry_full = df_rest.copy()
                    # Parquet ì €ì¥ (ë‹¤ìŒ ì‹¤í–‰ ì‹œ ë¡œë“œ ê°€ëŠ¥í•˜ë„ë¡)
                    self._save_to_parquet()
                    logging.info(f"[DATA] âœ… Baseline fetched and saved: {len(df_rest)} candles")
                    
                    # íŒŒìƒ ë°ì´í„° ìƒì„±
                    self._process_historical_data()
                    return True
                    
                return False
                
        except Exception as e:
            logging.error(f"[INIT] Data load failed: {e}")
            import traceback
            traceback.print_exc()
            return False

    def _process_historical_data(self):
        """ì›ë³¸ ë°ì´í„°(df_entry_full)ë¡œë¶€í„° ë¦¬ìƒ˜í”Œë§ ë° ì§€í‘œ ìƒì„±"""
        if self.df_entry_full is None or self.df_entry_full.empty:
            return

        try:
            from indicator_generator import IndicatorGenerator
            
            # 1. Entry TF ë¦¬ìƒ˜í”Œë§ (ì „ëµ ê³„ì‚°ìš©)
            entry_tf = self.strategy_params.get('entry_tf', '15m')
            if entry_tf in ['15m', '15min']:
                self.df_entry_resampled = self.df_entry_full.copy()
            else:
                resample_rule = TF_RESAMPLE_FIX.get(entry_tf, entry_tf)
                if resample_rule.endswith('m') and not resample_rule.endswith('min'):
                    resample_rule = resample_rule.replace('m', 'min')

                logging.info(f"[INIT] Resampling Entry Data: 15m -> {entry_tf} (rule={resample_rule})")
                
                df_temp = self.df_entry_full.set_index('timestamp')
                self.df_entry_resampled = df_temp.resample(resample_rule).agg({
                    'open': 'first', 'high': 'max', 'low': 'min', 
                    'close': 'last', 'volume': 'sum'
                }).dropna().reset_index()
            
            # Entry indicators ì¶”ê°€
            self.df_entry_resampled = IndicatorGenerator.add_all_indicators(self.df_entry_resampled)
            logging.info(f"[INIT] df_entry processed ({entry_tf}): {len(self.df_entry_resampled)}ê°œ")
            
            # 2. Pattern Data ìƒì„± (í•­ìƒ 1h)
            df_temp = self.df_entry_full.set_index('timestamp')
            self.df_pattern_full = df_temp.resample('1h').agg({
                'open': 'first', 'high': 'max', 'low': 'min', 
                'close': 'last', 'volume': 'sum'
            }).dropna().reset_index()
            
            # Pattern indicators ì¶”ê°€
            self.df_pattern_full = IndicatorGenerator.add_all_indicators(self.df_pattern_full)
            
            if 'timestamp' not in self.df_pattern_full.columns:
                self.df_pattern_full = self.df_pattern_full.reset_index()
                if 'index' in self.df_pattern_full.columns:
                    self.df_pattern_full = self.df_pattern_full.rename(columns={'index': 'timestamp'})
            
            logging.info(f"[INIT] df_pattern processed (1h): {len(self.df_pattern_full)}ê°œ")
            
            # [FIX] indicator_cache ë™ê¸°í™”
            self.indicator_cache['df_pattern'] = self.df_pattern_full
            self.indicator_cache['df_entry'] = self.df_entry_resampled
            self.indicator_cache['last_update'] = datetime.utcnow()
            
        except Exception as e:
            logging.error(f"[INIT] Data processing failed: {e}")
    
    def _run_backtest_to_now(self) -> bool:
        """ì „ì²´ ë°±í…ŒìŠ¤íŠ¸ ì‹¤í–‰ â†’ ìƒíƒœ ë³µêµ¬ + ê²°ê³¼ ì¶œë ¥ (ìºì‹œ ìš°ì„ )"""
        print("ğŸ› [BACKTEST] _run_backtest_to_now START", flush=True)
        
        # [NEW] ìºì‹œ ì²´í¬
        if self._load_state_cache():
            logging.info("[INIT] âœ… ìºì‹œì—ì„œ ìƒíƒœ ë¡œë“œ ì„±ê³µ, ë°±í…ŒìŠ¤íŠ¸ ìŠ¤í‚µ")
            return True

        if self.df_pattern_full is None or getattr(self, 'df_entry_resampled', None) is None:
            print("ğŸ› [BACKTEST] No data!", flush=True)
            logging.warning("[INIT] No historical data for backtest")
            return False
        
        try:
            from core.strategy_core import AlphaX7Core
            
            core = AlphaX7Core(use_mtf=True)
            params = self.strategy_params
            leverage = getattr(self.exchange, 'leverage', 1)
            
            df_entry = self.df_entry_resampled
            logging.info(f"[INIT] Running backtest: pattern={len(self.df_pattern_full)}, entry={len(df_entry)}, leverage={leverage}x")
            
            result = core.run_backtest(
                df_pattern=self.df_pattern_full,
                df_entry=df_entry,
                slippage=params.get('slippage', 0.0005),
                atr_mult=params['atr_mult'],  # [Phase 1.3] í•„ìˆ˜
                trail_start_r=params['trail_start_r'],  # [Phase 1.3] í•„ìˆ˜
                trail_dist_r=params['trail_dist_r'],  # [Phase 1.3] í•„ìˆ˜
                pattern_tolerance=params.get('pattern_tolerance', 0.03),
                entry_validity_hours=params.get('entry_validity_hours', 6.0),
                pullback_rsi_long=params.get('pullback_rsi_long', 40),
                pullback_rsi_short=params.get('pullback_rsi_short', 60),
                filter_tf=params.get('filter_tf', '4h'),
                rsi_period=params.get('rsi_period', 14),
                atr_period=params.get('atr_period', 14),
                return_state=True
            )
            

            
            if isinstance(result, tuple):
                trades = result[0]
                state = result[1] if len(result) > 1 else {}
            else:
                trades = result
                state = {}
            
            # ê²°ê³¼ ê³„ì‚° (ë ˆë²„ë¦¬ì§€ ì ìš©)
            if trades:
                wins = [t for t in trades if t.get('pnl_pct', t.get('pnl', 0)) > 0]
                total_pnl = sum(t.get('pnl_pct', t.get('pnl', 0)) for t in trades)
                total_pnl_leveraged = total_pnl * leverage
                win_rate = len(wins) / len(trades) * 100 if trades else 0
                

                logging.info(f"[INIT] âœ… Backtest: {len(trades)} trades, WinRate={win_rate:.1f}%, PnL={total_pnl_leveraged:.2f}% (Lev={leverage}x)")
            else:
                # print("âœ… [BACKTEST] 0 trades", flush=True)
                logging.info("[INIT] âœ… Backtest: 0 trades")
            
            # ìƒíƒœ ë³µêµ¬
            if not state:
                state = {'position': None, 'pending': [], 'positions': []}
            
            self.bt_state = state

            # [FIX] 12ì‹œê°„ ì´ë‚´ ì‹ í˜¸ë§Œ ìœ ì§€
            valid_pending = self._filter_valid_signals(state.get('pending', []))
            state['pending'] = valid_pending
            
            # pending_signals deque ë™ê¸°í™”
            from collections import deque
            self.pending_signals = deque(valid_pending, maxlen=100)
            
            logging.info(f"[INIT] Pending signals (filtered): {len(valid_pending)}")
            
            # [NEW] ìºì‹œ ì €ì¥
            self._save_state_cache()
            
            return True
            
        except Exception as e:

            logging.error(f"[INIT] Backtest failed: {e}")
            import traceback
            traceback.print_exc()
            return False

    def _load_state_cache(self) -> bool:
        """1ì‹œê°„ ì´ë‚´ ìºì‹œ ìˆìœ¼ë©´ ë¡œë“œ (ì‹ í˜¸ í•„í„°ë§ í¬í•¨)"""
        import os, json
        from datetime import datetime, timedelta
        
        if not os.path.exists(self.state_cache_path):
            return False
        
        try:
            # íŒŒì¼ ìˆ˜ì • ì‹œê°„ ì²´í¬
            mtime = datetime.fromtimestamp(os.path.getmtime(self.state_cache_path))
            if datetime.now() - mtime > timedelta(hours=1):
                logging.info(f"[CACHE] Expired: {self.state_cache_path}")
                return False  # 1ì‹œê°„ ì§€ë‚¨ â†’ ë¬´íš¨
            
            with open(self.state_cache_path, 'r', encoding='utf-8') as f:
                state = json.load(f)
            
            # pending ì‹ í˜¸ í•„í„°ë§ (12ì‹œê°„ ì´ë‚´ë§Œ)
            signals = state.get('pending', [])
            valid_signals = self._filter_valid_signals(signals)
            
            # bt_state ë³µêµ¬ (pendingë§Œì´ë¼ë„)
            if self.bt_state is None:
                self.bt_state = {'position': None, 'pending': [], 'positions': [], 'last_time': datetime.utcnow()}
            
            self.bt_state['pending'] = valid_signals
            
            # pending_signals dequeì—ë„ ë™ê¸°í™”
            from collections import deque
            self.pending_signals = deque(valid_signals, maxlen=100)
            
            logging.info(f"[CACHE] Loaded {len(valid_signals)} valid signals from cache")
            return len(valid_signals) > 0  # ì‹ í˜¸ê°€ í•˜ë‚˜ë¼ë„ ìˆì–´ì•¼ ì„±ê³µìœ¼ë¡œ ê°„ì£¼í• ì§€ ê³ ë¯¼... 
            # ì¼ë‹¨ ë¡œë“œ ì„±ê³µí•˜ë©´ True
            return True
            
        except Exception as e:
            logging.error(f"[CACHE] Load error: {e}")
            return False

    def _save_state_cache(self):
        """í˜„ì¬ ìƒíƒœ ìºì‹œ ì €ì¥"""
        import os, json
        from datetime import datetime
        
        try:
            os.makedirs(os.path.dirname(self.state_cache_path), exist_ok=True)
            
            # pending_signalsëŠ” dequeì´ë¯€ë¡œ listë¡œ ë³€í™˜
            pending_list = list(self.pending_signals)
            
            state = {
                'pending': pending_list,
                'last_update': datetime.utcnow().isoformat()
            }
            
            with open(self.state_cache_path, 'w', encoding='utf-8') as f:
                json.dump(state, f, indent=2, default=str)
                
            logging.debug(f"[CACHE] Saved: {len(pending_list)} signals")
        except Exception as e:
            logging.error(f"[CACHE] Save error: {e}")

    def _filter_valid_signals(self, signals: list) -> list:
        """12ì‹œê°„ ì´ë‚´ ì‹ í˜¸ë§Œ ë°˜í™˜"""
        from datetime import datetime, timedelta
        import pandas as pd
        
        now = datetime.utcnow()
        validity = timedelta(hours=12)
        valid = []
        
        for sig in signals:
            try:
                # [FIX] DataFrame ëª¨í˜¸ì„± ë°©ì§€: or ì—°ì‚° ëŒ€ì‹  ëª…ì‹œì  get() ì‚¬ìš©
                sig_time_raw = sig.get('entry_time')
                if sig_time_raw is None:
                    sig_time_raw = sig.get('timestamp')
                if sig_time_raw is None:
                    sig_time_raw = sig.get('time')
                if not sig_time_raw:
                    continue
                    
                if isinstance(sig_time_raw, str):
                    # ISO format parsing
                    sig_time = pd.to_datetime(sig_time_raw.replace('Z', '')).to_pydatetime()
                elif isinstance(sig_time_raw, (int, float)):
                    sig_time = datetime.fromtimestamp(sig_time_raw / 1000)
                else:
                    sig_time = sig_time_raw
                
                # í˜„ì¬ ì‹œê°„ ê¸°ì¤€ 12ì‹œê°„ ì´ë‚´ë§Œ
                if now - validity <= sig_time <= now + timedelta(hours=1):
                    valid.append(sig)
            except Exception as e:
                logging.debug(f"[FILTER] Signal time parse error: {e}")
                continue
        
        return valid

    def _add_signal_to_queue(self, signal: dict):
        """ìœ íš¨ì„± ì²´í¬ í›„ ì‹ í˜¸ íì— ì¶”ê°€"""
        filtered = self._filter_valid_signals([signal])
        if filtered:
            s = filtered[0]
            # ì¤‘ë³µ ì²´í¬ (Robust Key-based: Timestamp + Direction)
            sig_key = f"{s.get('time', '')}_{s.get('type', '')}"
            existing_keys = {f"{p.get('time', '')}_{p.get('type', '')}" for p in self.pending_signals}
            
            if sig_key in existing_keys:
                # logging.debug(f"[QUEUE] Skipping duplicate: {sig_key}")
                return
                
            self.pending_signals.append(s)
            
            # [FIX] DataFrame ëª¨í˜¸ì„± ë°©ì§€: dict.get() ê¸°ë³¸ê°’ í™œìš©
            # [FIX] Safe Access for Signal Object or Dict
            if isinstance(s, dict):
                sig_type = s.get('type') or s.get('direction', 'Unknown')  # getattr equivalent
                sig_time = s.get('time') or s.get('timestamp', 'N/A')  # getattr equivalent
            else:
                sig_type = getattr(s, 'type', None) or getattr(s, 'direction', 'Unknown')
                sig_time = getattr(s, 'time', None) or getattr(s, 'timestamp', 'N/A')
                
            logging.info(f"[LIVE] âœ¨ New signal queued: {sig_type} @ {sig_time}")
            self._save_state_cache()
        else:
            logging.debug(f"[LIVE] Signal expired or invalid, skipped: {getattr(signal, 'time', signal.get('time')) if isinstance(signal, dict) else getattr(signal, 'time', 'Unknown')}")
    
    # ========== ì—°ì† ë°±í…ŒìŠ¤íŠ¸ ë©”ì„œë“œ (run_backtest ë¡œì§ê³¼ 100% ë™ì¼) ==========
    
    def _continue_backtest(self, new_candle_1h: dict = None, new_candle_15m: dict = None) -> dict:
        """ìƒˆ ìº”ë“¤ ì¶”ê°€ í›„ ë°±í…ŒìŠ¤íŠ¸ ì—°ì† ì‹¤í–‰"""
        if self.bt_state is None:
            return None
        
        from core.strategy_core import AlphaX7Core
        import pandas as pd
        
        state = self.bt_state
        params = self.strategy_params
        
        # [FIX] ìƒˆ ìº”ë“¤ ë°ì´í„° ì¶”ê°€ (ì¤‘ë³µ ë°©ì§€: ì´ë¯¸ _on_candle_closeì—ì„œ ì¶”ê°€ë¨)
        # ë‹¨, 1HëŠ” ì—¬ê¸°ì„œ ì¶”ê°€
        if new_candle_1h and self.df_pattern_full is not None:
            new_row = pd.DataFrame([new_candle_1h])
            self.df_pattern_full = pd.concat([self.df_pattern_full, new_row], ignore_index=True)
            self.df_pattern_full = self.df_pattern_full.drop_duplicates(subset='timestamp', keep='last')
            
            # ìƒˆ ì‹œê·¸ë„ ì¶”ì¶œ
            core = AlphaX7Core(use_mtf=True)
            new_signals = core._extract_new_signals(
                self.df_pattern_full,
                since=state['last_time'],
                tolerance=params.get('pattern_tolerance', 0.03),
                validity_hours=params.get('entry_validity_hours', 6.0)
            )
            
            # pendingì— ì¶”ê°€ (í•„í„°ë§ ì ìš©)
            for s in new_signals:
                self._add_signal_to_queue(s)
                
                # [NEW] íŒ¨í„´ ê°ì§€ ì‹œ í…”ë ˆê·¸ë¨ ì•Œë¦¼
                if self.notifier:
                    try:
                        # ì˜ˆìƒ ì§„ì… ê¸ˆì•¡ ê³„ì‚°
                        balance = getattr(self.exchange, 'capital', 1000)
                        leverage = self.strategy_params.get('leverage', 5)
                        expected_amount = balance * 0.98 * leverage
                        
                        msg = (f"ğŸ”” íŒ¨í„´ ê°ì§€!\n"
                               f"â”Œ ë°©í–¥: {s['type']}\n"
                               f"â”œ íŒ¨í„´: {s.get('pattern', 'W/M')}\n"
                               f"â”œ ì˜ˆìƒ ê¸ˆì•¡: ${expected_amount:,.0f}\n"
                               f"â”œ SL: ${s.get('sl', 0):,.0f}\n"
                               f"â”” ë§Œë£Œ: {params.get('entry_validity_hours', 6)}ì‹œê°„\n"
                               f"â³ ì¶”ì„¸ í•„í„° í†µê³¼ ì‹œ ì§„ì…...")
                        self.notifier.send_message(msg)
                    except Exception as e:
                        logging.debug(f"[SIGNAL] Alert send failed: {e}")
        
        # í˜„ì¬ ì‹œê°„
        if new_candle_15m:
            current_time = pd.Timestamp(new_candle_15m.get('timestamp', pd.Timestamp.now()))
        else:
            current_time = pd.Timestamp.now()
        
        # ë§Œë£Œëœ ì‹œê·¸ë„ ì œê±°
        state['pending'] = [s for s in state['pending'] if s.get('expire_time', current_time + pd.Timedelta(hours=1)) > current_time]
        
        # [FIX] 6. ì‹¤ì‹œê°„ ì‹ í˜¸ ë™ê¸°í™” (pending_signals -> state['pending'])
        if self.pending_signals:
            for s in list(self.pending_signals):
                # ì¤‘ë³µ ì²´í¬ í›„ ì¶”ê°€
                if not any(p.get('time') == s.get('time') for p in state['pending']):
                    # expire_time ì„¤ì • (ì—†ì„ ê²½ìš°)
                    if 'expire_time' not in s:
                        sig_time = pd.Timestamp(s.get('time') or s.get('timestamp'))
                        s['expire_time'] = sig_time + pd.Timedelta(hours=params.get('entry_validity_hours', 6.0))
                    
                    state['pending'].append(s)
            
            logging.info(f"[SYNC] Synchronized {len(self.pending_signals)} signals to state queue (Total: {len(state['pending'])})")
            self.pending_signals.clear()  # ë™ê¸°í™” í›„ í´ë¦¬ì–´
        
        # í¬ì§€ì…˜ ê´€ë¦¬ ë˜ëŠ” ì‹ ê·œ ì§„ì…
        action = None
        
        if state['position']:
            # í¬ì§€ì…˜ ê´€ë¦¬ (íŠ¸ë ˆì¼ë§)
            action = self._manage_position_live(state, new_candle_15m)
        else:
            # ì‹ ê·œ ì§„ì… ì²´í¬
            action = self._check_entry_live(state, new_candle_15m)
        
        # ìƒíƒœ ì—…ë°ì´íŠ¸
        state['last_time'] = current_time
        state['last_idx'] = state.get('last_idx', 0) + 1
        
        return action  # âœ… action ë¦¬í„´ ì¶”ê°€
    
    def _manage_position_live(self, state: dict, candle: dict) -> dict:
        """ì‹¤ì‹œê°„ í¬ì§€ì…˜ ê´€ë¦¬ (run_backtest ë¡œì§ ë™ì¼)"""
        if candle is None:
            return None
            
        from core.strategy_core import AlphaX7Core
        
        core = AlphaX7Core()
        params = self.strategy_params
        
        high = float(candle.get('high', 0))
        low = float(candle.get('low', 0))
        
        # RSI ê³„ì‚° (ì¸ë¼ì¸)
        # [FIX] DataFrameì€ or ì—°ì‚°ì ì‚¬ìš© ë¶ˆê°€ - is None ì²´í¬ ì‚¬ìš©
        df_entry = getattr(self, 'df_entry_resampled', None)
        if df_entry is None or (hasattr(df_entry, 'empty') and df_entry.empty):
            df_entry = self.df_entry_full
        if df_entry is not None and len(df_entry) >= 30:
            rsi_period = params.get('rsi_period', 14)
            closes = df_entry['close'].tail(rsi_period + 10)
            delta = closes.diff()
            gain = (delta.where(delta > 0, 0)).rolling(window=rsi_period).mean()
            loss = (-delta.where(delta < 0, 0)).rolling(window=rsi_period).mean()
            rs = gain / loss.replace(0, 1e-10)
            rsi_series = 100 - (100 / (1 + rs))
            current_rsi = float(rsi_series.iloc[-1]) if not rsi_series.empty else 50
        else:
            current_rsi = 50
        
        direction = state.get('position')
        entry_price = state.get('positions', [{}])[0].get('entry', candle.get('open', 0)) if state.get('positions') else candle.get('open', 0)
        current_sl = state.get('current_sl', 0)
        extreme_price = state.get('extreme_price', entry_price)
        
        # [FIX] risk ê³„ì‚° - safe access
        initial_sl = state.get('positions', [{}])[0].get('initial_sl', current_sl) if state.get('positions') else current_sl
        risk = abs(entry_price - initial_sl)
        if risk == 0:
            risk = entry_price * 0.01
        
        result = self.strategy.manage_position_realtime(
            position_side=direction,
            entry_price=entry_price,
            current_sl=current_sl,
            extreme_price=extreme_price,
            current_high=high,
            current_low=low,
            current_rsi=current_rsi,
            trail_start_r=params['trail_start_r'],  # [Phase 1.3] í•„ìˆ˜
            trail_dist_r=params['trail_dist_r'],  # [Phase 1.3] í•„ìˆ˜
            risk=risk,
            pullback_rsi_long=params.get('pullback_rsi_long', 40),
            pullback_rsi_short=params.get('pullback_rsi_short', 60)
        )
        
        # SL Hit
        if result.get('sl_hit'):
            sl_price = result.get('sl_price', current_sl)
            logging.info(f"[LIVE] ğŸ”´ SL HIT: {direction} @ {sl_price:.2f}")
            
            if not getattr(self.exchange, 'dry_run', False):
                try:
                    self.exchange.close_position()
                except Exception as e:
                    logging.error(f"[LIVE] âŒ SL Close Error: {e}")
            
            state['position'] = None
            state['positions'] = []
            return {'action': 'CLOSE', 'direction': direction, 'price': sl_price, 'reason': 'SL_HIT'}
        
        # ìƒíƒœ ì—…ë°ì´íŠ¸
        state.update({'extreme_price': result.get('new_extreme')})
        
        # [FIX] SL ì—…ë°ì´íŠ¸ - API í˜¸ì¶œ
        new_sl_val = result.get('new_sl')
        if new_sl_val:
            if (direction == 'Long' and new_sl_val > current_sl) or \
               (direction == 'Short' and new_sl_val < current_sl):
                if not getattr(self.exchange, 'dry_run', False):
                    if self.exchange.update_stop_loss(new_sl_val):
                        state.update({'current_sl': new_sl_val})
                        logging.info(f"[LIVE] ğŸ“ˆ SL Updated (API): {new_sl_val:.2f}")
                    else:
                        logging.warning("[LIVE] âš ï¸ SL Update API failed")
                else:
                    state.update({'current_sl': new_sl_val})
                    logging.info(f"[LIVE] ğŸ“ˆ SL Updated (DRY): {new_sl_val:.2f}")
        
        # í’€ë°± ì¶”ê°€ ì§„ì…
        enable_pullback = params.get('enable_pullback', False)
        max_adds = params.get('max_adds', 1)
        current_adds = len(state['positions']) - 1
        
        if enable_pullback and current_adds < max_adds:
            should_add = self.strategy.should_add_position_realtime(
                direction=direction,
                current_rsi=current_rsi,
                pullback_rsi_long=params.get('pullback_rsi_long', 40),
                pullback_rsi_short=params.get('pullback_rsi_short', 60)
            )
            if should_add:
                return {'action': 'ADD', 'direction': direction, 'price': float(candle.get('close', 0)), 'reason': 'PULLBACK'}
        
        return None
    
    def _check_entry_live(self, state: dict, candle: dict) -> dict:
        """ì‹ ê·œ ì§„ì… ì²´í¬ (run_backtest ë¡œì§ ë™ì¼)"""
        if candle is None:
            return None
        if not state.get('pending'):
            return None
        
        # [NEW] ê³µìš© ì¡°ê±´ ì²´í¬ ë©”ì„œë“œ í™œìš© (100% ì¼ì¹˜ ë³´ì¥)
        cond = self._get_current_trading_conditions()
        if not cond['ready']:
            return None
            
        direction_code = cond['direction'] # 'LONG' or 'SHORT'
        direction = 'Long' if direction_code == 'LONG' else 'Short'
        
        # íœë”© ì¤‘ì¸ ì‹ í˜¸ ì¤‘ í•´ë‹¹ ë°©í–¥ì´ ìˆëŠ”ì§€ í™•ì¸
        matching_signal = next((s for s in state['pending'] if s['type'].capitalize() == direction), None)
        if not matching_signal:
            return None

        # ATR ë° SL ê³„ì‚°
        from core.strategy_core import AlphaX7Core
        core = AlphaX7Core(use_mtf=True)
        params = self.strategy_params
        
        df_entry = getattr(self, 'df_entry_resampled', None)
        if df_entry is None:
            df_entry = self.df_entry_full
            
        if df_entry is not None and len(df_entry) >= 20:
            atr = core.calculate_atr(df_entry.tail(20), period=params.get('atr_period', 14))
        else:
            atr = 100  # ê¸°ë³¸ê°’
            
        entry_price = float(candle.get('close', candle.get('open', 0)))
        atr_mult = params['atr_mult']
        
        if direction == 'Long':
            sl = entry_price - atr * atr_mult
        else:
            sl = entry_price + atr * atr_mult
            
        risk = abs(entry_price - sl)
        trail_start_r = params['trail_start_r']
        trail_dist_r = params['trail_dist_r']
        
        # ìƒíƒœ ì—…ë°ì´íŠ¸
        state['position'] = direction
        state['positions'] = [{'entry_time': candle.get('timestamp'), 'entry': entry_price}]
        state['current_sl'] = sl
        state['extreme_price'] = entry_price
        state['trail_start'] = entry_price + risk * trail_start_r if direction == 'Long' else entry_price - risk * trail_start_r
        state['trail_dist'] = risk * trail_dist_r
        state['add_count'] = 0
        state['pending'] = []  # ì§„ì… í›„ pending í´ë¦¬ì–´
        
        logging.info(f"[LIVE] ğŸŸ¢ ENTRY: {direction_code} @ {entry_price:.2f}, SL={sl:.2f}, Pattern={matching_signal.get('pattern', 'W/M')}")
        
        return {
            'action': 'ENTRY',
            'direction': direction,
            'price': entry_price,
            'sl': sl,
            'pattern': matching_signal.get('pattern', 'W/M')
        }

    def _get_current_trading_conditions(self) -> dict:
        """[CORE] í†µí•© ì§„ì… ì¡°ê±´ íŒë‹¨ (ì˜ˆì¸¡/ì‹¤í–‰ ê³µìš©)"""
        try:
            from core.strategy_core import AlphaX7Core
            core = AlphaX7Core(use_mtf=True)
            params = self.strategy_params
            
            # 1. íœë”© ë°ì´í„° í™•ì¸
            pending_signals = []
            if hasattr(self, 'bt_state') and self.bt_state:
                pending_signals.extend(self.bt_state.get('pending', []))
            if hasattr(self, 'pending_signals'):
                pending_signals.extend(self.pending_signals)
                
            now = datetime.utcnow()
            valid_pending = [p for p in pending_signals if p.get('expire_time', now + timedelta(hours=1)) > now]
            
            pending_long = any(p['type'] in ('Long', 'W', 'LONG') for p in valid_pending)
            pending_short = any(p['type'] in ('Short', 'M', 'SHORT') for p in valid_pending)
            
            # 2. RSI í™•ì¸ (ìºì‹œ ë˜ëŠ” ê³„ì‚°)
            df_entry = getattr(self, 'df_entry_resampled', None)
            if df_entry is None:
                df_entry = self.indicator_cache.get('df_entry')
            if df_entry is None:
                df_entry = self.df_entry_full
                
            rsi = 50.0
            rsi_long_met = False
            rsi_short_met = False
            
            if df_entry is not None and len(df_entry) >= 20:
                # 1. ìºì‹œëœ RSI í™•ì¸
                if 'rsi' in df_entry.columns:
                    rsi = float(df_entry['rsi'].iloc[-1])
                elif 'rsi_14' in df_entry.columns:
                    rsi = float(df_entry['rsi_14'].iloc[-1])
                
                # 2. [FIX] RSIê°€ NaNì´ë©´ ì¦‰ì‹œ ê³„ì‚° (IndicatorGenerator ë¯¸í˜¸ì¶œ ëŒ€ë¹„)
                if np.isnan(rsi):
                    try:
                        rsi_period = params.get('rsi_period', 14)
                        closes = df_entry['close'].tail(rsi_period + 50) # ì¶©ë¶„í•œ ë°ì´í„°
                        delta = closes.diff()
                        gain = (delta.where(delta > 0, 0)).rolling(window=rsi_period).mean()
                        loss = (-delta.where(delta < 0, 0)).rolling(window=rsi_period).mean()
                        rs = gain / loss.replace(0, 1e-10)
                        rsi_series = 100 - (100 / (1 + rs))
                        if not rsi_series.empty:
                            rsi = float(rsi_series.iloc[-1])
                            logging.info(f"[COND] RSI Calculated Inline: {rsi:.2f}")
                    except Exception as e:
                        logging.error(f"[COND] RSI Inline Calc Error: {e}")
                
                pullback_long = params.get('pullback_rsi_long', 45)
                pullback_short = params.get('pullback_rsi_short', 55)
                rsi_long_met = rsi < pullback_long
                rsi_short_met = rsi > pullback_short
            
            # 3. MTF ì¶”ì„¸ í™•ì¸ (df_pattern_full ê¸°ì¤€)
            # ì‹¤í–‰ ë¡œì§ê³¼ ë™ì¼í•˜ê²Œ ë‚´ë¶€ ë°ì´í„° ì‚¬ìš©
            trend = core.get_filter_trend(self.df_pattern_full, filter_tf=params.get('filter_tf', '4h'))
            
            # í•„í„° ë£°: up/neutralì´ë©´ Long ê°€ëŠ¥, down/neutralì´ë©´ Short ê°€ëŠ¥
            # trendê°€ None(ë°ì´í„° ë¶€ì¡±)ì¸ ê²½ìš°ë„ ì¼ë‹¨ ë³´ìˆ˜ì ìœ¼ë¡œ í†µê³¼ (backtest ë¡œì§ê³¼ ë™ì¼)
            mtf_long_met = trend in ('up', 'neutral', None)
            mtf_short_met = trend in ('down', 'neutral', None)
            
            # ìµœì¢… íŒë‹¨
            will_enter_long = pending_long and rsi_long_met and mtf_long_met
            will_enter_short = pending_short and rsi_short_met and mtf_short_met
            
            # ë°ì´í„° ì„¤ëª… (ë¡œê·¸ìš©)
            pattern_desc = "ì—†ìŒ"
            if pending_long and pending_short: pattern_desc = "Long/Short"
            elif pending_long: pattern_desc = "Long"
            elif pending_short: pattern_desc = "Short"
            
            trend_map = {'up': 'ìƒìŠ¹ â†‘', 'down': 'í•˜ë½ â†“', 'neutral': 'ì¤‘ë¦½ â†’', None: 'N/A'}
            
            return {
                'ready': will_enter_long or will_enter_short,
                'direction': 'LONG' if will_enter_long else 'SHORT' if will_enter_short else None,
                'data': {
                    'pattern': {'met': pending_long or pending_short, 'desc': f"{pattern_desc} ({len(valid_pending)}ê°œ)"},
                    'rsi': {'value': rsi, 'long_met': rsi_long_met, 'short_met': rsi_short_met, 'desc': f"{rsi:.1f}"},
                    'mtf': {'trend': trend, 'long_met': mtf_long_met, 'short_met': mtf_short_met, 'desc': trend_map.get(trend, 'N/A')},
                    'validity': {'desc': f"{params.get('entry_validity_hours', 6)}H"}
                }
            }
        except Exception as e:
            logging.debug(f"[COND] Check error: {e}")
            return {'ready': False, 'direction': None, 'data': {}}
    def _append_candle(self, candle: dict):
        """ìƒˆ ìº”ë“¤ì„ df_entryì— ì¶”ê°€"""
        df = self.indicator_cache.get('df_entry')
        if df is None:
            return
        
        try:
            # [HARDENING] ì¤‘ë³µ ìº”ë“¤ ë°©ì§€ (ë§ˆì§€ë§‰ ìº”ë“¤ê³¼ ì‹œê°„ ê°™ìœ¼ë©´ ë¬´ì‹œ ë˜ëŠ” ë®ì–´ì“°ê¸°)
            # Timestamp ë³€í™˜/í™•ì¸
            new_ts = candle.get('timestamp')
            if not new_ts:
                # 'time' í‚¤ì¼ ìˆ˜ë„ ìˆìŒ
                new_ts = candle.get('time')
            
            # ì •ìˆ˜í˜•ì´ë©´ datetime ë³€í™˜ (ms ë‹¨ìœ„ ê°€ì •)
            if isinstance(new_ts, (int, float)):
                new_ts = datetime.fromtimestamp(new_ts / 1000)
            elif isinstance(new_ts, str):
                new_ts = pd.to_datetime(new_ts)
                
            if not df.empty:
                last_ts = df.iloc[-1]['timestamp']
                if new_ts == last_ts:
                    # ë®ì–´ì“°ê¸° (ì—…ë°ì´íŠ¸) - ì»¬ëŸ¼ëª… ê¸°ë°˜ìœ¼ë¡œ ì•ˆì „í•˜ê²Œ í• ë‹¹
                    idx = df.index[-1]
                    df.at[idx, 'open'] = candle['open']
                    df.at[idx, 'high'] = candle['high']
                    df.at[idx, 'low'] = candle['low']
                    df.at[idx, 'close'] = candle['close']
                    df.at[idx, 'volume'] = candle['volume']
                    return
                elif new_ts < last_ts:
                    # ê³¼ê±° ë°ì´í„°ëŠ” ë¬´ì‹œ
                    return
            
            new_row = pd.DataFrame([{
                'timestamp': new_ts,
                'open': candle['open'],
                'high': candle['high'],
                'low': candle['low'],
                'close': candle['close'],
                'volume': candle['volume']
            }])
            
            self.indicator_cache['df_entry'] = pd.concat(
                [df, new_row], ignore_index=True
            ).tail(500)
        except Exception as e:
            logging.error(f"[CACHE] Append error: {e}")
    
    def _update_indicators(self):
        """ì§€í‘œ ì¬ê³„ì‚°"""
        df = self.indicator_cache.get('df_entry')
        if df is None or len(df) < 50:
            return
        
        try:
            from indicator_generator import IndicatorGenerator
            df = IndicatorGenerator.add_all_indicators(df)
            self.indicator_cache['df_entry'] = df
            self.indicator_cache['last_update'] = datetime.now()
        except Exception as e:
            logging.error(f"[INDICATOR] Update error: {e}")
    
    def _pre_calculate_signal(self):
        """ì‹ í˜¸ ë¯¸ë¦¬ ê³„ì‚°"""
        df_pattern = self.indicator_cache.get('df_pattern')
        df_entry = self.indicator_cache.get('df_entry')
        
        # [DEBUG] ë°ì´í„° ìƒíƒœ í™•ì¸
        pattern_len = len(df_pattern) if df_pattern is not None else 0
        entry_len = len(df_entry) if df_entry is not None else 0
        
        # [HARDENING] ë°ì´í„° ë¶€ì¡± ì‹œ ê³„ì‚° ìŠ¤í‚µ
        if df_pattern is None or len(df_pattern) < 50:
            logging.warning(f"[SIGNAL] âš ï¸ Skip: pattern data insufficient ({pattern_len} < 50)")
            return
        if df_entry is None or len(df_entry) < 50:
            logging.warning(f"[SIGNAL] âš ï¸ Skip: entry data insufficient ({entry_len} < 50)")
            return
        
        try:
            if not hasattr(self, '_strategy_core'):
                from core.strategy_core import AlphaX7Core
                self._strategy_core = AlphaX7Core(use_mtf=self.USE_4H_TREND_FILTER)
            
            # [FIX] íŒ¨í„´ ë°ì´í„° ì£¼ê¸°ì  ê°±ì‹  (1ì‹œê°„ë§ˆë‹¤)
            last_update = self.indicator_cache.get('last_pattern_update')
            now = datetime.utcnow()  # [FIX] UTC ê¸°ì¤€
            
            # ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸ê°€ ì—†ê±°ë‚˜ 59ë¶„ ì§€ë‚¬ìœ¼ë©´ ê°±ì‹ 
            # 1ë¶„ë§ˆë‹¤ ê°±ì‹  (ì‹¤ì‹œê°„ì„± í™•ë³´)
            if last_update is None or (now - last_update).total_seconds() > 60:
                logging.info("[CACHE] Updating pattern data (1H)...")
                sig_exchange = self._get_signal_exchange()
                pattern_tf = self.tf_config.get('pattern', '60')
                
                new_pattern = sig_exchange.get_klines(pattern_tf, 300)
                if new_pattern is not None:
                    try:
                         from indicator_generator import IndicatorGenerator
                         new_pattern = IndicatorGenerator.add_all_indicators(new_pattern)
                         self.indicator_cache['df_pattern'] = new_pattern
                         self.indicator_cache['last_pattern_update'] = now
                         df_pattern = new_pattern # ì§€ì—­ ë³€ìˆ˜ ê°±ì‹ 
                         logging.info(f"[CACHE] Pattern data updated: {len(new_pattern)} candles")
                    except Exception as e:
                        logging.error(f"[CACHE] Pattern update failed: {e}")

            preset = getattr(self.exchange, 'preset_params', {})
            user_atr_period = preset.get('atr_period', DEFAULT_PARAMS.get('atr_period', 14))
            user_rsi_period = preset.get('rsi_period', DEFAULT_PARAMS.get('rsi_period', 21))
            user_tolerance = preset.get('pattern_tolerance', 0.05)
            user_validity = preset.get('entry_validity_hours', 4.0)
            
            signal = self._strategy_core.detect_signal(
                df_pattern, df_entry,
                filter_tf=self.FILTER_TF,
                rsi_period=user_rsi_period,
                atr_period=user_atr_period,
                pattern_tolerance=user_tolerance,
                entry_validity_hours=user_validity
            )
            self.indicator_cache['last_signal'] = signal
            self.indicator_cache['ready'] = True
            
            if signal:
                logging.info(f"[SIGNAL] Pre-calc: {signal.signal_type} ({signal.pattern})")
        except Exception as e:
            logging.error(f"[SIGNAL] Pre-calc error: {e}")
    
    # ========== WebSocket ì½œë°± ==========
    
    def _check_and_fill_gap(self, new_ts):
        """ì›¹ì†Œì¼“ ìˆ˜ì‹  ì‹œ ê°­ ì²´í¬ + ìë™ ë³µêµ¬"""
        if self.df_entry_full is None or len(self.df_entry_full) == 0:
            return
            
        try:
            with self._data_lock:
                last_ts = self.df_entry_full['timestamp'].iloc[-1]
                if isinstance(last_ts, str):
                    last_ts = pd.to_datetime(last_ts)
                    
                gap_minutes = (new_ts - last_ts).total_seconds() / 60
                
                # [FIX] ê°­ ì„ê³„ê°’ ì™„í™”: íƒ€ì„í”„ë ˆì„ì˜ 2ë°° ì´ìƒì¼ ë•Œë§Œ ì§„ì§œ ê°­ìœ¼ë¡œ ê°„ì£¼
                entry_tf_str = self.strategy_params.get('entry_tf', '15m')
                try:
                    tf_val = int(''.join(filter(str.isdigit, entry_tf_str)))
                except Exception:
                    tf_val = 15
                threshold = tf_val * 2 + 1
                
                if gap_minutes > threshold:
                    logging.warning(f"[GAP] ìˆ˜ì‹  ê°­ ê°ì§€: {last_ts} ~ {new_ts} ({gap_minutes:.0f}ë¶„). REST API ë°±í•„ ì‹œì‘...")
                    self._backfill_missing_candles()
                    logging.info("[GAP] ë°±í•„ ì™„ë£Œ.")
        except Exception as e:
            logging.error(f"[GAP] Check/Fill error: {e}")

    def _on_candle_close(self, candle: dict):
        """ì›¹ì†Œì¼“ 15ë¶„ë´‰ ë§ˆê° í•¸ë“¤ëŸ¬"""
        # 1. ì‹œê·¸ë„ ì¶”ì¶œ ë° ì§„ì… ë¡œì§ ìˆ˜í–‰
        self._process_new_candle(candle)
        
        # 2. íì— ë„£ê¸° (ê¸°ì¡´ í˜¸í™˜ì„±)
        self.candle_queue.put(candle)

    def _process_new_candle(self, candle: dict):
        """[CORE] ì‹ ê·œ ìº”ë“¤ ì²˜ë¦¬ í†µí•© ë¡œì§ (WS/REST ê³µìš©)"""
        logging.info(f"[BOT] Processing candle: {candle.get('timestamp') or candle.get('time')} - Close: {candle.get('close')}")
        
        with self._data_lock:
            try:
                # 1. timestamp ë³€í™˜
                ts_raw = candle.get('timestamp')
                if ts_raw is None:
                    ts_raw = candle.get('time')
                    
                if isinstance(ts_raw, (int, float)):
                    ts = pd.to_datetime(ts_raw, unit='ms')
                else:
                    # [FIX] String timestamp safety (try float convert for ms)
                    try:
                        ts = pd.to_datetime(float(ts_raw), unit='ms')
                    except:
                        ts = pd.to_datetime(ts_raw)
                
                # [FIX] 1.5. ê°­ ì²´í¬ (WS ìˆ˜ì‹  ì‹œì—ë§Œ í˜¸ì¶œë¨ - _on_candle_closeì—ì„œ ë³„ë„ í˜¸ì¶œí•´ë„ ë¨)
                # ì—¬ê¸°ì„œëŠ” ìº”ë“¤ í•˜ë‚˜ì— ëŒ€í•œ ì²˜ë¦¬ì´ë¯€ë¡œ ê°­ ì²´í¬ëŠ” í˜¸ì¶œìì—ê²Œ ë§¡ê¹€
                
                # 2. df_entry_fullì— ì´ì–´ë¶™ì´ê¸°
                if self.df_entry_full is not None:
                    new_row = pd.DataFrame([{
                        'timestamp': ts,
                        'open': float(candle['open']),
                        'high': float(candle['high']),
                        'low': float(candle['low']),
                        'close': float(candle['close']),
                        'volume': float(candle.get('volume', 0))
                    }])
                    self.df_entry_full = pd.concat([self.df_entry_full, new_row], ignore_index=True)
                    self.df_entry_full = self.df_entry_full.drop_duplicates(subset='timestamp', keep='last')
                    self.df_entry_full = self.df_entry_full.sort_values('timestamp').reset_index(drop=True)
                
                # 3. 1ì‹œê°„ ì •ê°ì´ë©´ df_pattern_fullì—ë„ ì¶”ê°€
                new_1h_candle = None
                if ts.minute == 0 and self.df_entry_full is not None and len(self.df_entry_full) >= 4:
                    last_4 = self.df_entry_full.tail(4)
                    new_1h = pd.DataFrame([{
                        'timestamp': last_4.iloc[0]['timestamp'],
                        'open': float(last_4.iloc[0]['open']),
                        'high': float(last_4['high'].max()),
                        'low': float(last_4['low'].min()),
                        'close': float(last_4.iloc[-1]['close']),
                        'volume': float(last_4['volume'].sum())
                    }])
                    self.df_pattern_full = pd.concat([self.df_pattern_full, new_1h], ignore_index=True)
                    self.df_pattern_full = self.df_pattern_full.drop_duplicates(subset='timestamp', keep='last')
                    self.df_pattern_full = self.df_pattern_full.sort_values('timestamp').reset_index(drop=True)
                    
                    # ì§€í‘œ ê°±ì‹  (1H)
                    try:
                        from indicator_generator import IndicatorGenerator
                        self.df_pattern_full = IndicatorGenerator.add_all_indicators(self.df_pattern_full)
                    except Exception as e:
                        logging.debug(f"[INDICATOR] 1H ì§€í‘œ ê°±ì‹  ì¤‘ ì˜ˆì™¸: {e}")
                    
                    logging.info(f"[DATA] 1H candle added. Pattern data: {len(self.df_pattern_full)} rows")
                    new_1h_candle = new_1h.iloc[0].to_dict()

                # [FIX] Remove redundant truncating save. rely on _save_to_parquet below.
                # self._save_realtime_candle_to_parquet()

                # 4. ë¦¬ìƒ˜í”Œë§ ë° ìºì‹œ ì—…ë°ì´íŠ¸
                entry_tf = self.strategy_params.get('entry_tf', '15m')
                if entry_tf not in ('15m', '15min') and self.df_entry_full is not None:
                    from utils.bot_data_utils import resample_ohlcv
                    from indicator_generator import IndicatorGenerator
                    self.df_entry_resampled = resample_ohlcv(self.df_entry_full, entry_tf)
                    self.df_entry_resampled = IndicatorGenerator.add_all_indicators(self.df_entry_resampled)
                else:
                    self.df_entry_resampled = self.df_entry_full

                self._save_to_parquet()
                self._append_candle(candle)
                self._update_indicators()

                # 5. ì—°ì† ë°±í…ŒìŠ¤íŠ¸ ì‹¤í–‰ (ì‹¤ì œ ì§„ì…/ì²­ì‚° ì²´í¬)
                if self.bt_state is not None:
                    action = self._continue_backtest(new_candle_15m=candle, new_candle_1h=new_1h_candle)
                    if action:
                        if action.get('action') == 'ENTRY':
                            self._execute_live_entry(action)
                        elif action.get('action') == 'CLOSE':
                            self._execute_live_close(action)
                        elif action.get('action') == 'ADD':
                            # [NEW] ì‹¤ì‹œê°„ ì¶”ê°€ ì§„ì… (ë¶ˆíƒ€ê¸°) ì²˜ë¦¬
                            self._execute_live_add(action)

            except Exception as e:
                logging.error(f"[BOT] Error in _process_new_candle: {e}")
                import traceback
                traceback.print_exc()

    def _save_to_parquet(self):
        """í˜„ì¬ ë°ì´í„°ë¥¼ Parquetìœ¼ë¡œ ì €ì¥"""
        try:
            from pathlib import Path
            from paths import Paths
            cache_dir = Path(Paths.CACHE)
            cache_dir.mkdir(parents=True, exist_ok=True)
            
            exchange_name = self.exchange.name.lower()
            symbol_clean = self.exchange.symbol.lower().replace('/', '')
            entry_file = cache_dir / f"{exchange_name}_{symbol_clean}_15m.parquet"
            
            if self.df_entry_full is not None and len(self.df_entry_full) > 0:
                save_df = self.df_entry_full.copy()
                if 'timestamp' in save_df.columns:
                    save_df['timestamp'] = pd.to_datetime(save_df['timestamp'])
                save_df.to_parquet(entry_file, index=False)
                save_df.to_parquet(entry_file, index=False)
                
                # [NEW] Duplicate save logic merged from realtime (Bithumb/Upbit sync)
                if exchange_name == 'bithumb':
                    try:
                        from constants import COMMON_KRW_SYMBOLS
                        import shutil
                        coin = symbol_clean.upper().replace('KRW', '').replace('-', '') # simplified
                        # Logic: Check if coin in common list (omitted for safety/speed, just copy if it looks like one)
                        # Just copy to upbit filename
                        upbit_filename = f"upbit_{symbol_clean}_{entry_tf}.parquet"
                        upbit_path = cache_dir / upbit_filename
                        shutil.copy(entry_file, upbit_path)
                        logging.debug(f"[SAVE] Hybrid Sync to Upbit: {upbit_filename}")
                    except Exception as e:
                        logging.error(f"[SAVE] Hybrid Copy Error: {e}")

                logging.info(f"[SAVE] Parquet saved: {len(save_df)} rows")
        except Exception as e:
            logging.error(f"[SAVE] Parquet failed: {e}")
    
    def _save_realtime_candle_to_parquet(self):
        """[NEW] ë¹—ì¸-ì—…ë¹„íŠ¸ ë´‰ë§ˆê° ì¦‰ì‹œ Parquet ì €ì¥ (ì´ì¤‘ ì €ì¥ ë¡œì§ í¬í•¨)"""
        try:
            import shutil
            from pathlib import Path
            from paths import Paths
            
            cache_dir = Path(Paths.CACHE)
            exchange_name = self.exchange.name.lower()
            symbol_raw = self.exchange.symbol
            symbol_clean = symbol_raw.lower().replace('/', '').replace(':', '')
            
            # 1. ëŒ€ìƒ ìº”ë“¤ ë¦¬ìŠ¤íŠ¸ ìƒì„±
            save_targets = []
            if self.df_entry_full is not None and not self.df_entry_full.empty:
                save_targets.append((self.df_entry_full, '15m'))
            if self.df_pattern_full is not None and not self.df_pattern_full.empty:
                save_targets.append((self.df_pattern_full, '1h'))
                
            for df, tf in save_targets:
                # ìµœê·¼ 1000ê°œë§Œ ìœ ì§€ (íŒŒì¼ í¬ê¸° ë¹„ëŒ€í•´ì§€ëŠ” ê²ƒ ë°©ì§€)
                save_df = df.tail(1000).copy()
                # [FIX] ì¤‘ë³µ ì œê±° ë° ì •ë ¬ (ë°ì´í„° ë¬´ê²°ì„±)
                save_df = save_df.drop_duplicates(subset='timestamp', keep='last')
                save_df = save_df.sort_values('timestamp')
                filename = f"{exchange_name}_{symbol_clean}_{tf}.parquet"
                path = cache_dir / filename
                
                # ì›ë³¸ ì €ì¥
                save_df.to_parquet(path, index=False)
                
                # [HYBRID] Bithumb -> Upbit ì´ì¤‘ ì €ì¥ ë¡œì§
                if exchange_name == 'bithumb':
                    try:
                        from constants import COMMON_KRW_SYMBOLS
                        coin = symbol_raw.split('/')[0].replace('KRW', '').replace('-', '').upper()
                        if coin in COMMON_KRW_SYMBOLS:
                            upbit_filename = f"upbit_{symbol_clean}_{tf}.parquet"
                            upbit_path = cache_dir / upbit_filename
                            shutil.copy(path, upbit_path)
                            logging.debug(f"[SAVE] Hybrid Sync: {filename} -> {upbit_filename}")
                    except Exception as e:
                        logging.error(f"[SAVE] Hybrid Sync error: {e}")
                        
        except Exception as e:
            logging.error(f"[SAVE] Realtime parquet error: {e}")

    def _execute_live_entry(self, action: dict):
        """ì‹¤ë§¤ë§¤ ì§„ì… ì‹¤í–‰ (ì—°ì† ë°±í…ŒìŠ¤íŠ¸ì—ì„œ í˜¸ì¶œ)"""
        try:
            from exchanges.base_exchange import Signal
            
            direction = action.get('direction')
            price = action.get('price')
            sl = action.get('sl')
            pattern = action.get('pattern', 'W/M')
            
            logging.info(f"[EXECUTE] ğŸŸ¢ {direction} Entry @ {price:.2f}, SL={sl:.2f}, Pattern={pattern}")
            
            # trade_logì— ê¸°ë¡
            capital = getattr(self.exchange, 'capital', 100)
            leverage = getattr(self.exchange, 'leverage', 1)
            trade_logger.info(f"[TRADE] {direction.upper()}_ENTRY | {self.exchange.symbol} | Price={price:.2f} | SL={sl:.2f} | Capital=${capital:.2f} | Lev={leverage}x")
            
            # Signal ê°ì²´ ìƒì„±
            signal = Signal(
                type=direction,
                pattern=pattern,
                stop_loss=sl,
                atr=abs(price - sl) / self.ATR_MULT,  # [Phase 1.3] ê²€ì¦ëœ ê°’ ì‚¬ìš©
                timestamp=datetime.utcnow()
            )
            
            # ê¸°ì¡´ execute_entry í˜¸ì¶œ
            self.execute_entry(signal)
            
        except Exception as e:
            logging.error(f"[EXECUTE] Entry error: {e}")
            import traceback
            traceback.print_exc()
    
    def _execute_live_close(self, action: dict):
        """ì‹¤ë§¤ë§¤ ì²­ì‚° ì‹¤í–‰ (ì—°ì† ë°±í…ŒìŠ¤íŠ¸ì—ì„œ í˜¸ì¶œ)"""
        try:
            direction = action.get('direction')
            price = action.get('price')
            reason = action.get('reason', 'UNKNOWN')
            
            logging.info(f"[EXECUTE] ğŸ”´ {direction} Close @ {price:.2f}, Reason={reason}")
            
            # [FIX] ì‹¤ì œ ì²­ì‚° ì£¼ë¬¸ ì‹¤í–‰ (ì¬ì‹œë„ ë¡œì§ ì¶”ê°€)
            if not getattr(self.exchange, 'dry_run', False):
                max_retries = 3
                close_success = False
                for attempt in range(max_retries):
                    try:
                        close_result = self.exchange.close_position()
                        if close_result:
                            logging.info(f"[EXECUTE] âœ… Close order executed: {close_result}")
                            close_success = True
                            break
                        else:
                            logging.warning(f"[EXECUTE] âš ï¸ Close order returned False (Attempt {attempt+1}/{max_retries})")
                    except Exception as e:
                        logging.error(f"[EXECUTE] âš ï¸ Close order error (Attempt {attempt+1}/{max_retries}): {e}")
                    
                    if attempt < max_retries - 1:
                        time.sleep(1) # ì¬ì‹œë„ ëŒ€ê¸°
                
                if not close_success:
                    # ìµœì¢… ì‹¤íŒ¨ ì²˜ë¦¬
                    logging.error(f"[EXECUTE] âŒ Close failed after {max_retries} attempts.")
                    if self.notifier:
                        self.notifier.notify_error(f"âŒ ì²­ì‚° ì£¼ë¬¸ ìµœì¢… ì‹¤íŒ¨! (3íšŒ ì¬ì‹œë„)")
                    return
            else:
                logging.info("[EXECUTE] ğŸ§ª DRY-RUN: Close order skipped")
            
            # trade_logì— ê¸°ë¡ (PnL ê³„ì‚° í¬í•¨)
            if self.position:
                entry = self.position.entry_price
                if self.position.side == 'Long':
                    pnl_pct = (price - entry) / entry * 100
                else:
                    pnl_pct = (entry - price) / entry * 100
                    
                leverage = getattr(self.exchange, 'leverage', 1)
                pnl_pct_leveraged = pnl_pct * leverage
                capital = getattr(self.exchange, 'capital', 100)
                profit_usd = capital * (pnl_pct_leveraged / 100)
                new_balance = capital + profit_usd

                # [TRADE_LOG] íˆìŠ¤í† ë¦¬ ì €ì¥ (ë§¤ìš° ì¤‘ìš”)
                order_id = getattr(self.position, 'order_id', '') if self.position else ''
                
                # [CRITICAL] ê±°ë˜ ê¸°ë¡ ì €ì¥ (ë³µë¦¬ ê³„ì‚° ë° ëŒ€ì‹œë³´ë“œ í‘œì‹œìš©)
                self.save_trade_history({
                    'time': datetime.now().isoformat(),
                    'symbol': self.exchange.symbol,
                    'side': self.position.side,
                    'entry': entry,
                    'exit': price,
                    'size': self.position.size,
                    'pnl': profit_usd,
                    'pnl_usd': profit_usd,
                    'pnl_pct': pnl_pct_leveraged,
                    'be_triggered': getattr(self.position, 'be_triggered', False),
                    'exchange': self.exchange.name,
                    'order_id': order_id,
                    'reason': reason
                })
                
                # [NEW] ì¼ì¼ ì†ì‹¤ ì¶”ì  ë° í•œë„ ì²´í¬
                self.daily_pnl += profit_usd
                if self.daily_start_balance > 0:
                    current_daily_dd = (self.daily_pnl / self.daily_start_balance) * 100
                    if current_daily_dd <= -self.max_daily_loss_pct:
                        self.stop_trading = True
                        logging.critical(f"ğŸ›‘ [MDD LIMIT] Daily loss limit reached ({current_daily_dd:.2f}%). Trading stopped.")
                        if self.notifier:
                            self.notifier.notify_error(f"ğŸ›‘ ì¼ì¼ ì†ì‹¤ í•œë„ ë„ë‹¬!\ní˜„ì¬ ì†ì‹¤: {current_daily_dd:.2f}%\në´‡ì´ ìë™ìœ¼ë¡œ ë§¤ë§¤ë¥¼ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
                
                trade_logger.info(f"[TRADE] {direction.upper()}_EXIT | {self.exchange.symbol} | Entry={entry:.2f} | Exit={price:.2f} | PnL={pnl_pct_leveraged:+.2f}% | Profit=${profit_usd:+.2f} | Balance=${new_balance:.2f} | ID={order_id}")

                # [GUI] ì¼ë°˜ ì²­ì‚° ë¡œê·¸
                self._log_trade_to_gui({
                    'time': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                    'symbol': self.exchange.symbol,
                    'side': direction, # Position side
                    'entry_price': entry,
                    'exit_price': price,
                    'pnl': profit_usd,
                    'pnl_pct': pnl_pct_leveraged,
                    'action': 'EXIT',
                    'reason': reason,
                    'exchange': self.exchange.name
                })
            
            # ìƒíƒœ ì •ë¦¬
            self.position = None
            self.exchange.position = None
            self.save_state()
            
            # í…”ë ˆê·¸ë¨ ì•Œë¦¼
            if self.notifier and hasattr(self, 'position') and self.position:
                 # ìœ„ì—ì„œ None ì²˜ë¦¬í–ˆìœ¼ë¯€ë¡œ ë¡œì»¬ ë³€ìˆ˜ í™œìš© í•„ìš”í•˜ì§€ë§Œ ë‹¨ìˆœí™”
                 pass
                
        except Exception as e:
            logging.error(f"[EXECUTE] Close error: {e}")
            import traceback
    
    def _on_price_update(self, price: float):
        """ì›¹ì†Œì¼“ ê°€ê²© ì—…ë°ì´íŠ¸ ì½œë°±"""
        self.last_ws_price = price
    
    # ========== ì‹¤ì‹œê°„ ì§„ì… ì˜ˆì¸¡ ë¡œê·¸ ==========
    
    def _check_entry_conditions(self) -> dict:
        """í˜„ì¬ ë´‰ ê¸°ì¤€ ì§„ì… ì¡°ê±´ ì²´í¬ (í†µí•© ë©”ì„œë“œ í˜¸ì¶œ)"""
        cond = self._get_current_trading_conditions()
        
        # ë‚¨ì€ ì‹œê°„ ê³„ì‚°
        now = datetime.utcnow()
        entry_tf = self.strategy_params.get('entry_tf', '15m')
        tf_min = int(''.join(filter(str.isdigit, entry_tf))) if any(c.isdigit() for c in entry_tf) else 15
        minute_in_tf = now.minute % tf_min
        remaining_min = tf_min - minute_in_tf - (now.second / 60)
        
        return {
            'ready': cond['ready'],
            'direction': cond['direction'],
            'remaining_min': remaining_min,
            'conditions': cond['data'],
            'current_price': self.last_ws_price if self.last_ws_price else 0
        }
    
    def _log_entry_prediction(self):
        """ì§„ì… ì˜ˆì¸¡ ìƒíƒœë¥¼ ë¡œê·¸ì— ê¸°ë¡"""
        try:
            pred = self._check_entry_conditions()
            
            if not pred.get('conditions'):
                return
            
            c = pred['conditions']
            remaining = pred.get('remaining_min', 0)
            price = pred.get('current_price', 0)
            
            # ë¡œê·¸ ìƒì„±
            symbol = self.exchange.symbol
            entry_tf = self.strategy_params.get('entry_tf', '15m')
            
            logging.info(f"[PREDICT] â”â”â” ì§„ì… ì¡°ê±´ ì²´í¬ â”â”â”")
            logging.info(f"[PREDICT] ğŸ“Š {symbol} {entry_tf} ({remaining:.0f}ë¶„ í›„ ë§ˆê°)")
            logging.info(f"[PREDICT] â”œâ”€ íŒ¨í„´: {'âœ…' if c['pattern']['met'] else 'âŒ'} {c['pattern']['desc']}")
            logging.info(f"[PREDICT] â”œâ”€ RSI: {c['rsi']['desc']} (Long:{'âœ…' if c['rsi']['long_met'] else 'âŒ'} / Short:{'âœ…' if c['rsi']['short_met'] else 'âŒ'})")
            logging.info(f"[PREDICT] â”œâ”€ MTF: {'âœ…' if c['mtf']['long_met'] or c['mtf']['short_met'] else 'âšª'} {c['mtf']['desc']}")
            logging.info(f"[PREDICT] â””â”€ ìœ íš¨: {c['validity']['desc']}")
            
            if pred['ready']:
                direction = pred['direction']
                logging.info(f"[PREDICT] ğŸŸ¢ ë´‰ ë§ˆê° ì‹œ {direction} ì§„ì… ì˜ˆì •")
                logging.info(f"[PREDICT] â””â”€ í˜„ì¬ê°€: ${price:,.0f}")
            else:
                logging.info(f"[PREDICT] âšª ì§„ì… ì¡°ê±´ ë¯¸ì¶©ì¡±")
                
        except Exception as e:
            logging.debug(f"[PREDICT] Log error: {e}")
    
    # ========== í ê¸°ë°˜ ì‹ í˜¸ ê´€ë¦¬ (ë°±í…ŒìŠ¤íŠ¸ì™€ ë™ì¼) ==========
    
    def _add_new_patterns_to_queue(self):
        """ìƒˆ íŒ¨í„´ì„ pending_signals íì— ì¶”ê°€ (1H íŒ¨í„´ ë°ì´í„° ê°±ì‹  ì‹œ)"""
        from datetime import timedelta
        
        try:
            df_pattern = self.indicator_cache.get('df_pattern')
            if df_pattern is None or len(df_pattern) < 50:
                return
            
            current_time = pd.Timestamp(df_pattern.iloc[-1]['timestamp'])
            
            # ë§ˆì§€ë§‰ ì²´í¬ ì‹œê°„ ì´í›„ ìƒˆ íŒ¨í„´ë§Œ ì¶”ì¶œ
            if self.last_pattern_check_time is None:
                self.last_pattern_check_time = current_time - timedelta(hours=self.ENTRY_VALIDITY_HOURS)
            
            tolerance = self.PATTERN_TOLERANCE
            validity_hours = self.ENTRY_VALIDITY_HOURS
            
            # ëª¨ë“  ì‹œê·¸ë„ ì¶”ì¶œ
            all_signals = self.strategy._extract_all_signals(df_pattern, tolerance, validity_hours)
            
            # ë§ˆì§€ë§‰ ì²´í¬ ì‹œê°„ ì´í›„ ìƒˆ ì‹œê·¸ë„ë§Œ ì¶”ê°€
            new_count = 0
            for s in all_signals:
                signal_time = pd.Timestamp(s['time'])
                
                # ì´ë¯¸ ì²´í¬í•œ ì‹œê°„ ì´í›„ì˜ ì‹œê·¸ë„ë§Œ
                if signal_time > self.last_pattern_check_time:
                    expire_time = signal_time + timedelta(hours=validity_hours)
                    
                    # ì•„ì§ ë§Œë£Œë˜ì§€ ì•Šì€ ì‹œê·¸ë„ë§Œ
                    if expire_time > current_time:
                        s['expire_time'] = expire_time
                        self.pending_signals.append(s)
                        new_count += 1
            
            # ë§ˆì§€ë§‰ ì²´í¬ ì‹œê°„ ê°±ì‹ 
            self.last_pattern_check_time = current_time
            
            if new_count > 0:
                logging.info(f"[QUEUE] Added {new_count} new signals, total={len(self.pending_signals)}")
                
        except Exception as e:
            logging.error(f"[QUEUE] Add patterns error: {e}")
    
    def _check_entry_from_queue(self) -> Optional[Signal]:
        """
        íì—ì„œ ìœ íš¨í•œ ì§„ì… ì‹ í˜¸ í™•ì¸ (ë°±í…ŒìŠ¤íŠ¸ run_backtestì™€ 100% ë™ì¼)
        - ë§Œë£Œëœ ì‹œê·¸ë„ ì œê±°
        - 4H íŠ¸ë Œë“œ í•„í„°ëŠ” ì—¬ê¸°ì„œ ì ìš© (ì§„ì… ì‹œì ì—!)
        """
        from exchanges.base_exchange import Signal
        
        try:
            df_pattern = self.indicator_cache.get('df_pattern')
            df_entry = self.indicator_cache.get('df_entry')
            
            if df_pattern is None or df_entry is None:
                return None
            if len(df_pattern) < 50 or len(df_entry) < 50:
                return None
            
            current_time = pd.Timestamp(df_entry.iloc[-1]['timestamp'])
            
            # 1. ë§Œë£Œëœ ì‹œê·¸ë„ ì œê±° (ì•ì—ì„œë¶€í„° - ì‹œê°„ìˆœì´ë¯€ë¡œ)
            while self.pending_signals and self.pending_signals[0]['expire_time'] <= current_time:
                expired = self.pending_signals.popleft()
                logging.debug(f"[QUEUE] Expired: {expired['time']} ({expired['type']})")
            
            if not self.pending_signals:
                return None
            
            # 2. í˜„ì¬ 4H íŠ¸ë Œë“œ í™•ì¸ (ì§„ì… ì‹œì ì— ì²´í¬!)
            trend = self.strategy.get_filter_trend(df_pattern, filter_tf=self.FILTER_TF)
            logging.debug(f"[QUEUE] Current trend: {trend}, pending={len(self.pending_signals)}")
            
            # 3. íì—ì„œ ìœ íš¨í•œ ì‹œê·¸ë„ ì°¾ê¸°
            for signal in self.pending_signals:
                # [FIX] Safe Access for Signal Object or Dict
                if isinstance(signal, dict):
                    signal_type = signal.get('type', 'Unknown')  # getattr equivalent for dict
                else:
                    signal_type = getattr(signal, 'type', 'Unknown')
                
                # ë°©í–¥ í•„í„°
                if self.direction == 'Long' and signal_type != 'Long':
                    continue
                elif self.direction == 'Short' and signal_type != 'Short':
                    continue
                
                # 4H íŠ¸ë Œë“œ í•„í„° (ë°±í…ŒìŠ¤íŠ¸ì™€ ë™ì¼!)
                if self.USE_4H_TREND_FILTER and trend:
                    if signal_type == 'Long' and trend != 'up':
                        logging.debug(f"[QUEUE] Long blocked by trend={trend}")
                        continue
                    if signal_type == 'Short' and trend != 'down':
                        logging.debug(f"[QUEUE] Short blocked by trend={trend}")
                        continue
                
                # ìœ íš¨í•œ ì‹œê·¸ë„ ë°œê²¬!
                price = float(df_entry.iloc[-1]['close'])
                
                # ATR ê³„ì‚°
                preset = getattr(self.exchange, 'preset_params', {})
                atr_period = preset.get('atr_period', DEFAULT_PARAMS.get('atr_period', 14))
                atr_mult = preset.get('atr_mult', self.ATR_MULT)
                atr = self.strategy.calculate_atr(df_entry, period=atr_period)
                
                # SL ê³„ì‚°
                if signal_type == 'Long':
                    sl = price - atr * atr_mult
                else:
                    sl = price + atr * atr_mult
                
                # íì—ì„œ ì‚¬ìš©í•œ ì‹œê·¸ë„ ì œê±°
                self.pending_signals.remove(signal)
                
                logging.info(f"[QUEUE] âœ… Valid {signal_type} from queue @ ${price:,.0f} (pattern: {getattr(signal, 'pattern', signal.get('pattern', 'W/M')) if isinstance(signal, dict) else getattr(signal, 'pattern', 'W/M')})")
                
                return Signal(
                    type=signal_type,
                    pattern=getattr(signal, 'pattern', signal.get('pattern', 'W/M')) if isinstance(signal, dict) else getattr(signal, 'pattern', 'W/M'),
                    stop_loss=sl,
                    atr=atr,
                    timestamp=datetime.now()
                )
            
            # ìœ íš¨í•œ ì‹œê·¸ë„ ì—†ìŒ
            return None
            
        except Exception as e:
            logging.error(f"[QUEUE] Check entry error: {e}")
            return None
    
    def _start_websocket(self):
        """ì›¹ì†Œì¼“ ì—°ê²° ì‹œì‘ (ë‚´ë¶€ìš©)"""
        # print("ğŸ› [DEBUG] UnifiedBot._start_websocket START", flush=True)
        if self._ws_started:
            # print("ğŸ› [DEBUG] WS already started", flush=True)
            return
        
        try:
            sig_exchange = self._get_signal_exchange()
            ws_interval = '15m'  # í•­ìƒ 15ë¶„ ê³ ì • (Parquet ì €ì¥ ê¸°ì¤€)
            
            # print(f"ğŸ› [DEBUG] Calling {sig_exchange.name}.start_websocket...", flush=True)
            if hasattr(sig_exchange, 'start_websocket'):
                result = sig_exchange.start_websocket(
                    interval=ws_interval,
                    on_candle_close=self._on_candle_close,
                    on_price_update=self._on_price_update,
                    on_connect=self._on_ws_reconnect  # [NEW] ì¬ì—°ê²° ì‹œ ë°ì´í„° ë³´ì¶©
                )
                # print(f"ğŸ› [DEBUG] start_websocket returned: {result}", flush=True)
                
                if result:
                    self._ws_started = True
                    self._ws_init_time = time.time()  # [NEW] ì‹œì‘ ì‹œê°„ ê¸°ë¡ (Grace Periodìš©)
                    logging.info(f"[WS] ì‹œì‘: {sig_exchange.symbol} {ws_interval} (Parquet ì €ì¥ìš©)")
                else:
                    logging.warning("[BOT] WebSocket start failed, using REST mode")
                    self.use_websocket = False
            else:
                logging.info("[BOT] Exchange does not support WebSocket, using REST mode")
                try:
                    self.use_websocket = False
                except Exception as e:
                    logging.debug(f"[WS] WebSocket ì„¤ì • ì¤‘ ì˜ˆì™¸: {e}")
            
            # print("ğŸ› [DEBUG] UnifiedBot._start_websocket END", flush=True)
        except Exception as e:
            # print(f"âŒ [CRITICAL] _start_websocket failed: {e}", flush=True)
            logging.error(f"[BOT] _start_websocket failed: {e}")
            import traceback
            traceback.print_exc()
    
    def _stop_websocket(self):
        """ì›¹ì†Œì¼“ ì—°ê²° ì¤‘ì§€ (ë‚´ë¶€ìš©)"""
        if self._ws_started:
            sig_exchange = self._get_signal_exchange()
            if hasattr(sig_exchange, 'stop_websocket'):
                sig_exchange.stop_websocket()
            self._ws_started = False
            logging.info("[BOT] WebSocket stopped")
    
    def _on_ws_reconnect(self):
        """[NEW] WS ì¬ì—°ê²° ì‹œ ëˆ„ë½ ë°ì´í„° ë³´ì¶©"""
        logging.info("[WS] â™»ï¸ Reconnected! Backfilling missing candles...")
        try:
            self._backfill_missing_candles()
        except Exception as e:
            logging.error(f"[WS] Backfill failed: {e}")
    
    def sync_position(self) -> bool:
        """ê±°ë˜ì†Œ í¬ì§€ì…˜ê³¼ ë´‡ ìƒíƒœ ë™ê¸°í™”
        
        Returns:
            True if synced successfully, False if error
        """
        try:
            # í˜„ë¬¼ ê±°ë˜ì†ŒëŠ” ìŠ¤í‚µ
            if not hasattr(self.exchange, 'get_positions'):
                return True
            
            # 1. ê±°ë˜ì†Œ í¬ì§€ì…˜ ì¡°íšŒ
            positions = self.exchange.get_positions()
            
            # 2. í˜„ì¬ ì‹¬ë³¼ í¬ì§€ì…˜ ì°¾ê¸°
            # [FIX] Hedge Mode: ê°™ì€ ì‹¬ë³¼ì— Long/Short ë‘˜ ë‹¤ ìˆì„ ìˆ˜ ìˆìŒ
            my_positions = []
            for pos in positions:
                if pos.get('symbol') == self.exchange.symbol:
                    my_positions.append(pos)
            
            # 3. ë´‡ ìƒíƒœì™€ ë¹„êµ (í•˜ë‚˜ë¼ë„ size > 0ì´ë©´ ê±°ë˜ì†Œì— í¬ì§€ì…˜ ìˆìŒ)
            bot_has_pos = self.bt_state and self.bt_state.get('position')
            exchange_has_pos = any(p.get('size', 0) > 0 for p in my_positions)
            
            has_changed = False
            
            if bot_has_pos and not exchange_has_pos:
                # ë´‡ì€ ìˆëŠ”ë° ê±°ë˜ì†Œ ì—†ìŒ â†’ ë´‡ ìƒíƒœ ì´ˆê¸°í™”
                logging.warning("[SYNC] ë¶ˆì¼ì¹˜: ë´‡ë§Œ í¬ì§€ì…˜ â†’ ì´ˆê¸°í™”")
                self.bt_state['position'] = None
                self.bt_state['positions'] = []
                self.position = None
                self.exchange.position = None
                has_changed = True
            
            elif exchange_has_pos:
                # ê±°ë˜ì†Œì— í¬ì§€ì…˜ì´ ìˆì„ ë•Œ
                valid_pos = next((p for p in my_positions if p.get('size', 0) > 0), None)
                if valid_pos:
                    side = 'Long' if valid_pos.get('side', 'Buy') == 'Buy' else 'Short'
                    entry = valid_pos.get('entry_price', 0)
                    sl = valid_pos.get('stop_loss', 0)
                    size = valid_pos.get('size', 0)
                    
                    # [NEW] ì™¸ë¶€ í¬ì§€ì…˜ ê°ì§€ ë¡œì§ (Order ID Tracking)
                    # ë´‡ ìƒíƒœì— í¬ì§€ì…˜ ê¸°ë¡ì´ ì „í˜€ ì—†ê±°ë‚˜, ê¸°ë¡ì€ ìˆëŠ”ë° order_idê°€ ë¶ˆì¼ì¹˜í•˜ë©´ ì™¸ë¶€ ì§„ì…ìœ¼ë¡œ ê°„ì£¼
                    bot_order_ids = [str(p.get('order_id')) for p in self.bt_state.get('positions', []) if p.get('order_id')]
                    exchange_order_id = str(valid_pos.get('order_id', ''))
                    
                    is_bot_order = True
                    if exchange_order_id and bot_order_ids:
                        if exchange_order_id not in bot_order_ids:
                            is_bot_order = False
                    
                    if not bot_has_pos or not is_bot_order:
                        msg = f"[SYNC] âš ï¸ ì™¸ë¶€ í¬ì§€ì…˜ ê°ì§€ ({side} @ {entry}, ID: {exchange_order_id}). ë´‡ì´ ê´€ë¦¬í•˜ì§€ ì•ŠëŠ” ì£¼ë¬¸ì´ë©° ë¬´ì‹œë©ë‹ˆë‹¤."
                        logging.warning(msg)
                        if self.notifier:
                            self.notifier.notify_error(f"âš ï¸ ì™¸ë¶€ í¬ì§€ì…˜ ê°ì§€ ({self.exchange.symbol}): ID {exchange_order_id} ì£¼ë¬¸ì€ ë´‡ ê´€ë¦¬ ëŒ€ìƒì—ì„œ ì œì™¸ë©ë‹ˆë‹¤.")
                        return True
                    
                    # ë´‡ ìƒíƒœì™€ ë°©í–¥ì´ ë‹¤ë¥´ë©´ ì—…ë°ì´íŠ¸
                    if self.bt_state.get('position') != side:
                        logging.info(f"[SYNC] í¬ì§€ì…˜ ë°©í–¥ ë¶ˆì¼ì¹˜ë¡œ ì—…ë°ì´íŠ¸ ({side} @ {entry})")
                        self.bt_state['position'] = side
                        # [FIX] ê¸°ì¡´ order_id ë³´ì¡´í•˜ë©° positions ì—…ë°ì´íŠ¸
                        if not self.bt_state.get('positions'):
                            self.bt_state['positions'] = [{'entry': entry, 'initial_sl': sl, 'size': size, 'order_id': exchange_order_id}]
                        else:
                            # ì²« ë²ˆì§¸ í¬ì§€ì…˜ ì •ë³´ë§Œ ì—…ë°ì´íŠ¸í•˜ë˜ IDëŠ” ìœ ì§€
                            p0 = self.bt_state['positions'][0]
                            p0.update({'entry': entry, 'initial_sl': sl, 'size': size})
                            if exchange_order_id: p0['order_id'] = exchange_order_id
                            
                        self.bt_state['current_sl'] = sl
                        self.bt_state['extreme_price'] = entry
                        has_changed = True
                        
                    # self.position ê°ì²´ê°€ ì—†ìœ¼ë©´ ìƒì„± (ë´‡ ì—”ì§„ìš©)
                    if self.position is None or self.position.side != side:
                        self.position = Position(
                            symbol=self.exchange.symbol,
                            side=side,
                            entry_price=entry,
                            size=size,
                            stop_loss=sl,
                            initial_sl=sl,
                            risk=0,
                            entry_time=datetime.now()
                        )
                        self.exchange.position = self.position
                        logging.info(f"[SYNC] Position ê°ì²´ ë³µêµ¬: {side}")
                        has_changed = True
            
            if has_changed:
                self.save_state()
                logging.info("[SYNC] âœ… ë´‡ ìƒíƒœ ì €ì¥ ì™„ë£Œ")
            else:
                logging.info(f"[SYNC] ë™ê¸°í™” ì™„ë£Œ: í¬ì§€ì…˜={'ìˆìŒ' if bot_has_pos else 'ì—†ìŒ'} (ê±°ë˜ì†Œ {len(my_positions)}ê°œ)")
            
            return True
        except Exception as e:
            logging.error(f"[SYNC] ë™ê¸°í™” ì‹¤íŒ¨: {e}")
            return False
    
    def _log_prediction(self):
        """1ë¶„ë§ˆë‹¤ ì§„ì… ì˜ˆì¸¡ ë¡œê·¸ (ì‹¤ì œ ì§„ì… X)"""
        try:
            with self._data_lock:
                if self.df_entry_full is None or len(self.df_entry_full) < 10:
                    return
                
                # ê¸°ì¡´ _check_entry_conditions í™œìš©
                pred = self._check_entry_conditions()
                
                if pred.get('ready'):
                    direction = pred['direction']
                    remaining = pred.get('remaining_min', 0)
                    logging.info(f"[PREDICT] ğŸ”” {direction} ì§„ì… ê°€ëŠ¥ (ë´‰ë§ˆê°ê¹Œì§€ {remaining:.0f}ë¶„)")
                else:
                    c = pred.get('conditions', {})
                    if c.get('pattern', {}).get('met'):
                        logging.debug(f"[PREDICT] â³ íŒ¨í„´ ìˆìŒ, MTF í•„í„° ëŒ€ê¸°ì¤‘")
        except Exception as e:
            logging.debug(f"[PREDICT] Log failed: {e}")
    
    def _run_data_monitor(self):
        """[NEW] ë°±ê·¸ë¼ìš´ë“œ ë°ì´í„° ë¬´ê²°ì„± ëª¨ë‹ˆí„°ë§ (1ë¶„ ì£¼ê¸° ì˜ˆì¸¡ + 5ë¶„ ì£¼ê¸° ë™ê¸°í™”)"""
        logging.info("[DATA_MONITOR] ë°±ê·¸ë¼ìš´ë“œ ëª¨ë‹ˆí„° ì‹œì‘ (1ë¶„/5ë¶„ ì£¼ê¸°)")
        
        minute_counter = 0
        
        while not self._data_monitor_stop.is_set():
            try:
                # 1ë¶„ë§ˆë‹¤ ì˜ˆì¸¡ ë¡œê·¸
                self._log_prediction()
                
                minute_counter += 1
                
                # 5ë¶„ë§ˆë‹¤ ë™ê¸°í™” ë° ê°­ ì²´í¬
                if minute_counter >= 5:
                    minute_counter = 0
                    
                    # í¬ì§€ì…˜ ë™ê¸°í™”
                    self.sync_position()
                    
                    # ë°ì´í„° ê°­ ì²´í¬ ë° ë³´ì¶©
                    if self.df_entry_full is not None and len(self.df_entry_full) > 0:
                        with self._data_lock:
                            last_ts = self.df_entry_full['timestamp'].iloc[-1]
                            if isinstance(last_ts, str):
                                last_ts = pd.to_datetime(last_ts)
                            
                            now = datetime.utcnow()
                            gap_minutes = (now - last_ts).total_seconds() / 60
                            
                            # [FIX] ê°­ ì„ê³„ê°’ ì™„í™”: íƒ€ì„í”„ë ˆì„ì˜ 2ë°° ì´ìƒì¼ ë•Œë§Œ ì§„ì§œ ê°­ìœ¼ë¡œ ê°„ì£¼
                            # 15m ê¸°ì¤€ 15.5ë¶„ì€ ë„ˆë¬´ ë¯¼ê°í•¨ (ì •ìƒ ë²”ìœ„ ë‚´ì—ì„œë„ ë°œìƒ ê°€ëŠ¥)
                            entry_tf_str = self.strategy_params.get('entry_tf', '15m')
                            try:
                                tf_val = int(''.join(filter(str.isdigit, entry_tf_str)))
                            except Exception:
                                tf_val = 15
                                
                            threshold = tf_val * 2 + 1  # 15m -> 31m, 1h -> 121m
                        
                        if gap_minutes > threshold:
                            logging.warning(f"[DATA_MONITOR] ê°­ ê°ì§€: {gap_minutes:.0f}ë¶„ (ì„ê³„ì¹˜ {threshold}ë¶„). ìë™ ë³´ì¶©...")
                            self._backfill_missing_candles()
                        else:
                            logging.debug(f"[DATA_MONITOR] ì •ìƒ: ë§ˆì§€ë§‰ ìº”ë“¤ {gap_minutes:.1f}ë¶„ ì „")
                
            except Exception as e:
                logging.error(f"[DATA_MONITOR] Error: {e}")
            
            # 1ë¶„ ëŒ€ê¸° (ì¤‘ë‹¨ ì‹ í˜¸ ì²´í¬í•˜ë©´ì„œ)
            self._data_monitor_stop.wait(60)
        
        logging.info("[DATA_MONITOR] ë°±ê·¸ë¼ìš´ë“œ ëª¨ë‹ˆí„° ì¢…ë£Œ")
    
    def _start_data_monitor(self):
        """[NEW] ë°ì´í„° ëª¨ë‹ˆí„° ìŠ¤ë ˆë“œ ì‹œì‘"""
        if self._data_monitor_thread is not None and self._data_monitor_thread.is_alive():
            return  # ì´ë¯¸ ì‹¤í–‰ ì¤‘
        
        self._data_monitor_stop.clear()
        self._data_monitor_thread = threading.Thread(
            target=self._run_data_monitor,
            name="DataMonitor",
            daemon=True
        )
        self._data_monitor_thread.start()
        logging.info("[DATA_MONITOR] ìŠ¤ë ˆë“œ ì‹œì‘ë¨")
    
    def _stop_data_monitor(self):
        """[NEW] ë°ì´í„° ëª¨ë‹ˆí„° ìŠ¤ë ˆë“œ ì¤‘ì§€"""
        if self._data_monitor_thread is None:
            return
        
        self._data_monitor_stop.set()
        self._data_monitor_thread.join(timeout=5)
        logging.info("[DATA_MONITOR] ìŠ¤ë ˆë“œ ì¤‘ì§€ë¨")


    
    def _fetch_historical_from_rest(self, limit: int = 1000) -> Optional[pd.DataFrame]:
        """[NEW] REST APIë¥¼ í†µí•´ ê³¼ê±° ìº”ë“¤ ë°ì´í„° ì§ì ‘ ìˆ˜ì§‘"""
        try:
            sig_exchange = self._get_signal_exchange()
            # Entry TF ê¸°ì¤€ìœ¼ë¡œ ìˆ˜ì§‘
            entry_tf = self.tf_config.get('entry', '15')
            logging.info(f"[DATA] Fetching {limit} candles ({entry_tf}) from {sig_exchange.name}...")
            
            df = sig_exchange.get_klines(entry_tf, limit=limit)
            if df is not None and not df.empty:
                # Timestamp ì»¬ëŸ¼ ë³´ì¥
                if 'timestamp' not in df.columns and df.index.name == 'timestamp':
                    df = df.reset_index()
                return df
            return None
        except Exception as e:
            logging.error(f"[DATA] REST fetch failed: {e}")
            return None

    def _backfill_missing_candles(self):
        """[NEW] REST APIë¡œ ëˆ„ë½ëœ ìº”ë“¤ ë³´ì¶© ë° ì‹ í˜¸ ì²´í¬"""
        if self.df_entry_full is None or len(self.df_entry_full) == 0:
            logging.warning("[BACKFILL] No existing data to backfill from")
            return
        
        with self._data_lock:
            # ë§ˆì§€ë§‰ ì €ì¥ëœ ìº”ë“¤ ì‹œê°„
            last_ts = self.df_entry_full['timestamp'].iloc[-1]
            if isinstance(last_ts, str):
                last_ts = pd.to_datetime(last_ts)
            
            # í˜„ì¬ ì‹œê°„ê³¼ ì°¨ì´ ê³„ì‚° (UTC ê¸°ì¤€)
            now = datetime.utcnow()
            gap_minutes = (now - last_ts).total_seconds() / 60
            
            # [FIX] íƒ€ì„í”„ë ˆì„ ê³ ë ¤ (15ë¶„ ë´‰ì´ë©´ ì‚¬ì‹¤ìƒ 15ë¶„ì€ ê°­ì´ ì•„ë‹˜)
            if gap_minutes < 16:
                logging.debug(f"[BACKFILL] No real gap detected (last: {last_ts})")
                return
            
            # APIë¡œ ëˆ„ë½ ìº”ë“¤ ê°€ì ¸ì˜¤ê¸°
            needed_candles = int(gap_minutes / 15) + 1
            needed_candles = min(needed_candles, 1000) # ìµœëŒ€ 1000ê°œ
            
            logging.info(f"[BACKFILL] Fetching {needed_candles} candles (gap: {gap_minutes:.0f}min, last_ts: {last_ts})")
            
            try:
                sig_exchange = self._get_signal_exchange()
                new_candles_df = sig_exchange.get_klines('15m', limit=needed_candles)
                
                if new_candles_df is not None and len(new_candles_df) > 0:
                    # ì¤‘ë³µë˜ì§€ ì•Šì€ ì§„ì§œ "ìƒˆë¡œìš´" ìº”ë“¤ë§Œ ì¶”ì¶œ
                    if 'timestamp' not in new_candles_df.columns and new_candles_df.index.name == 'timestamp':
                        new_candles_df = new_candles_df.reset_index()
                    
                    # ë§ˆì§€ë§‰ tsë³´ë‹¤ ë‚˜ì¤‘ì¸ ê²ƒë§Œ í•„í„°ë§
                    new_candles_df['timestamp'] = pd.to_datetime(new_candles_df['timestamp'])
                    fresh_candles = new_candles_df[new_candles_df['timestamp'] > last_ts].copy()
                    
                    if not fresh_candles.empty:
                        logging.info(f"[BACKFILL] âœ… {len(fresh_candles)} new candles found. Processing...")
                        for _, row in fresh_candles.iterrows():
                            # dictë¡œ ë³€í™˜í•˜ì—¬ ì²˜ë¦¬ ë¡œì§ íƒœìš°ê¸° (Lock ë‚´ë¶€ì´ë¯€ë¡œ ì¬ì§„ì… ì£¼ì˜)
                            # _process_new_candle ë‚´ë¶€ì—ì„œ Lockì„ ë‹¤ì‹œ ê±°ë¯€ë¡œ, _process_new_candleì„ Lock ë°–ìœ¼ë¡œ ë¹¼ê±°ë‚˜ RLock ì‚¬ìš©
                            # ì—¬ê¸°ì„œëŠ” ê°„ë‹¨íˆ ì²˜ë¦¬ ë¡œì§ì„ ì§ì ‘ ìˆ˜í–‰í•˜ê±°ë‚˜ Lockì„ ì ê¹ í’€ê³  í˜¸ì¶œ
                            pass
                        
                        # [REFACTOR] ë½ ì•ˆì „ì„±ì„ ìœ„í•´ ë³‘í•© í›„ ì¼ê´„ ì²˜ë¦¬
                        self.df_entry_full = pd.concat([self.df_entry_full, fresh_candles], ignore_index=True)
                        self.df_entry_full = self.df_entry_full.drop_duplicates(subset='timestamp', keep='last')
                        self.df_entry_full = self.df_entry_full.sort_values('timestamp').reset_index(drop=True)
                        
                        # ì§€í‘œ ë° ì‹ í˜¸ ê°±ì‹ 
                        self._process_historical_data()
                        self._save_to_parquet()
                        
                        # ë§ˆì§€ë§‰ ìº”ë“¤ ê¸°ì¤€ìœ¼ë¡œ ì‹œê·¸ë„ ì²´í¬ (ëˆ„ë½ëœ ì‹œê·¸ë„ ë³µêµ¬)
                        if self.bt_state is not None:
                            last_candle = fresh_candles.iloc[-1].to_dict()
                            # 1H ìº”ë“¤ ì—¬ë¶€ í™•ì¸ (ë°±í•„ëœ ë°ì´í„° ì¤‘ 0ë¶„ ë´‰ì´ ìˆëŠ”ì§€)
                            has_1h = any(ts.minute == 0 for ts in fresh_candles['timestamp'])
                            new_1h = None
                            if has_1h:
                                # ë§ˆì§€ë§‰ 0ë¶„ ë´‰ ì°¾ê¸°
                                h1_rows = fresh_candles[fresh_candles['timestamp'].dt.minute == 0]
                                if not h1_rows.empty:
                                    last_0m = h1_rows.iloc[-1]['timestamp']
                                    # ì—¬ê¸°ì„œ 1H êµ¬í•˜ëŠ” ë¡œì§ì€ ë‹¤ì†Œ ë³µì¡í•˜ë¯€ë¡œ _on_candle_closeì™€ ë™ì¼í•˜ê²Œ ì²˜ë¦¬í•˜ê±°ë‚˜ 
                                    # _process_historical_dataì—ì„œ ë§Œë“¤ì–´ì§„ df_pattern_full ì‚¬ìš©
                                    if self.df_pattern_full is not None and not self.df_pattern_full.empty:
                                        new_1h = self.df_pattern_full.iloc[-1].to_dict()
                            
                            action = self._continue_backtest(new_candle_15m=last_candle, new_candle_1h=new_1h)
                            if action:
                                if action.get('action') == 'ENTRY':
                                    self._execute_live_entry(action)
                        
                        logging.info(f"[BACKFILL] âœ… Sync complete. Total: {len(self.df_entry_full)}")
                    else:
                        logging.info("[BACKFILL] No fresher candles than current data.")
                else:
                    logging.warning("[BACKFILL] No candles returned from API")
            except Exception as e:
                logging.error(f"[BACKFILL] API fetch failed: {e}")
    
    def _on_price_update(self, price: float):
        """ì›¹ì†Œì¼“ ê°€ê²© ì—…ë°ì´íŠ¸ ì½œë°±"""
        self.last_ws_price = price
        
        # ì²« ê°€ê²© ìˆ˜ì‹  ì‹œ ì¦‰ì‹œ ë¡œê·¸
        from datetime import datetime
        now = datetime.utcnow()  # [FIX] UTC ê¸°ì¤€
        
        if not hasattr(self, '_last_price_log'):
            # ì²« ê°€ê²© ìˆ˜ì‹ 
            print(f"ğŸ› [WS] First price: ${price:,.2f}", flush=True)
            logging.info(f"[WS] ğŸ’° First Price: ${price:,.2f}")
            self._last_price_log = now
        elif (now - self._last_price_log).total_seconds() > 300:
            # 5ë¶„ë§ˆë‹¤ ê°€ê²© ë¡œê·¸
            logging.info(f"[WS] ğŸ’° Price: ${price:,.2f}")
            self._last_price_log = now
    
    # Duplicate method removed
    
    # [NEW] License ê¸°ë°˜ ë§¤ë§¤ ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
    def _can_trade(self) -> bool:
        """ë¼ì´ì„ ìŠ¤ ë° ë“±ê¸‰ ê¸°ë°˜ ë§¤ë§¤ ê°€ëŠ¥ ì—¬ë¶€"""
        # ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œëŠ” í•­ìƒ í—ˆìš©
        if getattr(self, 'simulation_mode', False):
            return True
        
        # License Guard ì—†ìœ¼ë©´ í—ˆìš© (ê°œë°œ ëª¨ë“œ)
        if not getattr(self, 'license_guard', None):
            return True
        
        # ë¼ì´ì„ ìŠ¤ ì²´í¬
        result = self.license_guard.can_trade()
        
        if not result.get('can_trade', False):
            logging.warning(f"[LICENSE] ë§¤ë§¤ ë¶ˆê°€: {result.get('reason', 'Unknown')}")
            return False
        
        if result.get('grace_mode', False):
            logging.info(f"[LICENSE] ìœ ì˜ˆ ëª¨ë“œ: {result.get('reason')}")
        
        return True
    
    def _get_price_safe(self) -> float:
        """ì•ˆì „í•œ ê°€ê²© ì¡°íšŒ (WS ìš°ì„ , REST fallback)"""
        if self.last_ws_price and self.use_websocket:
            sig_exchange = self._get_signal_exchange()
            ws = getattr(sig_exchange, 'ws_handler', None)
            if ws and ws.is_healthy(10):
                return self.last_ws_price
        return self.exchange.get_current_price()
    
    def _check_ws_health(self):
        """ì›¹ì†Œì¼“ ìƒíƒœ ì²´í¬ ë° ì¬ì—°ê²°"""
        if not self.use_websocket or not self._ws_started:
            return
            
        # [NEW] ì‹œì‘ ì§í›„ 60ì´ˆê°„ì€ ìƒíƒœ ì²´í¬ ê±´ë„ˆëœ€ (ì—°ê²° ì´ˆê¸°í™” ëŒ€ê¸°)
        if hasattr(self, '_ws_init_time') and (time.time() - self._ws_init_time) < 60:
            return
        
        sig_exchange = self._get_signal_exchange()
        ws = getattr(sig_exchange, 'ws_handler', None)
        
        if ws:
            # ìƒíƒœ ë¶ˆëŸ‰ ê°ì§€
            if not ws.is_healthy(60): # 30ì´ˆ -> 60ì´ˆë¡œ ì™„í™”
                logging.warning(f"[BOT] âš ï¸ WebSocket unhealthy (Last update: {ws.last_message_time}), attempting restart...")
                if hasattr(sig_exchange, 'restart_websocket'):
                    result = sig_exchange.restart_websocket()
                    if result:
                        self._ws_init_time = time.time() # ì¬ì‹œì‘ ì‹œ íƒ€ì´ë¨¸ ë¦¬ì…‹
                        logging.info("[BOT] âœ… WebSocket restarted")
                    else:
                        logging.warning("[BOT] WebSocket restart failed, switching to REST mode")
                        self.use_websocket = False
                        self._ws_started = False
    
    def load_state(self):
        """ìƒíƒœ ë¡œë“œ"""
        try:
            # ìƒˆ Storage ì‚¬ìš©
            if USE_NEW_STORAGE and hasattr(self, 'state_storage'):
                state = self.state_storage.load()
                if state and state.get('position'):
                    self.position = Position.from_dict(state['position'])
                    self.exchange.position = self.position
                    self.exchange.capital = state.get('capital', self.exchange.amount_usd)
                    # [NEW] bt_state ë³µêµ¬
                    if state.get('bt_state'):
                        self.bt_state.update(state['bt_state'])
                    logging.info(f"State loaded (new): {self.position.side} @ {self.position.entry_price}")
                return
            
            # ë ˆê±°ì‹œ ë°©ì‹
            if os.path.exists(STATE_FILE):
                with open(STATE_FILE, 'r') as f:
                    state = json.load(f)
                if state.get('position'):
                    self.position = Position.from_dict(state['position'])
                    self.exchange.position = self.position
                    self.exchange.capital = state.get('capital', self.exchange.amount_usd)
                    # [NEW] bt_state ë³µêµ¬
                    if state.get('bt_state'):
                        self.bt_state.update(state['bt_state'])
                    logging.info(f"State loaded: {self.position.side} @ {self.position.entry_price}")
        except Exception as e:
            logging.error(f"State load error: {e}")
    
    def save_state(self):
        """ìƒíƒœ ì €ì¥"""
        try:
            state = {
                'position': self.position.to_dict() if self.position else None,
                'capital': self.exchange.capital,
                'exchange': self.exchange.name,
                'timestamp': datetime.now().isoformat(),
                # [NEW] bt_stateë„ ì €ì¥ (ì¬ì‹œì‘ ì‹œ ë³µêµ¬ìš©)
                'bt_state': {
                    'position': self.bt_state.get('position') if self.bt_state else None,
                    'positions': self.bt_state.get('positions', []) if self.bt_state else [],
                    'current_sl': self.bt_state.get('current_sl', 0) if self.bt_state else 0,
                    'extreme_price': self.bt_state.get('extreme_price', 0) if self.bt_state else 0,
                }
            }
            
            # ìƒˆ Storage ì‚¬ìš© (ì¦‰ì‹œ ì €ì¥, ì›ìì  êµì²´)
            if USE_NEW_STORAGE and hasattr(self, 'state_storage'):
                self.state_storage.save(state)
                # [FIX] UI ë™ê¸°í™”ìš©ìœ¼ë¡œ STATE_FILEì—ë„ ì €ì¥ (return ì œê±°)
            
            # ë ˆê±°ì‹œ ë°©ì‹ + UI ë™ê¸°í™”ìš© (í•­ìƒ ì‹¤í–‰)
            # [FIX] ì „ì—­ STATE_FILE ëŒ€ì‹  ì¸ìŠ¤í„´ìŠ¤ ì „ìš© state_file ì‚¬ìš©
            target_file = getattr(self, 'state_file', DEFAULT_STATE_FILE)
            with open(target_file, 'w') as f:
                json.dump(state, f, indent=2)
            
            # í•˜ìœ„ í˜¸í™˜ì„± ìœ„í•´ í•˜ë‚˜ëŠ” ë¬´ì¡°ê±´ bot_state.jsonìœ¼ë¡œ ì €ì¥ (ë§ˆì§€ë§‰ ë´‡ ìƒíƒœ)
            if target_file != DEFAULT_STATE_FILE:
                try:
                    with open(DEFAULT_STATE_FILE, 'w') as f:
                        json.dump(state, f, indent=2)
                except Exception as e:
                    logging.debug(f"Save legacy state failed: {e}")
        except Exception as e:
            logging.error(f"State save error: {e}")
    
    def _sync_with_exchange_position(self):
        """ê±°ë˜ì†Œ ì‹¤ì œ í¬ì§€ì…˜ê³¼ ë™ê¸°í™” (sync_positionì˜ Wrapper)"""
        return self.sync_position()
    
    def save_trade_history(self, trade: dict):
        """ê±°ë˜ íˆìŠ¤í† ë¦¬ ì €ì¥"""
        try:
            # ìƒˆ Storage ì‚¬ìš© (í¬ì§€ì…˜ ì²­ì‚° ì‹œ ì¦‰ì‹œ ì €ì¥)
            if USE_NEW_STORAGE and hasattr(self, 'trade_storage'):
                self.trade_storage.add_trade(trade, immediate_flush=True)
                logging.info(f"Trade saved to new storage: {trade.get('pnl_pct', 0):.2f}%")
                return
            
            # ë ˆê±°ì‹œ ë°©ì‹
            history = []
            if os.path.exists(HISTORY_FILE):
                with open(HISTORY_FILE, 'r') as f:
                    history = json.load(f)
            history.append(trade)
            with open(HISTORY_FILE, 'w') as f:
                json.dump(history, f, indent=2)
        except Exception as e:
            logging.error(f"History save error: {e}")
    
    # ========== [NEW] ë³µë¦¬ ìë³¸ ê´€ë¦¬ ==========
    

    
    def _get_signal_exchange(self) -> BaseExchange:
        """ì‹ í˜¸ ê°ì§€ìš© ê±°ë˜ì†Œ ë°˜í™˜ (ë°”ì´ë‚¸ìŠ¤ ëª¨ë“œë©´ ë°”ì´ë‚¸ìŠ¤, ì•„ë‹ˆë©´ ë§¤ë§¤ ê±°ë˜ì†Œ)"""
        # [NEW] ë¹—ì¸-ì—…ë¹„íŠ¸ í•˜ì´ë¸Œë¦¬ë“œ ë¦¬ë‹¤ì´ë ‰ì…˜
        # ë¹—ì¸ ë§¤ë§¤ë”ë¼ë„ ë°ì´í„°(ì‹ í˜¸)ëŠ” ì—…ë¹„íŠ¸ì—ì„œ ê°€ì ¸ì˜´
        if self.exchange.name.lower() == 'bithumb' and not self.use_binance_signal:
            try:
                from constants import COMMON_KRW_SYMBOLS
                # ì‹¬ë³¼ì—ì„œ ì½”ì¸ ì¶”ì¶œ
                symbol = self.exchange.symbol
                coin = symbol.split('/')[0].replace('KRW', '').replace('-', '').upper()
                
                if coin in COMMON_KRW_SYMBOLS:
                    if self.signal_exchange is None:
                        from exchanges.upbit_exchange import UpbitExchange
                        # ì—…ë¹„íŠ¸ ì‹ í˜¸ìš© ê±°ë˜ì†Œ ìƒì„± (API í‚¤ ì—†ì´ ë°ì´í„° ì „ìš©)
                        self.signal_exchange = UpbitExchange({
                            'symbol': f"KRW-{coin}",
                            'api_key': '',
                            'api_secret': ''
                        })
                        self.signal_exchange.connect()
                        logging.info(f"ğŸ”„ [HYBRID] Bithumb {coin} -> Upbit Signal Source Connected")
                    return self.signal_exchange
            except Exception as e:
                logging.error(f"âš ï¸ [HYBRID] Signal redirection failed: {e}")

        if not self.use_binance_signal:
            return self.exchange
        
        if self.exchange.name.lower() == 'binance':
            return self.exchange
        
        # ë°”ì´ë‚¸ìŠ¤ ì‹ í˜¸ ê±°ë˜ì†Œ ìƒì„± (API í‚¤ ì—†ì´ ë°ì´í„°ë§Œ)
        if self.signal_exchange is None:
            try:
                if CCXTExchange:
                    self.signal_exchange = CCXTExchange('binance', {
                        'symbol': self.exchange.symbol,
                        'api_key': '',
                        'api_secret': ''
                    })
                    self.signal_exchange.connect()
                    logging.info("Binance signal exchange connected (read-only)")
                else:
                    logging.warning("CCXT not available, using trade exchange for signals")
                    return self.exchange
            except Exception as e:
                logging.error(f"Failed to create Binance signal exchange: {e}")
                return self.exchange
        
        return self.signal_exchange
    
    def _verify_price_match(self, signal_price: float) -> bool:
        """ë°”ì´ë‚¸ìŠ¤ ê°€ê²©ê³¼ ë§¤ë§¤ ê±°ë˜ì†Œ ê°€ê²© ë¹„êµ"""
        if not self.use_binance_signal:
            return True
        
        if self.exchange.name.lower() == 'binance':
            return True
        
        trade_price = self.exchange.get_current_price()
        if trade_price <= 0:
            return False
        
        diff_pct = abs(trade_price - signal_price) / signal_price
        
        if diff_pct > self.MAX_PRICE_DIFF_PCT:
            logging.warning(f"âš ï¸ Price mismatch! Binance: {signal_price:.2f}, {self.exchange.name}: {trade_price:.2f} (diff: {diff_pct*100:.2f}%)")
            return False
        
        logging.info(f"âœ… Price verified: Binance={signal_price:.2f}, {self.exchange.name}={trade_price:.2f} (diff: {diff_pct*100:.3f}%)")
        return True
    
    def _check_4h_trend(self, signal_type: str) -> bool:
        """
        ì¶”ì„¸ ë°©í–¥ í™•ì¸ (ë™ì  TF ì‚¬ìš©)
        - Long: Trend TF ê°€ê²© > EMA20 (ìƒìŠ¹ ì¶”ì„¸)
        - Short: Trend TF ê°€ê²© < EMA20 (í•˜ë½ ì¶”ì„¸)
        """
        if not self.USE_4H_TREND_FILTER:
            return True
        
        try:
            sig_exchange = self._get_signal_exchange()
            df_trend = sig_exchange.get_klines(self.tf_config['trend'], 30)  # ë™ì  Trend TF
            
            if df_trend is None or len(df_trend) < 20:
                logging.warning(f"Trend TF ({self.tf_config['trend']}) data not available, skipping filter")
                return True
            
            # EMA20 ê³„ì‚°
            df_trend['ema20'] = df_trend['close'].ewm(span=20, adjust=False).mean()
            
            current_price = float(df_trend.iloc[-1]['close'])
            ema20 = float(df_trend.iloc[-1]['ema20'])
            
            trend = 'up' if current_price > ema20 else 'down'
            
            if signal_type == 'Long' and trend != 'up':
                logging.info(f"â¸ï¸ Trend Filter: Long blocked (trend={trend}, price={current_price:.0f}, EMA={ema20:.0f})")
                return False
            
            if signal_type == 'Short' and trend != 'down':
                logging.info(f"â¸ï¸ Trend Filter: Short blocked (trend={trend}, price={current_price:.0f}, EMA={ema20:.0f})")
                return False
            
            logging.info(f"âœ… Trend OK: {signal_type} in {trend} trend")
            return True
            
        except Exception as e:
            logging.error(f"Trend check error: {e}")
            return True  # ì—ëŸ¬ ì‹œ í•„í„° í†µê³¼
    
    # ========== íŒ¨í„´ ê°ì§€ (strategy_breakeven.py ë¡œì§) ==========
    
    # ========== ì „ëµ ì½”ì–´ í†µí•© (Alpha-X7 Final) ==========
    
    def detect_signal(self) -> Optional[Signal]:
        """
        ì‹ í˜¸ ê°ì§€ (ë°±í…ŒìŠ¤íŠ¸ì™€ 100% ë™ì¼í•œ í ê¸°ë°˜ ë¡œì§)
        - pending_signals íì—ì„œ ìœ íš¨í•œ ì‹ í˜¸ í™•ì¸
        - 4H íŠ¸ë Œë“œ í•„í„°ëŠ” ì§„ì… ì‹œì ì— ì ìš© (ë°±í…ŒìŠ¤íŠ¸ì™€ ë™ì¼!)
        """
        # 1. ìºì‹œëœ ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ì´ˆê¸°í™”
        if self.indicator_cache.get('df_pattern') is None:
            self._init_indicator_cache()
        
        # 2. íŒ¨í„´ ë°ì´í„° ì£¼ê¸°ì  ê°±ì‹  + ìƒˆ íŒ¨í„´ í ì¶”ê°€
        df_pattern = self.indicator_cache.get('df_pattern')
        if df_pattern is not None:
            last_update = self.indicator_cache.get('last_pattern_update')
            now = datetime.utcnow()  # [FIX] UTC ê¸°ì¤€
            
            # 1ë¶„ë§ˆë‹¤ ë°ì´í„° ê°±ì‹  (ì‹¤ì‹œê°„ì„± í™•ë³´)
            if last_update is None or (now - last_update).total_seconds() > 60:
                logging.debug("[SIGNAL] Refreshing pattern data...")
                sig_exchange = self._get_signal_exchange()
                pattern_tf = self.tf_config.get('pattern', '60')
                entry_tf = self.tf_config.get('entry', '15')
                
                new_pattern = sig_exchange.get_klines(pattern_tf, 300)
                new_entry = sig_exchange.get_klines(entry_tf, 500)
                
                if new_pattern is not None:
                    try:
                        from indicator_generator import IndicatorGenerator
                        new_pattern = IndicatorGenerator.add_all_indicators(new_pattern)
                        self.indicator_cache['df_pattern'] = new_pattern
                        self.indicator_cache['last_pattern_update'] = now
                    except Exception as e:
                        logging.error(f"[SIGNAL] Pattern update error: {e}")
                
                if new_entry is not None:
                    try:
                        from indicator_generator import IndicatorGenerator
                        new_entry = IndicatorGenerator.add_all_indicators(new_entry)
                        self.indicator_cache['df_entry'] = new_entry
                    except Exception as e:
                        logging.error(f"[SIGNAL] Entry update error: {e}")
                
                # ìƒˆ íŒ¨í„´ íì— ì¶”ê°€
                self._add_new_patterns_to_queue()
        
        # 3. íì—ì„œ ìœ íš¨í•œ ì‹ í˜¸ í™•ì¸ (ë°±í…ŒìŠ¤íŠ¸ì™€ ë™ì¼!)
        signal = self._check_entry_from_queue()
        
        if signal:
            logging.info(f"[SIGNAL] âœ… Queue-based entry: {signal.type} ({signal.pattern})")
            return signal
        
        # 4. íê°€ ë¹„ì–´ìˆìœ¼ë©´ ìƒíƒœ ë¡œê¹…
        pending_count = len(self.pending_signals)
        if pending_count > 0:
            logging.debug(f"[SIGNAL] ğŸ”„ {pending_count} pending signals, waiting for valid entry...")
        else:
            logging.debug("[SIGNAL] â³ No pending signals in queue")
        
        return None

    def manage_position(self):
        """
        í¬ì§€ì…˜ ê´€ë¦¬ (Alpha-X7 Core ì ì‘í˜• íŠ¸ë ˆì¼ë§)
        """
        if not self.position:
            return
        
        try:
            # ë°ì´í„° ë¡œë“œ (ë™ì  Entry TF ì‚¬ìš©)
            df_entry = self.exchange.get_klines(self.tf_config['entry'], 200)
            if df_entry is None or len(df_entry) < 50:
                return

            # strategy_core ëª¨ë“ˆ
            from core.strategy_core import AlphaX7Core
            if not hasattr(self, '_strategy_core'):
                self._strategy_core = AlphaX7Core(use_mtf=self.USE_4H_TREND_FILTER)

            # ì ì‘í˜• íŒŒë¼ë¯¸í„° ê³„ì‚° (ì•„ì§ ì—†ìœ¼ë©´)
            if self._strategy_core.adaptive_params is None:
                # [FIX] í”„ë¦¬ì…‹ RSI Period ì „ë‹¬
                user_rsi_period = self.exchange.preset_params.get('rsi_period')
                self._strategy_core.calculate_adaptive_params(df_entry, rsi_period=user_rsi_period)
            
            params = self._strategy_core.adaptive_params
            if params is None:
                return # ë°ì´í„° ë¶€ì¡± ë“±ìœ¼ë¡œ ê³„ì‚° ë¶ˆê°€ ì‹œ ìŠ¤í‚µ
            
            # í˜„ì¬ ìƒíƒœ
            current_price = float(df_entry.iloc[-1]['close'])
            current_high = float(df_entry.iloc[-1]['high'])
            current_low = float(df_entry.iloc[-1]['low'])
            
            # RSI ê³„ì‚° (ì ì‘í˜• period ì‚¬ìš©)
            rsi = self._strategy_core.calculate_rsi(df_entry['close'].values, period=params['rsi_period'])
            
            entry = self.position.entry_price
            current_sl = self.position.stop_loss
            risk = self.position.risk
            
            # Extreme Price ì´ˆê¸°í™”
            if not hasattr(self.position, 'extreme_price') or self.position.extreme_price is None:
                self.position.extreme_price = entry
            
            # =============== strategy_core ì¤‘ì•™í™” í˜¸ì¶œ (run_backtest ë¡œì§ê³¼ 100% ë™ì¼) ===============
            result = self._strategy_core.manage_position_realtime(
                position_side=self.position.side,
                entry_price=entry,
                current_sl=current_sl,
                extreme_price=self.position.extreme_price,
                current_high=current_high,
                current_low=current_low,
                current_rsi=rsi,
                trail_start_r=self.TRAIL_START_R,
                trail_dist_r=self.TRAIL_DIST_R,
                risk=risk,  # [FIX] Link to risk
                pullback_rsi_long=self.PULLBACK_RSI_LONG,
                pullback_rsi_short=self.PULLBACK_RSI_SHORT
            )
            
            # SL íˆíŠ¸ ì²˜ë¦¬
            if result.get('sl_hit'):
                self._close_on_sl(current_sl)
                return
            
            # Extreme Price ì—…ë°ì´íŠ¸
            self.position.extreme_price = result.get('new_extreme')
            
            # SL ì—…ë°ì´íŠ¸ ì‹¤í–‰
            new_sl_val = result.get('new_sl')
            if new_sl_val:
                if self.exchange.update_stop_loss(new_sl_val):
                    self.position.stop_loss = new_sl_val
                    self.save_state()
                    logging.info(f"ğŸ“ˆ Trailing SL: {new_sl_val:.2f} (RSI={rsi:.1f}, Mult={result.get('mult_used')})")
            
            # =============== í’€ë°± ì¶”ê°€ ì§„ì… (strategy_core ì¤‘ì•™í™”) ===============
            if self.ENABLE_PULLBACK and hasattr(self.position, 'add_count') and self.position.add_count < self.MAX_ADDS:
                should_add = self._strategy_core.should_add_position_realtime(
                    direction=self.position.side,
                    current_rsi=rsi,
                    pullback_rsi_long=self.PULLBACK_RSI_LONG,
                    pullback_rsi_short=self.PULLBACK_RSI_SHORT
                )
                
                if should_add:
                    logging.info(f"ğŸ“Š Pullback Entry Triggered: RSI={rsi:.1f}")
                    # ì¶”ê°€ ì§„ì… ì‹¤í–‰ (ê¸°ì¡´ í¬ì§€ì…˜ í¬ê¸°ì˜ 100%)
                    add_size = self.exchange.capital * 1.0 * self.exchange.leverage / current_price
                    result_order = self.exchange.add_position(self.position.side, add_size)
                    if result_order:
                        self.position.add_count = getattr(self.position, 'add_count', 0) + 1
                        
                        # [BT_STATE] ì¶”ê°€ ì§„ì… ê¸°ë¡
                        if self.bt_state is not None:
                            self.bt_state['positions'].append({
                                'entry': current_price,
                                'initial_sl': self.position.stop_loss,
                                'size': add_size,
                                'time': datetime.now().isoformat(),
                                'order_id': result_order if isinstance(result_order, str) else ''
                            })
                        
                        self.save_state()
                        logging.info(f"âœ… Pullback Add #{self.position.add_count}: {add_size:.4f} @ {current_price:.2f} (ID: {result_order})")

        except Exception as e:
            logging.error(f"Position manage error: {e}")

    def update_capital_for_compounding(self):
        """ê±°ë˜ ê¸°ë¡ ê¸°ë°˜ ë³µë¦¬ ê³„ì‚° (API ì”ê³  ì‚¬ìš© ì•ˆí•¨)"""
        if not self.use_compounding:
            return
        
        # trade_storageê°€ ì—†ê±°ë‚˜ USE_NEW_STORAGEê°€ Falseë©´ ìŠ¤í‚µ
        if not hasattr(self, 'trade_storage') or not self.trade_storage:
            return
        
        try:
            stats = self.trade_storage.get_stats()
            total_pnl = stats.get('total_pnl_usd', 0)
            
            old_capital = self.exchange.capital
            new_capital = self.initial_capital + total_pnl
            
            # ìë³¸ê¸ˆì´ ë³€í–ˆì„ ë•Œë§Œ ë¡œê·¸ ì¶œë ¥
            if abs(new_capital - old_capital) > 0.01:
                self.exchange.capital = new_capital
                logging.info(f"ğŸ’° Capital Updated (Bot History): ${old_capital:.2f} â†’ ${new_capital:.2f}")
                logging.info(f"   Based on {stats['total_trades']} trades, Total PnL: ${total_pnl:.2f}")
        except Exception as e:
            # [ì´ìŠˆ#3 ìˆ˜ì •] ë³µë¦¬ ê³„ì‚° ì‹¤íŒ¨ ì‹œ ìƒì„¸ ë¡œê·¸ ë° í´ë°±
            logging.error(f"[COMPOUNDING] âŒ Capital update failed: {e}")
            logging.error(f"[COMPOUNDING] Fallback: Keeping current capital ${self.exchange.capital:.2f}")
            import traceback
            logging.debug(traceback.format_exc())
    
    def _close_on_sl(self, exit_price: float):
        """SL ì²­ì‚°"""
        entry = self.position.entry_price
        side = self.position.side
        
        if side == 'Long':
            pnl_pct = (exit_price - entry) / entry * 100
        else:
            pnl_pct = (entry - exit_price) / entry * 100
        
        # [FIX] ì‹¤ì œ ì£¼ë¬¸ ê¸ˆì•¡ ê¸°ì¤€ PnL ê³„ì‚°
        position_value = self.position.size * entry
        pnl_usd = position_value * (pnl_pct / 100)
        
        # capital ì—…ë°ì´íŠ¸
        self.exchange.capital += pnl_usd
        
        logging.info(f"ğŸ”´ SL HIT: PnL {pnl_pct:.2f}% (${pnl_usd:.2f}) | Capital: ${self.exchange.capital:.2f}")
        
        # [TRADE_LOG] ê¸°ë¡
        order_id = getattr(self.position, 'order_id', '') if self.position else ''
        trade_logger.info(f"[TRADE] SL_EXIT | {self.exchange.symbol} | Entry={entry:.2f} | Exit={exit_price:.2f} | PnL={pnl_pct:+.2f}% | Profit=${pnl_usd:+.2f} | ID={order_id}")
        
        # [CRITICAL] ê±°ë˜ ê¸°ë¡ ì €ì¥ (ë³µë¦¬ ê³„ì‚°ìš©)
        self.save_trade_history({
            'time': datetime.now().isoformat(),
            'symbol': self.exchange.symbol,
            'side': side,
            'entry': entry,
            'exit': exit_price,
            'size': self.position.size,
            'pnl': pnl_usd,
            'pnl_usd': pnl_usd,
            'pnl_pct': pnl_pct,
            'be_triggered': getattr(self.position, 'be_triggered', False),
            'exchange': self.exchange.name,
            'order_id': getattr(self.position, 'order_id', '') if self.position else ''
        })
        
        # [GUI] SL ì²­ì‚° ë¡œê·¸
        self._log_trade_to_gui({
            'time': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            'symbol': self.exchange.symbol,
            'side': side,
            'entry_price': entry,
            'exit_price': exit_price,
            'pnl': pnl_usd,
            'pnl_pct': pnl_pct,
            'action': 'EXIT',
            'reason': 'SL_HIT',
            'exchange': self.exchange.name
        })
        
        # [NEW] ì¦‰ì‹œ ë³µë¦¬ ìë³¸ ì—…ë°ì´íŠ¸
        self.update_capital_for_compounding()
        
        self.position = None
        self.exchange.position = None
        self.save_state()
        
        # í…”ë ˆê·¸ë¨ ì²­ì‚° ì•Œë¦¼

        if self.notifier:
            self.notifier.notify_exit(
                self.exchange.name, self.exchange.symbol,
                side, pnl_pct, pnl_usd, exit_price
            )
        
        # [NEW] í—¬ìŠ¤ ëª¨ë‹ˆí„°ì— ê¸°ë¡
        try:
            from core.preset_health import get_health_monitor
            if hasattr(self, 'preset_name') and self.preset_name:
                get_health_monitor().record_trade(
                    preset_name=self.preset_name,
                    is_win=(pnl_pct > 0),
                    pnl_pct=pnl_pct
                )
        except Exception as e:
            logging.error(f"[HEALTH] Trade recording error: {e}")
    
    # [NEW] ì‹¤ì‹œê°„ ì¶”ê°€ ì§„ì… ì‹¤í–‰
    def _execute_live_add(self, action: dict) -> bool:
        """ì‹¤ì‹œê°„ ì¶”ê°€ ì§„ì… (ë¶ˆíƒ€ê¸°) ì²˜ë¦¬"""
        try:
            if not self.position:
                return False
                
            current_price = action.get('price', self.exchange.get_current_price())
            # ì¶”ê°€ ì§„ì… ìˆ˜ëŸ‰ ê³„ì‚° (ê¸°ì¡´ ìë³¸ ê¸°ì¤€)
            add_size = self.exchange.capital * 1.0 * self.exchange.leverage / current_price
            
            logging.info(f"ğŸ“Š [WS] Pullback Add Triggered: {self.position.side} @ {current_price:.2f}")
            
            result_order = self.exchange.add_position(self.position.side, add_size)
            if result_order:
                self.position.add_count = getattr(self.position, 'add_count', 0) + 1
                
                # [BT_STATE] ì¶”ê°€ ì§„ì… ê¸°ë¡
                if self.bt_state is not None:
                    self.bt_state['positions'].append({
                        'entry': current_price,
                        'initial_sl': self.position.stop_loss,
                        'size': add_size,
                        'time': datetime.now().isoformat(),
                        'order_id': result_order if isinstance(result_order, str) else ''
                    })
                
                self.save_state()
                logging.info(f"âœ… [WS] Pullback Add #{self.position.add_count}: {add_size:.4f} @ {current_price:.2f} (ID: {result_order})")
                return True
            return False
        except Exception as e:
            logging.error(f"[WS] Pullback Add Error: {e}")
            return False

    # [NEW] ì£¼ë¬¸ ì‹¤í–‰ ë©”ì„œë“œ (Execute Entry)
    def execute_entry(self, signal) -> bool:
        """ì‹ í˜¸ ê¸°ë°˜ ì§„ì… ì£¼ë¬¸ ì‹¤í–‰ (ì‚¬ìš©ì ìš”ì²­ ì•ˆì „ ë¡œì§ ì¶”ê°€)"""
        try:
            # [NEW] MDD í•œë„ ì²´í¬
            if self.stop_trading:
                logging.warning("[ENTRY] ğŸš« Trading is stopped due to daily loss limit.")
                return False
            
            # [FIX] ê¸°ì¡´ í¬ì§€ì…˜ ì¡´ì¬ ì‹œ ì§„ì… ì°¨ë‹¨ (ì¤‘ë³µ ì§„ì… ë°©ì§€)
            if self.bt_state and self.bt_state.get('position'):
                existing_pos = self.bt_state.get('position')
                logging.warning(f"[ENTRY] ğŸš« Already in position: {existing_pos} - skipping entry")
                return False
            
            # ê±°ë˜ì†Œì—ì„œë„ í¬ì§€ì…˜ ì²´í¬ (ì´ì¤‘ ì•ˆì „)
            if hasattr(self.exchange, 'get_positions'):
                try:
                    positions = self.exchange.get_positions()
                    if positions and any(p.get('size', 0) > 0 for p in positions):
                        logging.warning(f"[ENTRY] ğŸš« Exchange has open position - skipping entry")
                        return False
                except Exception as e:
                    logging.debug(f"[ENTRY] Position check failed: {e}")

            # [NEW] ë¼ì´ì„ ìŠ¤ ì²´í¬ (ADMIN Bypass)
            if not self._can_trade():
                # [FIX] Explicit ADMIN Bypass
                is_admin = False
                if self.license_guard and hasattr(self.license_guard, 'tier'):
                    if self.license_guard.tier == 'admin':
                        is_admin = True
                
                if is_admin:
                    logging.info("[ENTRY] License bypass allowed for ADMIN")
                else:
                    logging.warning("[ENTRY] License check failed - trading not allowed")
                    return False

            # [NEW] í—¬ìŠ¤ ì²´í¬
            try:
                from core.preset_health import get_health_monitor
                if self.preset_name:
                    can_active, reason = get_health_monitor().can_trade(self.preset_name)
                    if not can_active:
                        logging.warning(f"[ENTRY] ğŸš« Health check failed: {reason}")
                        if self.notifier:
                             self.notifier.notify_error(f"ğŸš« [Health] {self.preset_name}\nìƒíƒœ: {reason}\nì§„ì…ì´ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤.")
                        return False
            except Exception as e:
                logging.error(f"[HEALTH] Entry check error: {e}")
            
            # 1. ì‹ í˜¸ ê²€ì¦
            if signal is None:
                logging.warning("[ENTRY] No signal provided")
                return False
            
            # [HOTFIX] í˜„ë¬¼ ê±°ë˜ì†Œ ìˆ ì°¨ë‹¨ (Upbit, Bithumb)
            if isinstance(signal, dict):
                direction = signal.get('type', 'Long')  # getattr equivalent
            else:
                direction = getattr(signal, 'type', 'Long')
            exchange_name = getattr(self.exchange, 'name', '').lower()
            if exchange_name in ['upbit', 'bithumb'] and direction == 'Short':
                logging.warning(f"[ENTRY] ğŸš« Short entry blocked on Spot Exchange ({exchange_name})")
                return False
            
            # [NEW] ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œ: ì‹¤ì œ ì£¼ë¬¸ ì—†ì´ ê¸°ë¡ë§Œ
            if getattr(self, 'simulation_mode', False):
                price = self._get_price_safe() or 0
                self.trade_history.append({
                    'type': 'ENTRY',
                    'side': direction,
                    'price': price,
                    'time': datetime.now().isoformat(),
                    'sl': signal.get('stop_loss') if isinstance(signal, dict) else getattr(signal, 'stop_loss', None)
                })
                logging.info(f"[SIM] Entry recorded: {self.trade_history[-1]}")
                return True
            
            # 2. ì”ê³  í™•ì¸ (Optional but recommended)
            try:
                balance = self.exchange.get_balance()
                if balance < 10:
                    logging.warning(f"[ENTRY] Insufficient balance: {balance:.2f} USDT")
                    if self.notifier: self.notifier.notify_error(f"âš ï¸ ì£¼ë¬¸ ì‹¤íŒ¨: ì”ê³  ë¶€ì¡± ({balance:.2f} USDT)")
                    return False
            except Exception as e:
                logging.warning(f"[ENTRY] Balance check failed: {e}")
                # ì”ê³  ì²´í¬ ì‹¤íŒ¨í•´ë„ ì§„í–‰ (ê±°ë˜ì†Œë§ˆë‹¤ ë¡œì§ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ)

            # 3. ì£¼ë¬¸ í¬ê¸° ê³„ì‚°
            symbol = self.exchange.symbol
            # í”„ë¦¬ì…‹ ë ˆë²„ë¦¬ì§€ ìš°ì„ , ì—†ìœ¼ë©´ exchange ë ˆë²„ë¦¬ì§€
            leverage = self.exchange.preset_params.get('leverage', self.exchange.leverage)
            # ë¦¬ìŠ¤í¬ % (ê¸°ë³¸ 98% - í’€ì‹œë“œ)
            risk_pct = 0.98 
            
            # ë³µë¦¬ ìë³¸ ì‚¬ìš©
            capital = self.exchange.capital
            order_value = capital * risk_pct * leverage
            
            # ìµœì†Œ ì£¼ë¬¸ í¬ê¸° ì²´í¬ (100 USDT)
            if order_value < 100:
                logging.warning(f"[ENTRY] Order too small: {order_value:.2f} USDT < 100 USDT")
                if self.notifier: self.notifier.notify_error(f"âš ï¸ ì£¼ë¬¸ ì‹¤íŒ¨: ìµœì†Œ ì£¼ë¬¸ ê¸ˆì•¡ ë¯¸ë‹¬ ({order_value:.2f} USD)")
                return False
            
            # 4. í˜„ì¬ ê°€ê²© (Safe Method)
            price = self._get_price_safe()
            if price is None or price <= 0:
                logging.warning("[ENTRY] Invalid price detected")
                return False
            
            # 5. ìˆ˜ëŸ‰ ê³„ì‚°
            qty = order_value / price
            
            # 6. ë°©í–¥ ê²°ì • (Signal Type -> Side)
            side = signal.type # 'Long' or 'Short'
            
            # [FIX] 6.5. ë ˆë²„ë¦¬ì§€ ì‚¬ì „ ì„¤ì • (ì´ìŠˆ#1: ì‹¤íŒ¨ ì‹œ ì£¼ë¬¸ ì¤‘ë‹¨)
            if not getattr(self.exchange, 'dry_run', False):
                try:
                    if hasattr(self.exchange, 'set_leverage'):
                        lev_result = self.exchange.set_leverage(leverage)
                        if lev_result is False:  # ëª…ì‹œì  ì‹¤íŒ¨ ë°˜í™˜ ì‹œ
                            logging.error(f"[ENTRY] âŒ Leverage setting failed (returned False)")
                            if self.notifier: self.notifier.notify_error(f"âš ï¸ ë ˆë²„ë¦¬ì§€ ì„¤ì • ì‹¤íŒ¨: {leverage}x")
                            return False
                        logging.info(f"[ENTRY] Leverage set to {leverage}x")
                except Exception as e:
                    logging.error(f"[ENTRY] âŒ Leverage setting exception: {e}")
                    if self.notifier: self.notifier.notify_error(f"âš ï¸ ë ˆë²„ë¦¬ì§€ ì„¤ì • ì˜¤ë¥˜: {e}")
                    return False  # [ì´ìŠˆ#1 ìˆ˜ì •] ë ˆë²„ë¦¬ì§€ ì‹¤íŒ¨ ì‹œ ì£¼ë¬¸ ì¤‘ë‹¨
            
            # 7. ì£¼ë¬¸ ì‹¤í–‰
            logging.info(f"[ENTRY] Executing {side} {qty:.4f} {symbol} @ {price:.2f} (Value: ${order_value:.2f})")
            
            # ì‹œì¥ê°€ ì£¼ë¬¸
            # [FIX] dry_run ì²´í¬ ì¶”ê°€
            if getattr(self.exchange, 'dry_run', False):
                logging.info(f"[ENTRY] ğŸ§ª DRY-RUN: Order skipped ({side} {qty:.4f} @ {price:.2f})")
                order = {'dry_run': True, 'side': side, 'qty': qty, 'price': price, 'sl_set': True}
            else:
                # [NEW] 3íšŒ ì¬ì‹œë„ ë¡œì§
                max_retries = 3
                order = None
                for attempt in range(max_retries):
                    try:
                        order = self.exchange.place_market_order(
                            side=side,
                            size=qty,
                            stop_loss=signal.stop_loss
                        )
                        if order:
                            break
                    except Exception as e:
                        logging.warning(f"[ENTRY] ì£¼ë¬¸ ì‹¤íŒ¨ ({attempt+1}/{max_retries}): {e}")
                        if attempt < max_retries - 1:
                            time.sleep(1)
                
                if not order:
                    logging.error("[ENTRY] âŒ 3íšŒ ì‹¤íŒ¨ - ë‹¤ìŒ ë´‰ ëŒ€ê¸°")
                    if self.notifier: self.notifier.notify_error("âŒ ì£¼ë¬¸ 3íšŒ ì‹¤íŒ¨ - ìŠ¤í‚µ")
                    return False
            
            if order:
                logging.info(f"[ENTRY] âœ… Order placed successfully. Start Tracking.")
                
                # [ì´ìŠˆ#2 ìˆ˜ì •] SL ì„¤ì • ì‹¤íŒ¨ ì‹œ ì¦‰ì‹œ ì²­ì‚°
                # [FIX] orderê°€ boolì¼ ìˆ˜ ìˆìŒ (place_market_orderê°€ True/False ë°˜í™˜)
                if isinstance(order, dict):
                    sl_set = order.get('sl_set', True)  # APIê°€ sl_set ë°˜í™˜í•˜ì§€ ì•Šìœ¼ë©´ Trueë¡œ ê°€ì •
                else:
                    sl_set = True  # boolì´ë©´ SL ì„¤ì • ì„±ê³µìœ¼ë¡œ ê°€ì •
                if not sl_set and not getattr(self.exchange, 'dry_run', False):
                    logging.error(f"[ENTRY] ğŸ”´ CRITICAL: SL not set! Closing position immediately.")
                    if self.notifier: self.notifier.notify_error("ğŸ”´ SL ì„¤ì • ì‹¤íŒ¨! í¬ì§€ì…˜ ì¦‰ì‹œ ì²­ì‚°")
                    try:
                        self.exchange.close_position()
                    except Exception as e:
                        logging.error(f"[ENTRY] Emergency close failed: {e}")
                    return False
                
                # í¬ì§€ì…˜ ê°ì²´ ìƒì„± ë° ì €ì¥
                from exchanges.base_exchange import Position
                self.position = Position(
                    symbol=symbol,
                    side=side,
                    entry_price=price,
                    size=qty,
                    stop_loss=signal.stop_loss,
                    initial_sl=signal.stop_loss,
                    risk=abs(price - signal.stop_loss),
                    entry_time=datetime.now(),
                    atr=signal.atr,
                    order_id=order if isinstance(order, str) else ""
                )
                self.position.extreme_price = price
                self.exchange.position = self.position # Exchangeì—ë„ ë™ê¸°í™”
                
                # [FIX] bt_state ì—…ë°ì´íŠ¸ (UI ë™ê¸°í™”ìš©)
                if self.bt_state is not None:
                    self.bt_state['position'] = side
                    self.bt_state['positions'] = [{
                        'entry': price,
                        'initial_sl': signal.stop_loss,
                        'size': qty,
                        'time': datetime.now().isoformat(),
                        'order_id': order if isinstance(order, str) else ''
                    }]
                    self.bt_state['current_sl'] = signal.stop_loss
                    self.bt_state['extreme_price'] = price
                    logging.debug(f"[ENTRY] bt_state updated: {side} @ {price}")
                
                self.save_state()
                
                # [GUI] ì§„ì… ë¡œê·¸
                self._log_trade_to_gui({
                    'time': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                    'symbol': symbol,
                    'side': side,
                    'price': price,
                    'size': qty,
                    'action': 'ENTRY',
                    'exchange': self.exchange.name
                })
                
                # í…”ë ˆê·¸ë¨ ì•Œë¦¼
                if self.notifier:
                    self.notifier.notify_entry(
                        self.exchange.name, symbol, side, price, qty, signal.stop_loss, signal.pattern
                    )
                return True
            else:
                logging.error("[ENTRY] âŒ Order failed (API returned None)")
                if self.notifier: self.notifier.notify_error("âŒ ì£¼ë¬¸ ì‹¤íŒ¨: API ì˜¤ë¥˜")
                return False
                
        except Exception as e:
            logging.error(f"[ENTRY] âŒ Critical Error: {e}")
            logging.error(traceback.format_exc())
            if self.notifier: self.notifier.notify_error(f"âŒ ì£¼ë¬¸ ì¤‘ ì¹˜ëª…ì  ì˜¤ë¥˜: {e}")
            return False
    
    # ========== ë©”ì¸ ë£¨í”„ ==========
    
    def run(self):
        """ë©”ì¸ ë£¨í”„"""

        logging.info(f"Starting {self.exchange.name} Bot...")
        
        # 1. ë´‡ ìƒíƒœ ì—…ë°ì´íŠ¸

        try:
            from bot_status import update_bot_running, update_bot_stopped, update_bot_state, update_position, clear_position
            update_bot_running(self.exchange.name, self.exchange.symbol, "Alpha-X7 Final")
        except ImportError as e:
            logging.debug(f"Bot status modules not found: {e}")

        
        # 2. í…”ë ˆê·¸ë¨ ì‹œì‘ ì•Œë¦¼

        try:
            from telegram_notifier import TelegramNotifier
            self.notifier = TelegramNotifier()
            self.notifier.notify_bot_status("ì‹œì‘", self.exchange.name, self.exchange.symbol)
        except ImportError:
            self.notifier = None
        
        # 3. ì•ˆì „ ê´€ë¦¬ì

        try:
            from trading_safety import get_safety_manager
            safety_manager = get_safety_manager()
        except ImportError:
            safety_manager = None
            

        if not self.exchange.connect():
            logging.error("Exchange connection failed!")
            if self.notifier: self.notifier.notify_error("Exchange connection failed!")
            return

        
        # [NEW] ë³µë¦¬ ìë³¸ ì´ˆê¸°í™” (API íˆìŠ¤í† ë¦¬ ê¸°ë°˜)

        self.update_capital_for_compounding()
        
        # [NEW] ì§€í‘œ ìºì‹œ ì´ˆê¸°í™” (RESTë¡œ ì´ˆê¸° ë°ì´í„° ë¡œë“œ)

        self._init_indicator_cache()

        
        # [NEW] ì›¹ì†Œì¼“ ì‹œì‘ (ìºë“¤ ì‹¤ì‹œê°„ ìˆ˜ì‹ )

        if self.use_websocket:
            self._start_websocket()
        
        # [NEW] ë°±ê·¸ë¼ìš´ë“œ ë°ì´í„° ëª¨ë‹ˆí„° ì‹œì‘ (5ë¶„ë§ˆë‹¤ ê°­ ì²´í¬)
        self._start_data_monitor()

        
        signal_cache = None

        # [STARTUP] pending ì‹ í˜¸ ì¦‰ì‹œ ì²˜ë¦¬ (1íšŒ)
        _startup_done = False
        
        # [STARTUP] ì´ˆê¸° ë°ì¼ë¦¬ ë°¸ëŸ°ìŠ¤ ì„¤ì •
        self.daily_start_balance = getattr(self.exchange, 'capital', 0)
        
        while self.is_running:
            try:
                # [NEW] ì¼ì¼ ì†ì‹¤ ë¦¬ì…‹ (ë‚ ì§œ ë³€ê²½ ì‹œ)
                current_day = datetime.now().day
                if current_day != self.last_day:
                    logging.info(f"[MDD] New day detected ({current_day}). Resetting daily PnL.")
                    self.daily_pnl = 0
                    self.stop_trading = False
                    self.daily_start_balance = getattr(self.exchange, 'capital', 0)
                    self.last_day = current_day

                # Startup pending check
                if not _startup_done and hasattr(self, 'bt_state') and self.bt_state and not self.position:
                    _startup_done = True
                    pending = self.bt_state.get('pending', [])
                    if pending:
                        logging.info(f"[STARTUP] Checking {len(pending)} pending signals...")
                        
                        # ê°€ì¥ ì˜¤ë˜ëœ ì‹ í˜¸ë¶€í„° ìˆœì°¨ ì²˜ë¦¬
                        pending.sort(key=lambda x: x['time'])
                        
                        for p_sig in pending:
                            # 1. ë§Œë£Œ í™•ì¸
                            expire = p_sig.get('expire_time')
                            if expire and expire < datetime.utcnow():
                                continue
                                
                            # 2. ìœ íš¨ì„± ì¬í™•ì¸ (ê°€ê²© ë“±)
                            try:
                                from exchanges.base_exchange import Signal
                                
                                # í˜„ì¬ ê°€ê²©ìœ¼ë¡œ ATR ë“± ì¬ê³„ì‚° í•„ìš”í•˜ì§€ë§Œ, 
                                # ì—¬ê¸°ì„œëŠ” ë‹¨ìˆœíˆ ì§„ì… ê°€ëŠ¥í•œì§€ ì—¬ë¶€ë§Œ íŒë‹¨ (ìˆ˜ë™ ì§„ì…ê³¼ ìœ ì‚¬)
                                current_price = self._get_price_safe()
                                if current_price <= 0:
                                    continue
                                    
                                # Signal ê°ì²´ ë³€í™˜
                                signal_obj = Signal(
                                    type=p_sig['type'],
                                    pattern=p_sig['pattern'],
                                    stop_loss=0, # ì¶”í›„ ê³„ì‚°
                                    atr=0,       # ì¶”í›„ ê³„ì‚°
                                    timestamp=pd.Timestamp(p_sig['time'])
                                )
                                
                                # 3. ATR, SL ê³„ì‚° (strategy_core í™œìš©)
                                # í•„ìš”í•œ ë°ì´í„° ë¡œë“œ (Entry TF)
                                df_entry = self.exchange.get_klines(self.tf_config['entry'], 100)
                                if df_entry is not None:
                                    # ATR ê³„ì‚°
                                    atr = self.exchange.get_atr(df_entry, period=14)
                                    signal_obj.atr = atr
                                    
                                    # SL ê³„ì‚° (ATR ê¸°ë°˜)
                                    sl_dist = atr * self.ATR_MULT
                                    if signal_obj.type == 'Long':
                                        signal_obj.stop_loss = current_price - sl_dist
                                    else:
                                        signal_obj.stop_loss = current_price + sl_dist
                                        
                                    logging.info(f"[STARTUP] Executing restored signal: {signal_obj.type} ({signal_obj.pattern})")
                                    if self.execute_entry(signal_obj):
                                        break # ì§„ì… ì„±ê³µ ì‹œ ë£¨í”„ ì¢…ë£Œ (í•˜ë‚˜ë§Œ ì§„ì…)
                                        
                            except Exception as e:
                                logging.error(f"[STARTUP] Validating pending signal failed: {e}")

                # [NEW] WebSocket ìƒíƒœ ì²´í¬ (30ì´ˆ ë¬´ì‘ë‹µ ì‹œ ì¬ì—°ê²°)
                if self.use_websocket:
                    self._check_ws_health()
                
                # 4. ì•ˆì „ ê´€ë¦¬ ì²´í¬ (ê±°ë˜ ì¤‘ì§€ ìƒíƒœì¸ì§€ í™•ì¸)
                if safety_manager:
                    safety_status = safety_manager.check_can_trade()
                    if not safety_status['allowed']:
                        logging.warning(f"â›” ì•ˆì „ ëª¨ë“œ ì¤‘ì§€: {safety_status['reason']}")
                        if self.notifier:
                            self.notifier.notify_error(f"â›” Bot Stopped (Safety Mode)\nReason: {safety_status['reason']}")
                        break
                        
                # [NEW] WebSocket ëª¨ë“œ vs REST ëª¨ë“œ
                if self.use_websocket and self._ws_started:
                    try:
                        # íì—ì„œ ë´‰ ë§ˆê° ëŒ€ê¸° (íƒ€ì„ì•„ì›ƒ 1ì´ˆ)
                        # íƒ€ì„ì•„ì›ƒ ë°œìƒ ì‹œ -> í¬ì§€ì…˜ ê´€ë¦¬ ë¡œì§ìœ¼ë¡œ ë„˜ì–´ê°
                        candle = self.candle_queue.get(timeout=1)
                        logging.info("[BOT] Processing candle close event")
                        
                        # [HOTFIX] ìº”ë“¤ ì²˜ë¦¬ ë¡œì§ í˜¸ì¶œ
                        self._process_new_candle(candle)
                        
                        # ì§€í‘œ/ì‹ í˜¸ ê²€ì‚¬ ë° ì§„ì…ì€ _process_new_candle -> _execute_live_entryì—ì„œ ì²˜ë¦¬ë¨
                        # ì—¬ê¸°ì„œëŠ” ë³„ë„ ì²˜ë¦¬ ë¶ˆí•„ìš”
                        pass
                            
                    except queue.Empty:
                        # self.logger.debug("Candle queue empty")
                        pass
                else:
                    # ê¸°ì¡´ REST í´ë§ ëª¨ë“œ (1ì´ˆ ëŒ€ê¸°)
                    time.sleep(1)

                now = datetime.utcnow()  # [FIX] UTC ê¸°ì¤€
                minute_in_15min = now.minute % 15
                current_second = now.second
                
                # ========== ë§¤ë§¤ ìƒíƒœ ë¡œê¹… (1ë¶„ë§ˆë‹¤) ==========
                if not hasattr(self, 'last_status_log_time'):
                    self.last_status_log_time = datetime.min
                    
                if (now - self.last_status_log_time).total_seconds() >= 60:  # 1ë¶„ ê²½ê³¼ ì‹œ ë¬´ì¡°ê±´ ì¶œë ¥
                    self.last_status_log_time = now
                    price = self.last_ws_price if self.last_ws_price else 0
                    
                    if self.position:
                        entry = self.position.entry_price
                        sl = self.position.stop_loss
                        if self.position.side == 'Long':
                            pnl_pct = (price - entry) / entry * 100 if price > 0 else 0
                        else:
                            pnl_pct = (entry - price) / entry * 100 if price > 0 else 0
                        
                        logging.info(f"[STATUS] ğŸ“Š {self.position.side} | Entry=${entry:,.0f} | Now=${price:,.0f} | SL=${sl:,.0f} | PnL={pnl_pct:+.2f}%")
                    else:
                        pending = len(self.pending_signals) if hasattr(self, 'pending_signals') else 0
                        bt_pending = len(self.bt_state.get('pending', [])) if self.bt_state else 0
                        logging.info(f"[STATUS] â³ No Position | Price=${price:,.0f} | Pending={pending + bt_pending}")
                        
                        # [NEW] ì§„ì… ì˜ˆì¸¡ ë¡œê·¸ (1ë¶„ë§ˆë‹¤)
                        self._log_entry_prediction()
                
                # í¬ì§€ì…˜ ê´€ë¦¬ ë° ìƒíƒœ ì—…ë°ì´íŠ¸
                if self.position:
                    # ì‹¤ì‹œê°„ PnL ê³„ì‚° ë° ìƒíƒœ ì—…ë°ì´íŠ¸
                    try:
                        # [MOD] WS ê°€ê²© ìš°ì„  ì‚¬ìš©
                        current_price = self.last_ws_price if self.last_ws_price else self.exchange.get_current_price()
                        if current_price > 0:
                            entry = self.position.entry_price
                            if self.position.side == 'Long':
                                pnl_pct = (current_price - entry) / entry * 100
                            else:
                                pnl_pct = (entry - current_price) / entry * 100
                            
                            pnl_usd = self.exchange.capital * self.exchange.leverage * (pnl_pct / 100)
                            
                            update_position(
                                self.position.side, entry, current_price,
                                self.position.stop_loss, self.position.size,
                                pnl_pct, pnl_usd
                            )
                    except Exception as e:
                        logging.debug(f"PnL calc: {e}")
                        
                    self.manage_position()
                else:
                    if minute_in_15min == 14 and current_second >= 50:
                        update_bot_state("detecting")
                    else:
                        update_bot_state("waiting")
                
                # ì‹ í˜¸ ê°ì§€ (í¬ì§€ì…˜ ì—†ì„ ë•Œë§Œ)
                # WS ëª¨ë“œì—ì„œëŠ” ìœ„ì—ì„œ ì²˜ë¦¬í–ˆìœ¼ë¯€ë¡œ REST ëª¨ë“œì¼ ë•Œë§Œ ì‹¤í–‰
                if not self.position and not (self.use_websocket and self._ws_started):
                    # 14ë¶„ 50ì´ˆì— ë¯¸ë¦¬ ê³„ì‚°
                    if minute_in_15min == 14 and current_second >= 50:
                        if signal_cache is None:
                            logging.info("Pre-calculating signal...")
                            signal_cache = self.detect_signal()
                            if signal_cache:
                                logging.info(f"Signal ready: {signal_cache.type} ({signal_cache.pattern})")
                            else:
                                logging.info("No signal detected")
                    
                    # 0ë¶„ 0-5ì´ˆì— ì§„ì…
                    if minute_in_15min == 0 and current_second < 5:
                        if signal_cache:
                            # 1. ë°”ì´ë‚¸ìŠ¤ ëª¨ë“œ: ê°€ê²© ê²€ì¦
                            sig_price = self._get_signal_exchange().get_current_price()
                            if not self._verify_price_match(sig_price):
                                logging.warning(f"âš ï¸ Price mismatch, skipping entry")
                                signal_cache = None
                                continue
                            
                            # 2. 4H ì¶”ì„¸ í•„í„°
                            if not self._check_4h_trend(signal_cache.type):
                                logging.warning(f"âš ï¸ 4H trend filter blocked, skipping entry")
                                signal_cache = None
                                continue
                            
                            # [NEW] 3. ë¼ì´ì„ ìŠ¤ í¬ì§€ì…˜ ì œí•œ ì²´í¬
                            try:
                                from license_manager import get_license_manager
                                lm = get_license_manager()
                                max_pos = lm.get_max_positions()
                                
                                # í˜„ì¬ ì‹¤í–‰ ì¤‘ì¸ ë´‡ë“¤ì˜ ì´ í¬ì§€ì…˜ ìˆ˜ í™•ì¸ (BotStatus í™œìš©)
                                # ì—¬ê¸°ì„œëŠ” ê°„ë‹¨íˆ ìì‹ ì˜ í¬ì§€ì…˜ë§Œ ì²´í¬í•˜ê±°ë‚˜, ë” ë³µì¡í•œ ë¡œì§ì´ í•„ìš”í•  ìˆ˜ ìˆìŒ.
                                # í•˜ì§€ë§Œ unified_botì€ ê°œë³„ í”„ë¡œì„¸ìŠ¤ì´ë¯€ë¡œ, ì „ì—­ ìƒíƒœ(bot_status.json ë“±)ë¥¼ í™•ì¸í•˜ê±°ë‚˜
                                # ì¼ë‹¨ í˜„ì¬ëŠ” ì§„ì… ì‹œì ì—ì„œì˜ ì²´í¬ë¥¼ ìˆ˜í–‰. 
                                # *ì—„ë°€í•œ ì²´í¬ëŠ” staru_mainì´ë‚˜ ì»¨íŠ¸ë¡¤ëŸ¬ ë ˆë²¨ì—ì„œ ê´€ë¦¬í•˜ëŠ” ê²ƒì´ ì¢‹ìŒ*
                                # ì—¬ê¸°ì„œëŠ” pass (ì‚¬ìš©ì ìš”ì²­ì— ë”°ë¼ ì¶”ê°€ë§Œ í•´ë‘ )
                                pass 
                            except Exception as e:
                                logging.debug(f"License check: {e}")

                            logging.info(f"âœ… ENTRY @ {now.strftime('%H:%M:%S')}")
                            
                            self.execute_entry(signal_cache)
                            
                            signal_cache = None
                            time.sleep(60)
                    
                    # 1ë¶„ì— ìºì‹œ ë¦¬ì…‹
                    if minute_in_15min == 1:
                        signal_cache = None
                
                # bot_status.json ì—…ë°ì´íŠ¸ (GUI ì—°ë™)
                try:
                    status_data = {
                        'running': True,
                        'exchange': self.exchange.name,
                        'symbol': self.exchange.symbol,
                        'current_price': self.last_ws_price if self.last_ws_price else 0,
                        'timestamp': datetime.now().isoformat(),
                        'pnl_pct': 0,
                        'pnl_usd': 0,
                        'position': None
                    }
                    
                    if self.position:
                        entry = self.position.entry_price
                        current = self.last_ws_price if self.last_ws_price else self.exchange.get_current_price()
                        if current > 0:
                            if self.position.side == 'Long':
                                pnl_pct = (current - entry) / entry * 100
                            else:
                                pnl_pct = (entry - current) / entry * 100
                            status_data['pnl_pct'] = pnl_pct
                            status_data['pnl_usd'] = self.exchange.capital * self.exchange.leverage * (pnl_pct / 100)
                            status_data['position'] = self.position.side
                            status_data['entry_price'] = entry
                    
                    status_file = 'bot_status.json'
                    try:
                        if '_get_config_path' in globals():
                             status_file = _get_config_path('bot_status.json')
                    except Exception as e:
                        logging.debug(f"[STATUS] ê²½ë¡œ ì„¤ì • ì¤‘ ì˜ˆì™¸: {e}")

                    with open(status_file, 'w', encoding='utf-8') as f:
                        json.dump(status_data, f)
                except (IOError, OSError) as e:
                    logging.debug(f"Status file update failed: {e}")

                time.sleep(1)
                
            except KeyboardInterrupt:
                logging.info("Bot stopped by user")
                update_bot_stopped()
                # [NEW] ì›¹ì†Œì¼“ ì •ë¦¬
                self._stop_websocket()
                break
                if self.notifier: self.notifier.notify_error(f"Loop Error: {e}")
                time.sleep(5)

    def _log_trade_to_gui(self, data: dict):
        """GUIìš© ì‹¤ì‹œê°„ ê±°ë˜ ë¡œê·¸ ê¸°ë¡"""
        try:
            log_dir = 'logs'
            if not os.path.exists(log_dir):
                os.makedirs(log_dir)
                
            gui_log_path = os.path.join(log_dir, 'gui_trades.json')
            
            # ê¸°ì¡´ ë¡œê·¸ ë¡œë“œ
            trades = []
            if os.path.exists(gui_log_path):
                try:
                    with open(gui_log_path, 'r', encoding='utf-8') as f:
                        trades = json.load(f)
                except (json.JSONDecodeError, IOError):
                    trades = []
            
            # ìƒˆ ë¡œê·¸ ì¶”ê°€
            # entry: {time, symbol, side, price, size, action='ENTRY'}
            # exit:  {time, symbol, side, entry_price, exit_price, pnl, pnl_pct, action='EXIT'}
            trades.append(data)
            
            # ìµœê·¼ 100ê°œ ìœ ì§€
            trades = trades[-100:]
            
            with open(gui_log_path, 'w', encoding='utf-8') as f:
                json.dump(trades, f, indent=2)
                
        except Exception as e:
            logging.error(f"[GUI_LOG] Failed: {e}")



def create_bot(exchange_name: str, config: dict, use_binance_signal: bool = False) -> UnifiedBot:
    """ê±°ë˜ì†Œë³„ ë´‡ ìƒì„±"""
    global EXCHANGE_TIME_OFFSET
    
    # ì„œë²„ ì‹œê°„ ë™ê¸°í™”
    EXCHANGE_TIME_OFFSET = get_server_time_offset(exchange_name)
    logging.info(f"[TIME] Applied offset: {EXCHANGE_TIME_OFFSET:.3f}s for {exchange_name}")
    
    exchange_lower = exchange_name.lower()
    
    # ì „ìš© ì–´ëŒ‘í„°ê°€ ìˆëŠ” ê±°ë˜ì†Œ
    if exchange_lower == 'bybit':
        exchange = BybitExchange(config)
    elif exchange_lower == 'lighter':
        exchange = LighterExchange(config)
    elif exchange_lower == 'binance' and BinanceExchange:
        exchange = BinanceExchange(config)
    # CCXT ì§€ì› ê±°ë˜ì†Œ (OKX, Bitget, BingX, Gate ë“±)
    elif CCXTExchange and exchange_lower in SUPPORTED_EXCHANGES:
        exchange = CCXTExchange(exchange_lower, config)
    elif CCXTExchange:
        # ì§€ì› ëª©ë¡ì— ì—†ì–´ë„ ì‹œë„
        logging.warning(f"Trying unsupported exchange via CCXT: {exchange_name}")
        exchange = CCXTExchange(exchange_lower, config)
    else:
        raise ValueError(f"Unsupported exchange: {exchange_name}. Install ccxt: pip install ccxt")
    
    # [NEW] ì¶”ê°€ ì„¤ì • ì „ë‹¬ (í”„ë¦¬ì…‹, entry_tf, direction)
    exchange.preset_params = config.get('preset_params', {})
    exchange.entry_tf = config.get('entry_tf', '15min')
    exchange.direction = config.get('direction', 'Both')
    
    # [FIX] í”„ë¦¬ì…‹ ì´ë¦„ ì „ë‹¬ (ê²½ë¡œì—ì„œ ì¶”ì¶œ)
    if config.get('preset_params'):
        preset_path = config.get('preset_path', '')
        if preset_path:
            preset_name = os.path.basename(preset_path).replace('.json', '')
            exchange.preset_name = preset_name
    
    return UnifiedBot(exchange, use_binance_signal=use_binance_signal)


if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description='Unified Trading Bot')
    parser.add_argument('--exchange', type=str, default='bybit', help='Exchange name (bybit, binance, okx, bitget, etc.)')
    parser.add_argument('--symbol', type=str, help='Trading symbol (e.g., BTCUSDT)')
    parser.add_argument('--timeframe', type=str, help='Trend timeframe (e.g., 4h, 1d)')
    parser.add_argument('--entry-tf', type=str, default='15min', help='Entry timeframe (e.g., 15min, 1h)')
    parser.add_argument('--direction', type=str, default='Both', choices=['Both', 'Long', 'Short'], help='Trading direction')
    parser.add_argument('--preset', type=str, default='', help='Preset JSON path (e.g., config/presets/BTCUSDT_1d.json)')
    parser.add_argument('--binance-signal', action='store_true', help='Use Binance data for signal detection')
    parser.add_argument('--capital', type=float, help='Trading capital in USD')
    parser.add_argument('--leverage', type=int, default=10, help='Leverage (default: 10)')
    parser.add_argument('--dry-run', action='store_true', help='í…ŒìŠ¤íŠ¸ ëª¨ë“œ (ì‹¤ì œ ì£¼ë¬¸ ì•ˆ í•¨)')
    args = parser.parse_args()
    
    # Dry-run ëª¨ë“œ ì•Œë¦¼
    if args.dry_run:
        print("\nğŸ§ª DRY-RUN ëª¨ë“œ: ì‹¤ì œ ì£¼ë¬¸ ì—†ì´ ì‹ í˜¸ë§Œ í™•ì¸í•©ë‹ˆë‹¤")
        print("="*50)
    
    # ì„¤ì • ë¡œë“œ
    exchange_config = {}
    
    # LighterëŠ” .env.lighter íŒŒì¼ì—ì„œ ë¡œë“œ
    if args.exchange.lower() == 'lighter':
        # [FIX] EXE í˜¸í™˜ ê²½ë¡œ ì²˜ë¦¬
        if getattr(sys, 'frozen', False):
            env_file = os.path.join(os.path.dirname(sys.executable), '.env.lighter')
        else:
            env_file = os.path.join(os.path.dirname(__file__), '.env.lighter')
        if os.path.exists(env_file):
            with open(env_file, 'r') as f:
                for line in f:
                    line = line.strip()
                    if '=' in line and not line.startswith('#'):
                        key, value = line.split('=', 1)
                        if key == 'API_PRIVATE_KEY':
                            exchange_config['private_key'] = value
                        elif key == 'ACCOUNT_INDEX':
                            exchange_config['account_index'] = int(value)
                        elif key == 'API_KEY_INDEX':
                            exchange_config['key_index'] = int(value)
                        elif key == 'BASE_URL':
                            exchange_config['base_url'] = value
        exchange_config['symbol'] = 'ETH'
        exchange_config['leverage'] = 3
        exchange_config['amount_usd'] = 100
    else:
        try:
            sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'GUI'))
            from crypto_manager import load_api_keys
            config = load_api_keys()
            exchange_config = config.get(args.exchange.lower(), {})
        except Exception as e:
            logging.warning(f"Failed to load API keys: {e}, using defaults")
            exchange_config = {
                'symbol': 'BTCUSDT',
                'leverage': 3,
                'amount_usd': 100
            }

    # ëª…ë ¹í–‰ ì¸ìˆ˜ë¡œ ì„¤ì • ë®ì–´ì“°ê¸°
    if args.symbol:
        exchange_config['symbol'] = args.symbol
    if args.timeframe:
        exchange_config['timeframe'] = args.timeframe
    if args.capital:
        exchange_config['amount_usd'] = args.capital
    if args.leverage:
        exchange_config['leverage'] = args.leverage
    
    # Entry TF ì„¤ì •
    entry_tf = getattr(args, 'entry_tf', '15min')
    exchange_config['entry_tf'] = entry_tf
    
    # [NEW] ë°©í–¥ ì„¤ì •
    exchange_config['direction'] = args.direction
    
    # [NEW] í”„ë¦¬ì…‹ ë¡œë“œ
    preset_params = {}
    preset_path = getattr(args, 'preset', '')
    if preset_path and os.path.exists(preset_path):
        try:
            with open(preset_path, 'r', encoding='utf-8') as f:
                preset_data = json.load(f)
            preset_params = preset_data.get('params', preset_data)
            print(f"âœ… í”„ë¦¬ì…‹ ë¡œë“œ: {os.path.basename(preset_path)}")
            print(f"   params: atr_mult={preset_params.get('atr_mult')}, trail_start_r={preset_params.get('trail_start_r')}")
        except Exception as e:
            print(f"âš ï¸ í”„ë¦¬ì…‹ ë¡œë“œ ì‹¤íŒ¨: {e}")
    
    exchange_config['preset_params'] = preset_params
    exchange_config['dry_run'] = args.dry_run
    
    bot = create_bot(args.exchange, exchange_config, use_binance_signal=args.binance_signal)
    
    if args.dry_run:
        # Dry-run: ì‹ í˜¸ 1íšŒ ì²´í¬ í›„ ì¢…ë£Œ
        print("\nğŸ“Š ì‹ í˜¸ ê°ì§€ í…ŒìŠ¤íŠ¸ ì¤‘...")
        signal = bot.detect_signal()
        if signal:
            print(f"âœ… ì‹ í˜¸ ê°ì§€: {signal.type} ({signal.pattern})")
            print(f"   ì†ì ˆê°€: {signal.stop_loss:.2f}")
            print(f"   ATR: {signal.atr:.2f}")
        else:
            print("â„¹ï¸ í˜„ì¬ ì‹ í˜¸ ì—†ìŒ")
        print("\nğŸ§ª DRY-RUN ì™„ë£Œ")
    else:
        try:
            bot.run()
        except Exception as e:
            print(f"âŒ [CRASH] Top-level crash: {e}", flush=True)
            import traceback
            traceback.print_exc()


# Alias for compatibility
TradingBot = UnifiedBot
