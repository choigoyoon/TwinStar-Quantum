"""ë©”íƒ€ ìµœì í™” ì—”ì§„ - íŒŒë¼ë¯¸í„° ë²”ìœ„ ìë™ íƒìƒ‰

ì´ ëª¨ë“ˆì€ ë©”íƒ€ ìµœì í™” (Meta-Optimization) ì‹œìŠ¤í…œì„ êµ¬í˜„í•©ë‹ˆë‹¤.
ëœë¤ ìƒ˜í”Œë§ + ë°±ë¶„ìœ„ìˆ˜ ê¸°ë°˜ ë²”ìœ„ ì¶”ì¶œë¡œ ìµœì  íŒŒë¼ë¯¸í„° ë²”ìœ„ë¥¼ ìë™ íƒìƒ‰í•©ë‹ˆë‹¤.

Architecture:
    Level 1: ë„“ì€ ë²”ìœ„ ëœë¤ ìƒ˜í”Œë§ (1,000ê°œ ì¡°í•©)
    Level 2: ìƒìœ„ 10% ê²°ê³¼ ë¶„ì„ (ë°±ë¶„ìœ„ìˆ˜ 10~90%)
    Level 3: ë²”ìœ„ ì¶•ì†Œ + ë°˜ë³µ (ìˆ˜ë ´ ì¡°ê±´ ì¶©ì¡±ì‹œ ì¢…ë£Œ)

Author: Claude Sonnet 4.5
Version: 1.0.1
Date: 2026-01-17
"""

import time
import random
import itertools
import numpy as np
import pandas as pd
from typing import Dict, List, Optional, Callable, Union
from collections import Counter
from datetime import datetime
import json
import os

from utils.logger import get_module_logger

logger = get_module_logger(__name__)


class MetaOptimizer:
    """ë©”íƒ€ ìµœì í™” ì—”ì§„ - íŒŒë¼ë¯¸í„° ë²”ìœ„ ìë™ íƒìƒ‰

    ëœë¤ ìƒ˜í”Œë§ê³¼ ë°±ë¶„ìœ„ìˆ˜ ê¸°ë°˜ ë²”ìœ„ ì¶”ì¶œì„ ì‚¬ìš©í•˜ì—¬ ìµœì  íŒŒë¼ë¯¸í„° ë²”ìœ„ë¥¼ ìë™ìœ¼ë¡œ íƒìƒ‰í•©ë‹ˆë‹¤.

    Attributes:
        base_optimizer: ê¸°ì¡´ BacktestOptimizer ì¸ìŠ¤í„´ìŠ¤
        meta_ranges: ë©”íƒ€ ë²”ìœ„ (META_PARAM_RANGES, 26,950 ì¡°í•©)
        sample_size: ë°˜ë³µë‹¹ ìƒ˜í”Œ ìˆ˜ (ê¸°ë³¸ 2,000ê°œ, ê¶Œì¥ ë²”ìœ„: 500-5,000)
        min_improvement: ìˆ˜ë ´ ê¸°ì¤€ (ê¸°ë³¸ 5%)
        max_iterations: ìµœëŒ€ ë°˜ë³µ íšŸìˆ˜ (ê¸°ë³¸ 3íšŒ)
        iteration_results: ë°˜ë³µë³„ ìµœê³  ì ìˆ˜ ë¦¬ìŠ¤íŠ¸
        extracted_ranges: ì¶”ì¶œëœ ë²”ìœ„

    Example:
        >>> from core.optimizer import BacktestOptimizer
        >>> from core.meta_optimizer import MetaOptimizer
        >>> from core.strategy_core import AlphaX7Core
        >>>
        >>> # ê¸°ì¡´ Optimizer ìƒì„±
        >>> base_optimizer = BacktestOptimizer(AlphaX7Core, df)
        >>>
        >>> # Meta Optimizer ìƒì„±
        >>> meta = MetaOptimizer(
        ...     base_optimizer=base_optimizer,
        ...     sample_size=1000,
        ...     max_iterations=3
        ... )
        >>>
        >>> # ë©”íƒ€ ìµœì í™” ì‹¤í–‰
        >>> result = meta.run_meta_optimization(df, metric='sharpe_ratio')
        >>>
        >>> # ì¶”ì¶œëœ ë²”ìœ„ í™•ì¸
        >>> print(result['extracted_ranges'])
        >>> # {'atr_mult': {'quick': [1.2, 2.4], 'standard': [1.2, 1.8, 2.4], ...}}
    """

    def __init__(
        self,
        base_optimizer,  # BacktestOptimizer ì¸ìŠ¤í„´ìŠ¤
        meta_ranges: Optional[Dict[str, List]] = None,
        sample_size: int = 2000,
        min_improvement: float = 0.05,
        max_iterations: int = 3
    ):
        """MetaOptimizer ì´ˆê¸°í™”

        Args:
            base_optimizer: ê¸°ì¡´ BacktestOptimizer ì¸ìŠ¤í„´ìŠ¤ (ì¬ì‚¬ìš©)
            meta_ranges: META_PARAM_RANGES (ê¸°ë³¸ê°’: config.meta_ranges ì‚¬ìš©)
            sample_size: ë°˜ë³µë‹¹ ëœë¤ ìƒ˜í”Œ ìˆ˜ (ê¸°ë³¸ 2,000ê°œ, ë²”ìœ„: 500-5,000)
            min_improvement: ìˆ˜ë ´ ê¸°ì¤€ (ê¸°ë³¸ 5%)
            max_iterations: ìµœëŒ€ ë°˜ë³µ íšŸìˆ˜ (ê¸°ë³¸ 3íšŒ)
        """
        self.base_optimizer = base_optimizer

        # META_PARAM_RANGES ë¡œë“œ
        if meta_ranges is None:
            from .meta_ranges import load_meta_param_ranges
            meta_ranges = load_meta_param_ranges()
        self.meta_ranges = meta_ranges

        self.sample_size = sample_size
        self.min_improvement = min_improvement
        self.max_iterations = max_iterations

        # ìƒíƒœ ë³€ìˆ˜
        self.iteration_results: List[float] = []  # ë°˜ë³µë³„ ìµœê³  ì ìˆ˜
        self.extracted_ranges: Optional[Dict[str, List]] = None  # ì¶”ì¶œëœ ë²”ìœ„

    def run_meta_optimization(
        self,
        df: pd.DataFrame,
        trend_tf: str = '1h',
        metric: str = 'sharpe_ratio',
        callback: Optional[Callable] = None,
        progress_callback: Optional[Callable] = None
    ) -> Dict:
        """ê·¸ë¦¬ë“œ ê¸°ë°˜ ë©”íƒ€ ìµœì í™” - 3ë‹¨ê³„ ì ì‘í˜• íƒìƒ‰

        Algorithm:
            Phase 1: Coarse Grid (3^5 = 243ê°œ)
                - ì „ì²´ ë²”ìœ„ë¥¼ 3ê°œ í¬ì¸íŠ¸ë¡œ ìƒ˜í”Œë§ (min, mid, max)
                - ì „ì²´ ì‹¤í–‰, ìƒìœ„ 10% ë¶„ì„
            Phase 2: Fine Grid (5^5 = 3,125ê°œ â†’ 243ê°œ ì‹¤ì œ ì‹¤í–‰)
                - í”¼í¬ ì¤‘ì‹¬ Â±50% ë²”ìœ„, 5ê°œ í¬ì¸íŠ¸
            Phase 3: Ultra-Fine Grid (7^5 = 16,807ê°œ â†’ 729ê°œ ì‹¤ì œ ì‹¤í–‰)
                - ê°œì„ ìœ¨ â‰¥5%ì¼ ë•Œë§Œ ì‹¤í–‰
                - í”¼í¬ Â±20% ë²”ìœ„, 7ê°œ í¬ì¸íŠ¸

        Args:
            df: OHLCV ë°ì´í„°í”„ë ˆì„
            trend_tf: ì¶”ì„¸ íƒ€ì„í”„ë ˆì„ (ê¸°ë³¸ '1h')
            metric: ìµœì í™” ëª©í‘œ ì§€í‘œ ('sharpe_ratio', 'win_rate', 'profit_factor' ë“±)
            callback: ì§„í–‰ ìƒí™© ì½œë°± í•¨ìˆ˜ (event: str, *args)
            progress_callback: ë°±í…ŒìŠ¤íŠ¸ ì§„í–‰ë„ ì½œë°±

        Returns:
            {
                'optimal_params': {...},  # ë‹¨ì¼ ìµœì  íŒŒë¼ë¯¸í„°
                'confidence_intervals': {...},  # ì‹ ë¢° êµ¬ê°„
                'extracted_ranges': {...},  # PARAM_RANGES_BY_MODE (ë ˆê±°ì‹œ í˜¸í™˜)
                'best_result': OptimizationResult,
                'iterations': int,
                'convergence_reason': str,
                'statistics': {...}
            }

        Raises:
            ValueError: ë°ì´í„°ê°€ ë¹„ì–´ìˆê±°ë‚˜ ìœ íš¨í•˜ì§€ ì•Šì„ ë•Œ
        """
        if df is None or df.empty:
            raise ValueError("ë°ì´í„°ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤")

        logger.info(f"ğŸ” Grid-Based Meta-Optimization Started: 3-phase adaptive search")
        start_time = time.time()
        total_tested = 0

        # ì§€í‘œ ì‚¬ì „ ê³„ì‚° (1ë²ˆë§Œ ì‹¤í–‰)
        df_computed = self._precompute_indicators(df)

        # Phase 1: Coarse Grid (3^5 = 243ê°œ)
        logger.info("  Phase 1: Coarse Grid (3 points per param)")
        coarse_grid = self._generate_coarse_grid()
        coarse_results = self._run_full_grid(
            df_computed, coarse_grid, metric,
            phase=1, progress_callback=progress_callback
        )

        if not coarse_results:
            raise RuntimeError("Phase 1 failed: No valid results")

        total_tested += len(coarse_results)
        best_coarse = coarse_results[0]
        best_score_coarse = getattr(best_coarse, metric)
        self.iteration_results.append(best_score_coarse)

        if callback:
            callback('iteration_finished', 1, len(coarse_results), best_score_coarse)

        logger.info(f"  Phase 1 finished: best {metric}={best_score_coarse:.2f}")

        # Phase 2: Fine Grid (5^5 = 3,125ê°œ â†’ 243ê°œ ì‹¤ì œ ì‹¤í–‰)
        logger.info("  Phase 2: Fine Grid (5 points, Â±50% range)")
        fine_grid = self._refine_grid(coarse_results, n_points=5, range_factor=0.5)
        fine_results = self._run_full_grid(
            df_computed, fine_grid, metric,
            phase=2, progress_callback=progress_callback
        )

        if not fine_results:
            logger.warning("  Phase 2 failed, using Phase 1 results")
            fine_results = coarse_results

        total_tested += len(fine_results)
        best_fine = fine_results[0]
        best_score_fine = getattr(best_fine, metric)
        self.iteration_results.append(best_score_fine)

        if callback:
            callback('iteration_finished', 2, len(fine_results), best_score_fine)

        logger.info(f"  Phase 2 finished: best {metric}={best_score_fine:.2f}")

        # HIGH #4 FIX (v7.27): Phase 1 ê²°ê³¼ ë©”ëª¨ë¦¬ í•´ì œ (1.2MB ì ˆì•½)
        # Phase 2 ì™„ë£Œ í›„ coarse_resultsëŠ” ë” ì´ìƒ ì‚¬ìš©ë˜ì§€ ì•ŠìŒ
        del coarse_results
        coarse_results = None

        # Phase 3: Ultra-Fine Grid (ì¡°ê±´ë¶€)
        improvement_phase2 = (best_score_fine - best_score_coarse) / best_score_coarse if best_score_coarse > 0 else 0
        convergence_reason = 'improvement_below_threshold'

        if improvement_phase2 >= self.min_improvement:
            logger.info(f"  Phase 3: Ultra-Fine Grid (7 points, Â±20% range, improvement={improvement_phase2*100:.1f}% â‰¥ {self.min_improvement*100}%)")
            ultra_grid = self._refine_grid(fine_results, n_points=7, range_factor=0.2)
            ultra_results = self._run_full_grid(
                df_computed, ultra_grid, metric,
                phase=3, progress_callback=progress_callback
            )

            if ultra_results:
                total_tested += len(ultra_results)
                best_ultra = ultra_results[0]
                best_score_ultra = getattr(best_ultra, metric)
                self.iteration_results.append(best_score_ultra)

                if callback:
                    callback('iteration_finished', 3, len(ultra_results), best_score_ultra)

                logger.info(f"  Phase 3 finished: best {metric}={best_score_ultra:.2f}")
                final_results = ultra_results
            else:
                logger.warning("  Phase 3 failed, using Phase 2 results")
                final_results = fine_results
        else:
            logger.info(f"  Phase 3 skipped: improvement={improvement_phase2*100:.1f}% < {self.min_improvement*100}%")
            final_results = fine_results

        # HIGH #4 FIX (v7.27): Phase 2 ê²°ê³¼ ë©”ëª¨ë¦¬ í•´ì œ
        # final_resultsê°€ ê²°ì •ëœ í›„ fine_resultsëŠ” ë” ì´ìƒ ì‚¬ìš©ë˜ì§€ ì•ŠìŒ
        # (ultra_resultsê°€ ìƒì„±ë˜ì—ˆê±°ë‚˜ fine_resultsê°€ final_resultsë¡œ ëŒ€ì…ë¨)
        if final_results is not fine_results:
            del fine_results
            fine_results = None

        # ìµœì  íŒŒë¼ë¯¸í„° ì¶”ì¶œ
        optimal_params = final_results[0].params

        # ì‹ ë¢° êµ¬ê°„ ê³„ì‚° (ìƒìœ„ 10%)
        top_count = max(1, len(final_results) // 10)
        confidence_intervals = self._calculate_confidence_intervals(final_results[:top_count])

        # ë ˆê±°ì‹œ í˜¸í™˜: PARAM_RANGES_BY_MODE ìƒì„±
        extracted_ranges = self._convert_optimal_to_ranges(optimal_params, confidence_intervals)

        elapsed = time.time() - start_time

        logger.info(
            f"ğŸ‰ Grid-Based Meta-Optimization Completed: {len(self.iteration_results)} phases, "
            f"{total_tested} combinations, {elapsed:.1f}s, reason={convergence_reason}"
        )

        return {
            'optimal_params': optimal_params,
            'confidence_intervals': confidence_intervals,
            'extracted_ranges': extracted_ranges,
            'best_result': final_results[0] if final_results else None,
            'iterations': len(self.iteration_results),
            'convergence_reason': convergence_reason,
            'statistics': {
                'total_combinations_tested': total_tested,
                'time_elapsed_seconds': elapsed,
                'convergence_iterations': len(self.iteration_results),
                'top_score_history': self.iteration_results
            }
        }

    def _generate_coarse_grid(self) -> Dict[str, List]:
        """Coarse Grid ìƒì„± (3-point per parameter)

        ì „ì²´ ë²”ìœ„ë¥¼ 3ê°œ í¬ì¸íŠ¸ë¡œ ìƒ˜í”Œë§ (min, mid, max).
        3^5 = 243ê°œ ì¡°í•© ìƒì„±.

        Returns:
            Dict[íŒŒë¼ë¯¸í„°ëª…, List[3ê°œ ê°’]]

        Example:
            >>> grid = self._generate_coarse_grid()
            >>> grid['atr_mult']  # [0.5, 2.75, 5.0]
            >>> grid['filter_tf']  # ['2h', '6h', '1d']
        """
        grid = {}

        for param, values in self.meta_ranges.items():
            if isinstance(values[0], str):
                # ì¹´í…Œê³ ë¦¬í˜•: ê· ë“± ì„ íƒ (3ê°œ)
                n = len(values)
                if n >= 3:
                    indices = [0, n // 2, n - 1]
                    grid[param] = [values[i] for i in indices]
                else:
                    grid[param] = values
            else:
                # ìˆ˜ì¹˜í˜•: min, mid, max
                if len(values) >= 3:
                    grid[param] = [values[0], values[len(values) // 2], values[-1]]
                else:
                    grid[param] = values

        logger.info(f"    Coarse Grid: {' Ã— '.join([str(len(v)) for v in grid.values()])} = {np.prod([len(v) for v in grid.values()])} combinations")

        return grid

    def _generate_random_sample_combos(
        self,
        ranges: Dict[str, List]
    ) -> List[tuple]:
        """ëœë¤ ìƒ˜í”Œë§ìœ¼ë¡œ ì¡°í•© ìƒì„± (DEPRECATED - ë ˆê±°ì‹œ í˜¸í™˜ìš©)

        ì „ì²´ ì¡°í•©ì—ì„œ sample_size ê°œë§Œí¼ ëœë¤ ìƒ˜í”Œë§í•©ë‹ˆë‹¤.

        Args:
            ranges: íŒŒë¼ë¯¸í„° ë²”ìœ„

        Returns:
            ìƒ˜í”Œë§ëœ ì¡°í•© ë¦¬ìŠ¤íŠ¸
        """
        # ì „ì²´ ì¡°í•© ìƒì„±
        all_combinations = list(itertools.product(*ranges.values()))

        # ìƒ˜í”Œ ìˆ˜ ê²°ì •
        actual_sample_size = min(self.sample_size, len(all_combinations))

        # ëœë¤ ìƒ˜í”Œë§
        sampled_combos = random.sample(all_combinations, actual_sample_size)

        return sampled_combos

    def _refine_grid(
        self,
        results,  # List[OptimizationResult]
        n_points: int = 5,
        range_factor: float = 0.5
    ) -> Dict[str, List]:
        """í”¼í¬ ì¤‘ì‹¬ ê·¸ë¦¬ë“œ ìƒì„±

        ìƒìœ„ ê²°ê³¼ì˜ í”¼í¬ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ Â±range_factor ë²”ìœ„ì˜ ê·¸ë¦¬ë“œ ìƒì„±.

        Args:
            results: ìµœì í™” ê²°ê³¼ ë¦¬ìŠ¤íŠ¸ (ì •ë ¬ë¨)
            n_points: ìƒì„±í•  í¬ì¸íŠ¸ ìˆ˜ (5 ë˜ëŠ” 7)
            range_factor: ë²”ìœ„ ë¹„ìœ¨ (0.5 = Â±50%, 0.2 = Â±20%)

        Returns:
            Dict[íŒŒë¼ë¯¸í„°ëª…, List[n_pointsê°œ ê°’]]

        Algorithm:
            - ìˆ˜ì¹˜í˜•: peak Â± peak * range_factor, n_points ê· ë“± ìƒ˜í”Œë§
            - ì¹´í…Œê³ ë¦¬í˜•: ìƒìœ„ ë¹ˆë„ n_pointsê°œ ì„ íƒ

        Example:
            >>> # Phase 1 best: atr_mult=2.0
            >>> grid = self._refine_grid(results, n_points=5, range_factor=0.5)
            >>> grid['atr_mult']  # [1.0, 1.5, 2.0, 2.5, 3.0] (Â±50%)
        """
        # ìƒìœ„ 10% ê²°ê³¼ ë¶„ì„
        top_count = max(1, len(results) // 10)
        top_results = results[:top_count]

        refined_grid = {}

        for param in self.meta_ranges.keys():
            values = [r.params[param] for r in top_results]

            if isinstance(values[0], str):
                # ì¹´í…Œê³ ë¦¬í˜•: ë¹ˆë„ ìƒìœ„ n_pointsê°œ
                counts = Counter(values)
                refined_grid[param] = [v for v, _ in counts.most_common(n_points)]
            else:
                # ìˆ˜ì¹˜í˜•: í”¼í¬ Â± range_factor
                peak = values[0]  # ìµœê³  ì ìˆ˜ì˜ ê°’
                range_min = max(
                    min(self.meta_ranges[param]),  # ì›ë³¸ ìµœì†Œê°’ ì´ˆê³¼ ë°©ì§€
                    peak * (1 - range_factor)
                )
                range_max = min(
                    max(self.meta_ranges[param]),  # ì›ë³¸ ìµœëŒ€ê°’ ì´ˆê³¼ ë°©ì§€
                    peak * (1 + range_factor)
                )

                refined_grid[param] = np.linspace(range_min, range_max, n_points).tolist()

        logger.info(
            f"    Refined Grid ({n_points} points, Â±{range_factor*100:.0f}%): "
            f"{' Ã— '.join([str(len(v)) for v in refined_grid.values()])} = "
            f"{np.prod([len(v) for v in refined_grid.values()])} combinations"
        )

        return refined_grid

    def _run_full_grid(
        self,
        df,
        grid: Dict[str, List],
        metric: str,
        phase: int = 1,
        progress_callback: Optional[Callable] = None
    ) -> List:
        """ì „ì²´ ê·¸ë¦¬ë“œ ë°±í…ŒìŠ¤íŠ¸ ì‹¤í–‰ (ìƒ˜í”Œë§ ì—†ìŒ)

        Args:
            df: ë°ì´í„°í”„ë ˆì„ (ì§€í‘œ ì‚¬ì „ ê³„ì‚°ë¨)
            grid: íŒŒë¼ë¯¸í„° ê·¸ë¦¬ë“œ
            metric: ìµœì í™” ì§€í‘œ
            phase: Phase ë²ˆí˜¸ (ë¡œê¹…ìš©)
            progress_callback: ì§„í–‰ë„ ì½œë°±

        Returns:
            ìµœì í™” ê²°ê³¼ ë¦¬ìŠ¤íŠ¸ (metric ê¸°ì¤€ ì •ë ¬)
        """
        from concurrent.futures import ThreadPoolExecutor, as_completed
        import multiprocessing

        # ì „ì²´ ì¡°í•© ìƒì„±
        param_names = list(grid.keys())
        all_combinations = list(itertools.product(*grid.values()))
        total_combos = len(all_combinations)

        logger.info(f"    Phase {phase}: Running {total_combos} combinations")

        results = []
        n_cores = max(1, multiprocessing.cpu_count() - 1)

        # ë³‘ë ¬ ë°±í…ŒìŠ¤íŠ¸ ì‹¤í–‰
        with ThreadPoolExecutor(max_workers=n_cores) as executor:
            futures = {}

            for combo in all_combinations:
                params = dict(zip(param_names, combo))
                future = executor.submit(self._single_backtest, params, df)
                futures[future] = params

            # ê²°ê³¼ ìˆ˜ì§‘
            completed_count = 0
            for future in as_completed(futures):
                try:
                    result = future.result()
                    if result:
                        results.append(result)
                except Exception as e:
                    logger.debug(f"Backtest failed: {e}")

                # ì§„í–‰ë„ ì½œë°±
                completed_count += 1
                if progress_callback:
                    progress_callback(
                        'backtest_progress',
                        phase,
                        completed_count,
                        total_combos
                    )

        # ì§€í‘œ ê¸°ì¤€ ì •ë ¬
        if results:
            results.sort(key=lambda r: getattr(r, metric), reverse=True)

        logger.info(f"    Phase {phase} completed: {len(results)}/{total_combos} valid results")

        return results

    def _run_backtest_on_samples(
        self,
        df,
        grid: Dict[str, List],
        sampled_combos: List[tuple],
        metric: str,
        iteration: int = 1,
        progress_callback: Optional[Callable] = None
    ) -> List:
        """ìƒ˜í”Œë§ëœ ì¡°í•©ë§Œ ë°±í…ŒìŠ¤íŠ¸ ì‹¤í–‰ (DEPRECATED - ë ˆê±°ì‹œ í˜¸í™˜ìš©)

        Args:
            df: ë°ì´í„°í”„ë ˆì„
            grid: íŒŒë¼ë¯¸í„° ê·¸ë¦¬ë“œ (í‚¤ ìˆœì„œ ì°¸ì¡°ìš©)
            sampled_combos: ìƒ˜í”Œë§ëœ ì¡°í•©
            metric: ìµœì í™” ì§€í‘œ

        Returns:
            ìµœì í™” ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        """
        from concurrent.futures import ThreadPoolExecutor, as_completed
        from core.optimizer import OptimizationResult
        import multiprocessing

        param_names = list(grid.keys())
        results = []
        total_combos = len(sampled_combos)

        # CPU ì½”ì–´ ìˆ˜
        n_cores = max(1, multiprocessing.cpu_count() - 1)

        # âœ… ì§€í‘œ ì‚¬ì „ ê³„ì‚° (1ë²ˆë§Œ ì‹¤í–‰, 1,000ë²ˆ ì¬ì‚¬ìš©)
        logger.info(f"  Precomputing indicators for {len(df)} candles...")
        df_computed = self._precompute_indicators(df)

        # ë³‘ë ¬ ë°±í…ŒìŠ¤íŠ¸ ì‹¤í–‰ (ThreadPool: ì§ë ¬í™” ì˜¤ë²„í—¤ë“œ ì œê±°)
        with ThreadPoolExecutor(max_workers=n_cores) as executor:
            futures = {}

            for combo in sampled_combos:
                # ì¡°í•©ì„ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
                params = dict(zip(param_names, combo))

                # ë°±í…ŒìŠ¤íŠ¸ ì‘ì—… ì œì¶œ (ì‚¬ì „ ê³„ì‚°ëœ ì§€í‘œ ì‚¬ìš©)
                future = executor.submit(self._single_backtest, params, df_computed)
                futures[future] = params

            # ê²°ê³¼ ìˆ˜ì§‘
            completed_count = 0
            for future in as_completed(futures):
                try:
                    result = future.result()
                    if result:
                        results.append(result)
                except Exception as e:
                    logger.debug(f"Backtest failed: {e}")

                # ì§„í–‰ë„ ì½œë°±
                completed_count += 1
                if progress_callback:
                    progress_callback(
                        'backtest_progress',
                        iteration,
                        completed_count,
                        total_combos
                    )

        # ì§€í‘œ ê¸°ì¤€ ì •ë ¬
        if results:
            results.sort(key=lambda r: getattr(r, metric), reverse=True)

        logger.info(f"  Completed {len(results)}/{len(sampled_combos)} backtests")

        return results

    @staticmethod
    def _single_backtest(params: Dict, df):
        """ë‹¨ì¼ ë°±í…ŒìŠ¤íŠ¸ ì‹¤í–‰ (ì‚¬ì „ ê³„ì‚°ëœ ì§€í‘œ ì‚¬ìš©)

        Args:
            params: íŒŒë¼ë¯¸í„° ë”•ì…”ë„ˆë¦¬
            df: ë°ì´í„°í”„ë ˆì„ (rsi, atr ì»¬ëŸ¼ í¬í•¨)

        Returns:
            OptimizationResult ë˜ëŠ” None

        Note:
            dfì— 'rsi', 'atr' ì»¬ëŸ¼ì´ ì‚¬ì „ ê³„ì‚°ë˜ì–´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.
            ì§€í‘œ ì¬ê³„ì‚°ì„ ê±´ë„ˆë›°ì–´ 7-10ë°° ì„±ëŠ¥ í–¥ìƒ.
        """
        from core.strategy_core import AlphaX7Core
        from core.optimizer import OptimizationResult
        from config.parameters import DEFAULT_PARAMS

        try:
            # ì „ëµ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
            strategy = AlphaX7Core(use_mtf=True)

            # ë°±í…ŒìŠ¤íŠ¸ ì‹¤í–‰ (_worker_run_single íŒ¨í„´ ì‚¬ìš©)
            trades = strategy.run_backtest(
                df_pattern=df,  # 15m ë°ì´í„°
                df_entry=df,     # 15m ë°ì´í„°
                slippage=0.0005,  # ìŠ¬ë¦¬í”¼ì§€
                atr_mult=params.get('atr_mult', DEFAULT_PARAMS.get('atr_mult', 1.5)),
                trail_start_r=params.get('trail_start_r', DEFAULT_PARAMS.get('trail_start_r', 0.8)),
                trail_dist_r=params.get('trail_dist_r', DEFAULT_PARAMS.get('trail_dist_r', 0.02)),
                pattern_tolerance=params.get('pattern_tolerance', DEFAULT_PARAMS.get('pattern_tolerance', 0.03)),
                entry_validity_hours=params.get('entry_validity_hours', DEFAULT_PARAMS.get('entry_validity_hours', 24.0)),
                pullback_rsi_long=params.get('pullback_rsi_long', DEFAULT_PARAMS.get('pullback_rsi_long', 35)),
                pullback_rsi_short=params.get('pullback_rsi_short', DEFAULT_PARAMS.get('pullback_rsi_short', 65)),
                max_adds=params.get('max_adds', DEFAULT_PARAMS.get('max_adds', 1)),
                filter_tf=params.get('filter_tf', '4h'),
                rsi_period=params.get('rsi_period', DEFAULT_PARAMS.get('rsi_period', 14)),
                atr_period=params.get('atr_period', DEFAULT_PARAMS.get('atr_period', 14)),
                macd_fast=params.get('macd_fast', DEFAULT_PARAMS.get('macd_fast', 12)),
                macd_slow=params.get('macd_slow', DEFAULT_PARAMS.get('macd_slow', 26)),
                macd_signal=params.get('macd_signal', DEFAULT_PARAMS.get('macd_signal', 9)),
                ema_period=params.get('ema_period', DEFAULT_PARAMS.get('ema_period', 20)),
                enable_pullback=params.get('enable_pullback', False)
            )

            if not trades or len(trades) == 0:
                return None

            # ë©”íŠ¸ë¦­ ê³„ì‚°
            from utils.metrics import calculate_backtest_metrics
            from core.optimizer import extract_timestamps_from_trades

            bt_metrics = calculate_backtest_metrics(
                trades=trades,
                leverage=params.get('leverage', 1),
                capital=100.0
            )

            # [NEW] íƒ€ì„ìŠ¤íƒ¬í”„ ì¶”ì¶œ (v7.22)
            start_time, end_time, duration_days = extract_timestamps_from_trades(trades)

            # OptimizationResult ìƒì„±
            result = OptimizationResult(
                params=params,
                trades=bt_metrics.get('total_trades', 0),
                win_rate=bt_metrics.get('win_rate', 0),
                total_return=bt_metrics.get('total_pnl', 0),
                simple_return=bt_metrics.get('total_pnl', 0),
                compound_return=bt_metrics.get('total_pnl', 0),
                max_drawdown=bt_metrics.get('mdd', 0),
                sharpe_ratio=bt_metrics.get('sharpe_ratio', 0),
                profit_factor=bt_metrics.get('profit_factor', 0),
                backtest_start_time=start_time,      # [NEW] v7.22
                backtest_end_time=end_time,          # [NEW] v7.22
                backtest_duration_days=duration_days  # [NEW] v7.22
            )

            return result

        except Exception:
            return None

    def _precompute_indicators(
        self,
        df: pd.DataFrame,
        rsi_period: int = 14,
        atr_period: int = 14,
        macd_fast: int = 12,
        macd_slow: int = 26,
        macd_signal: int = 9
    ) -> pd.DataFrame:
        """ë°±í…ŒìŠ¤íŠ¸ìš© ì§€í‘œ ì‚¬ì „ ê³„ì‚°

        ìµœì í™” ì‹œì‘ ì „ ëª¨ë“  ì§€í‘œë¥¼ 1ë²ˆë§Œ ê³„ì‚°í•˜ì—¬ ì¬ì‚¬ìš©í•©ë‹ˆë‹¤.
        1,000ê°œ ì¡°í•© ë°˜ë³µ ì‹œ ì§€í‘œ ì¬ê³„ì‚°ì„ ë°©ì§€í•˜ì—¬ 10-20ë°° ì„±ëŠ¥ í–¥ìƒ.

        Args:
            df: OHLCV ë°ì´í„°í”„ë ˆì„
            rsi_period: RSI ê¸°ê°„ (ê¸°ë³¸ê°’ 14)
            atr_period: ATR ê¸°ê°„ (ê¸°ë³¸ê°’ 14)
            macd_fast: MACD fast ê¸°ê°„ (ê¸°ë³¸ê°’ 12)
            macd_slow: MACD slow ê¸°ê°„ (ê¸°ë³¸ê°’ 26)
            macd_signal: MACD signal ê¸°ê°„ (ê¸°ë³¸ê°’ 9)

        Returns:
            ì§€í‘œê°€ ì¶”ê°€ëœ ë°ì´í„°í”„ë ˆì„ (ì›ë³¸ ë³´ì¡´)

        Performance:
            - Before: 1,000ë²ˆ ì¬ê³„ì‚° (60ì´ˆ+)
            - After: 1ë²ˆ ê³„ì‚° (3-5ì´ˆ, 10-20ë°° ë¹ ë¦„)
        """
        from utils.indicators import calculate_rsi, calculate_atr

        # ì›ë³¸ ë³´ì¡´ (ë³µì‚¬)
        df_computed = df.copy()

        # RSI ê³„ì‚° (ë²¡í„°í™”, EWM ê¸°ë°˜)
        rsi_series = calculate_rsi(
            df_computed['close'],  # Seriesë¡œ ì „ë‹¬
            period=rsi_period,
            return_series=True
        )
        df_computed['rsi'] = rsi_series

        # ATR ê³„ì‚° (ë²¡í„°í™”, Wilder's Smoothing)
        atr_series = calculate_atr(
            df_computed,
            period=atr_period,
            return_series=True
        )
        df_computed['atr'] = atr_series

        # MACD ê³„ì‚° (íˆìŠ¤í† ê·¸ë¨ í¬í•¨) - ê°€ì¥ ëŠë¦° ë¶€ë¶„!
        exp1 = df_computed['close'].ewm(span=macd_fast, adjust=False).mean()
        exp2 = df_computed['close'].ewm(span=macd_slow, adjust=False).mean()
        macd_line = exp1 - exp2
        signal_line = macd_line.ewm(span=macd_signal, adjust=False).mean()
        df_computed['macd'] = macd_line
        df_computed['macd_signal'] = signal_line
        df_computed['macd_hist'] = macd_line - signal_line

        logger.info(f"  âœ… Indicators precomputed: RSI({rsi_period}), ATR({atr_period}), MACD({macd_fast},{macd_slow},{macd_signal})")

        return df_computed

    def _generate_random_sample(
        self,
        ranges: Dict[str, List]
    ) -> Dict[str, List]:
        """ëœë¤ ìƒ˜í”Œë§ìœ¼ë¡œ ê·¸ë¦¬ë“œ ìƒì„±

        ì „ì²´ ì¡°í•©ì—ì„œ sample_size ê°œë§Œí¼ ëœë¤ ìƒ˜í”Œë§í•˜ì—¬ ê·¸ë¦¬ë“œë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

        Args:
            ranges: íŒŒë¼ë¯¸í„° ë²”ìœ„ (META_PARAM_RANGES ë˜ëŠ” extracted_ranges)

        Returns:
            ìƒ˜í”Œë§ëœ ê·¸ë¦¬ë“œ (Dict[íŒŒë¼ë¯¸í„°ëª…, List[ê°’]])

        Example:
            >>> ranges = {'atr_mult': [1.0, 1.5, 2.0], 'filter_tf': ['4h', '6h']}
            >>> grid = self._generate_random_sample(ranges)
            >>> # ì „ì²´ 6ê°œ ì¡°í•© ì¤‘ min(sample_size, 6)ê°œ ìƒ˜í”Œë§
        """
        # ì „ì²´ ì¡°í•© ìƒì„±
        all_combinations = list(itertools.product(*ranges.values()))

        # ìƒ˜í”Œ ìˆ˜ ê²°ì • (ì „ì²´ ì¡°í•© ìˆ˜ì™€ sample_size ì¤‘ ì‘ì€ ê°’)
        actual_sample_size = min(self.sample_size, len(all_combinations))

        # ëœë¤ ìƒ˜í”Œë§
        sampled_combos = random.sample(all_combinations, actual_sample_size)

        # Dict í˜•ì‹ìœ¼ë¡œ ë³€í™˜ (ê° íŒŒë¼ë¯¸í„°ë³„ ê³ ìœ  ê°’ë§Œ ì¶”ì¶œ)
        param_names = list(ranges.keys())
        grid = {name: [] for name in param_names}

        for combo in sampled_combos:
            for i, name in enumerate(param_names):
                if combo[i] not in grid[name]:
                    grid[name].append(combo[i])

        logger.info(f"    Sampled {actual_sample_size} combinations from {len(all_combinations)} total")

        return grid

    def _calculate_confidence_intervals(
        self,
        top_results  # List[OptimizationResult]
    ) -> Dict[str, Dict[str, float]]:
        """ì‹ ë¢° êµ¬ê°„ ê³„ì‚° (ìƒìœ„ 10% ê²°ê³¼)

        Args:
            top_results: ìƒìœ„ 10% ìµœì í™” ê²°ê³¼ ë¦¬ìŠ¤íŠ¸

        Returns:
            Dict[íŒŒë¼ë¯¸í„°ëª…, {mean, std, min, max}]

        Example:
            >>> intervals = self._calculate_confidence_intervals(top_results)
            >>> intervals['atr_mult']
            {'mean': 1.8, 'std': 0.3, 'min': 1.2, 'max': 2.4}
        """
        intervals = {}

        for param in self.meta_ranges.keys():
            values = [r.params[param] for r in top_results]

            if isinstance(values[0], str):
                # ì¹´í…Œê³ ë¦¬í˜•: ìµœë¹ˆê°’ë§Œ
                counts = Counter(values)
                most_common = counts.most_common(1)[0][0]
                intervals[param] = {
                    'mode': most_common,
                    'count': counts[most_common],
                    'total': len(values)
                }
            else:
                # ìˆ˜ì¹˜í˜•: í†µê³„ ê°’
                intervals[param] = {
                    'mean': float(np.mean(values)),
                    'std': float(np.std(values)),
                    'min': float(np.min(values)),
                    'max': float(np.max(values))
                }

        return intervals

    def _extract_ranges_from_top_results(
        self,
        top_results  # List[OptimizationResult]
    ) -> Dict[str, List]:
        """ë°±ë¶„ìœ„ìˆ˜ ê¸°ë°˜ ë²”ìœ„ ì¶”ì¶œ

        ìƒìœ„ ê²°ê³¼ì˜ íŒŒë¼ë¯¸í„° ë¶„í¬ë¥¼ ë¶„ì„í•˜ì—¬ ìƒˆë¡œìš´ ë²”ìœ„ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.

        Args:
            top_results: ìƒìœ„ 10% ìµœì í™” ê²°ê³¼ ë¦¬ìŠ¤íŠ¸

        Returns:
            ì¶”ì¶œëœ ë²”ìœ„ (Dict[íŒŒë¼ë¯¸í„°ëª…, List[ê°’]])

        Algorithm:
            - ìˆ˜ì¹˜í˜•: 10~90% ë°±ë¶„ìœ„ìˆ˜ ê¸°ë°˜ 5ê°œ ê· ë“± ìƒ˜í”Œë§
            - ì¹´í…Œê³ ë¦¬í˜•: ë¹ˆë„ ìƒìœ„ 5ê°œ ì„ íƒ

        Example:
            >>> top_results = [...]  # 100ê°œ ê²°ê³¼
            >>> ranges = self._extract_ranges_from_top_results(top_results)
            >>> # {'atr_mult': [1.2, 1.5, 1.8, 2.1, 2.4], 'filter_tf': ['4h', '6h', '12h']}
        """
        new_ranges = {}

        for param in self.meta_ranges.keys():
            # ìƒìœ„ ê²°ê³¼ì—ì„œ íŒŒë¼ë¯¸í„° ê°’ ì¶”ì¶œ
            values = [r.params[param] for r in top_results]

            if isinstance(values[0], str):
                # ì¹´í…Œê³ ë¦¬í˜• (filter_tf)
                counts = Counter(values)
                new_ranges[param] = [v for v, c in counts.most_common(5)]
                logger.info(f"    {param} (categorical): {new_ranges[param]}")
            else:
                # ìˆ˜ì¹˜í˜• (atr_mult, trail_start_r, trail_dist_r, entry_validity_hours)
                p10 = np.percentile(values, 10)  # í•˜ìœ„ 10% ì œê±°
                p90 = np.percentile(values, 90)  # ìƒìœ„ 10% ì œê±°
                new_ranges[param] = np.linspace(p10, p90, 5).tolist()  # 5ê°œ ê· ë“± ìƒ˜í”Œë§
                logger.info(f"    {param} (numeric): [{p10:.2f}, ..., {p90:.2f}]")

        return new_ranges

    def _convert_optimal_to_ranges(
        self,
        optimal_params: Dict,
        confidence_intervals: Dict
    ) -> Dict:
        """ë‹¨ì¼ ìµœì ê°’ì„ PARAM_RANGES_BY_MODE í˜•ì‹ìœ¼ë¡œ ë³€í™˜ (ë ˆê±°ì‹œ í˜¸í™˜)

        Args:
            optimal_params: ìµœì  íŒŒë¼ë¯¸í„° (ë‹¨ì¼ ê°’)
            confidence_intervals: ì‹ ë¢° êµ¬ê°„

        Returns:
            PARAM_RANGES_BY_MODE í˜•ì‹
            {
                'atr_mult': {
                    'quick': [1.8],  # ë‹¨ì¼ ìµœì ê°’
                    'standard': [1.8],
                    'deep': [1.8]
                }
            }

        Note:
            ê·¸ë¦¬ë“œ MetaëŠ” ë‹¨ì¼ ìµœì ê°’ì„ ì¶œë ¥í•˜ë¯€ë¡œ, 3ê°œ ëª¨ë“œ ëª¨ë‘ ë™ì¼í•œ ê°’ ì‚¬ìš©.
            ê¸°ì¡´ UI/ì›Œí¬í”Œë¡œìš°ì™€ í˜¸í™˜ì„± ìœ ì§€.
        """
        result = {}

        for param, optimal_value in optimal_params.items():
            if isinstance(optimal_value, str):
                # ì¹´í…Œê³ ë¦¬í˜•: ìµœì ê°’ë§Œ
                result[param] = {
                    'quick': [optimal_value],
                    'standard': [optimal_value],
                    'deep': [optimal_value]
                }
            else:
                # ìˆ˜ì¹˜í˜•: ìµœì ê°’ Â± std (ì„ íƒì  ë²”ìœ„)
                interval = confidence_intervals.get(param, {})
                mean = interval.get('mean', optimal_value)
                std = interval.get('std', 0)

                # Quick: ìµœì ê°’ë§Œ
                # Standard: ìµœì ê°’ Â± 0.5*std (3ê°œ)
                # Deep: ìµœì ê°’ Â± std (5ê°œ)
                result[param] = {
                    'quick': [optimal_value],
                    'standard': [
                        max(mean - 0.5 * std, min(self.meta_ranges[param])),
                        optimal_value,
                        min(mean + 0.5 * std, max(self.meta_ranges[param]))
                    ],
                    'deep': [
                        max(mean - std, min(self.meta_ranges[param])),
                        max(mean - 0.5 * std, min(self.meta_ranges[param])),
                        optimal_value,
                        min(mean + 0.5 * std, max(self.meta_ranges[param])),
                        min(mean + std, max(self.meta_ranges[param]))
                    ]
                }

        return result

    def _convert_to_param_ranges_by_mode(
        self,
        ranges: Dict[str, List]
    ) -> Dict:
        """PARAM_RANGES_BY_MODE í˜•ì‹ìœ¼ë¡œ ë³€í™˜

        ì¶”ì¶œëœ ë²”ìœ„ë¥¼ Quick/Standard/Deep ëª¨ë“œë³„ ë²”ìœ„ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.

        Args:
            ranges: ì¶”ì¶œëœ ë²”ìœ„ (5ê°œ ê°’)

        Returns:
            PARAM_RANGES_BY_MODE í˜•ì‹
            {
                'atr_mult': {
                    'quick': [1.2, 2.4],               # ì–‘ ë
                    'standard': [1.2, 1.8, 2.4],       # ì‹œì‘/ì¤‘ê°„/ë
                    'deep': [1.2, 1.5, 1.8, 2.1, 2.4]  # ì „ì²´
                }
            }

        Algorithm:
            - Quick: 2ê°œ (ì–‘ ë)
            - Standard: 3ê°œ (ì‹œì‘, ì¤‘ê°„, ë)
            - Deep: 5ê°œ (ì „ì²´)
        """
        result = {}

        for param, values in ranges.items():
            if isinstance(values[0], str):
                # ì¹´í…Œê³ ë¦¬í˜•
                n = len(values)
                result[param] = {
                    'quick': values[:2] if n >= 2 else values,
                    'standard': values[:3] if n >= 3 else values,
                    'deep': values
                }
            else:
                # ìˆ˜ì¹˜í˜•
                n = len(values)
                result[param] = {
                    'quick': [values[0], values[-1]],  # ì–‘ ë
                    'standard': [values[0], values[n//2], values[-1]],  # ì‹œì‘/ì¤‘ê°„/ë
                    'deep': values  # ì „ì²´
                }

        return result

    def _check_convergence(self) -> bool:
        """ìˆ˜ë ´ ì¡°ê±´ ì²´í¬

        ìµœê·¼ 2íšŒ ë°˜ë³µì˜ ê°œì„ ìœ¨ì´ ëª¨ë‘ min_improvement (ê¸°ë³¸ 5%) ë¯¸ë§Œì´ë©´ ìˆ˜ë ´ìœ¼ë¡œ íŒë‹¨í•©ë‹ˆë‹¤.

        Returns:
            True: ìˆ˜ë ´ ì™„ë£Œ
            False: ì¶”ê°€ ë°˜ë³µ í•„ìš”

        Algorithm:
            1. ìµœì†Œ 2íšŒ ë°˜ë³µ ì™„ë£Œ í•„ìš”
            2. ìµœê·¼ 2íšŒ ê°œì„ ìœ¨ ê³„ì‚°
            3. ëª¨ë‘ < min_improvementì´ë©´ ìˆ˜ë ´

        Example:
            >>> self.iteration_results = [18.0, 18.72, 19.09]
            >>> # ê°œì„ ìœ¨: +4.0%, +2.0% â†’ ìˆ˜ë ´!
        """
        if len(self.iteration_results) < 2:
            return False

        # ìµœê·¼ 2íšŒ ê°œì„ ìœ¨ ê³„ì‚° (ì˜¬ë°”ë¥¸ ì¸ë±ì‹±)
        prev = self.iteration_results[-2]  # ì´ì „ ë°˜ë³µ
        curr = self.iteration_results[-1]  # í˜„ì¬ ë°˜ë³µ

        if prev == 0:
            improvement = 0
        else:
            improvement = (curr - prev) / prev

        # ê°œì„ ìœ¨ì´ min_improvement ë¯¸ë§Œì´ë©´ ìˆ˜ë ´
        return improvement < self.min_improvement

    def save_meta_ranges(
        self,
        exchange: str,
        symbol: str,
        timeframe: str,
        best_result=None,  # OptimizationResult (v7.23 ì¶”ê°€)
        output_dir: str = 'presets/meta_ranges'
    ) -> str:
        """ë©”íƒ€ ë²”ìœ„ë¥¼ JSONìœ¼ë¡œ ì €ì¥ (v7.23: best_params, best_metrics ì¶”ê°€)

        Args:
            exchange: ê±°ë˜ì†Œëª… (ì˜ˆ: 'bybit')
            symbol: ì‹¬ë³¼ëª… (ì˜ˆ: 'BTCUSDT')
            timeframe: íƒ€ì„í”„ë ˆì„ (ì˜ˆ: '1h')
            best_result: ìµœê³  ì„±ëŠ¥ OptimizationResult (v7.23 ì‹ ê·œ)
            output_dir: ì €ì¥ ë””ë ‰í† ë¦¬ (ê¸°ë³¸: 'presets/meta_ranges')

        Returns:
            ì €ì¥ëœ íŒŒì¼ ê²½ë¡œ

        Example:
            >>> meta.save_meta_ranges('bybit', 'BTCUSDT', '1h', best_result)
            'presets/meta_ranges/bybit_BTCUSDT_1h_meta_20260117_180000.json'
        """
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        filename = f"{exchange}_{symbol}_{timeframe}_meta_{timestamp}.json"
        filepath = os.path.join(output_dir, filename)

        data = {
            'meta_optimization_id': f"{exchange}_{symbol}_{timeframe}_meta_{timestamp}",
            'created_at': datetime.now().isoformat(),
            'meta_method': 'grid_based_adaptive',  # v7.23: ì•Œê³ ë¦¬ì¦˜ ëª…ì‹œ
            'exchange': exchange,
            'symbol': symbol,
            'timeframe': timeframe,
            'iterations': len(self.iteration_results),
            'convergence_reason': 'improvement_below_threshold' if self._check_convergence() else 'max_iterations_reached',
            'extracted_ranges': self.extracted_ranges,
            'param_ranges_by_mode': self._convert_to_param_ranges_by_mode(self.extracted_ranges) if self.extracted_ranges else {},
            'statistics': {
                'total_combinations_tested': len(self.iteration_results) * self.sample_size,
                'time_elapsed_seconds': 0,  # í˜¸ì¶œ ì‹œì ì—ì„œëŠ” ê³„ì‚° ë¶ˆê°€
                'convergence_iterations': len(self.iteration_results),
                'top_score_history': self.iteration_results,
                'sample_size': self.sample_size,
                'min_improvement': self.min_improvement,
                'max_iterations': self.max_iterations
            }
        }

        # âœ… v7.23: best_params, best_metrics ì¶”ê°€
        if best_result:
            data['best_params'] = {
                'atr_mult': best_result.params.get('atr_mult'),
                'filter_tf': best_result.params.get('filter_tf'),
                'trail_start_r': best_result.params.get('trail_start_r'),
                'trail_dist_r': best_result.params.get('trail_dist_r'),
                'entry_validity_hours': best_result.params.get('entry_validity_hours'),
                'leverage': best_result.params.get('leverage', 1)
            }
            data['best_metrics'] = {
                'win_rate': best_result.win_rate,
                'mdd': best_result.max_drawdown,
                'sharpe_ratio': best_result.sharpe_ratio,
                'profit_factor': best_result.profit_factor,
                'total_trades': best_result.trades,
                'total_pnl': best_result.total_return
            }
            logger.info(
                f"  âœ… Best result: Sharpe={best_result.sharpe_ratio:.2f}, "
                f"WinRate={best_result.win_rate:.1f}%, MDD={best_result.max_drawdown:.2f}%"
            )

        # ë””ë ‰í† ë¦¬ ìƒì„±
        os.makedirs(output_dir, exist_ok=True)

        # JSON ì €ì¥
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(data, f, indent=2, ensure_ascii=False)

        logger.info(f"âœ… Meta ranges saved: {filepath}")

        return filepath


if __name__ == '__main__':
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    print("=== MetaOptimizer Test ===")
    print("This module requires BacktestOptimizer instance.")
    print("Usage:")
    print("  from core.meta_optimizer import MetaOptimizer")
    print("  meta = MetaOptimizer(base_optimizer)")
    print("  result = meta.run_meta_optimization(df)")
