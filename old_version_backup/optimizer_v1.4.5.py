# optimizer.py
"""
STAR-U Bot ìµœì í™” ì—”ì§„
- íŒŒë¼ë¯¸í„° ê·¸ë¦¬ë“œ ì„œì¹˜
- ê²°ê³¼ ì •ë ¬ ë° ë­í‚¹
- ìµœì ê°’ ë°˜í™˜
"""

import itertools
import pandas as pd
import numpy as np
from typing import Dict, List, Optional, Callable
from dataclasses import dataclass
from concurrent.futures import ThreadPoolExecutor, as_completed
import time
import sys
import os

# TF_MAPPING, TF_RESAMPLE_MAP import
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'GUI'))
try:
    from constants import TF_MAPPING, TF_RESAMPLE_MAP, DEFAULT_PARAMS
    from utils.data_utils import resample_data as shared_resample
except ImportError:
    TF_MAPPING = {'1h': '15min', '4h': '1h', '1d': '4h', '1w': '1d'}
    TF_RESAMPLE_MAP = {
        '15min': '15min', '15m': '15min', '30min': '30min', '30m': '30min',
        '1h': '1h', '1H': '1h', '4h': '4h', '4H': '4h', '1d': '1D', '1D': '1D', '1w': '1W', '1W': '1W'
    }
    DEFAULT_PARAMS = {'atr_mult': 1.25, 'slippage': 0.0005, 'fee': 0.00055}
    shared_resample = None  # fallback


# ==================== ìµœì í™” ìƒìˆ˜ ====================

# ë¦¬ìƒ˜í”Œë§ ê°€ëŠ¥í•œ TF
AVAILABLE_TF = ['15m', '30m', '45m', '1h', '2h', '3h', '4h', '6h', '12h', '1d', '1w']

# ì¶”ì„¸ TFë³„ ìë™ íƒìƒ‰ ë²”ìœ„
TF_AUTO_RANGE = {
    '1h': {
        'filter_tf': ['2h', '4h', '6h', '12h', '1d'],
        'entry_tf': ['15m', '30m', '45m']
    },
    '4h': {
        'filter_tf': ['6h', '12h', '1d'],
        'entry_tf': ['15m', '30m', '1h', '2h']
    },
    '1d': {
        'filter_tf': ['1w'],
        'entry_tf': ['1h', '2h', '4h', '6h', '12h']
    },
    '1w': {
        'filter_tf': ['1d'],
        'entry_tf': ['4h', '6h', '12h', '1d']
    }
}

# ë°°ìœ¨ ë²”ìœ„
LEVERAGE_RANGE = [1, 2, 3, 5, 7, 10, 15, 20]

# ë°©í–¥ ë²”ìœ„
DIRECTION_RANGE = ['Both', 'Long', 'Short']

# ì§€í‘œ ë²”ìœ„
INDICATOR_RANGE = {
    'atr_mult': [1.0, 1.1, 1.2, 1.25, 1.35, 1.5],     # [MOD] ë³´ìˆ˜ì  ë²”ìœ„ (ê¸°ì¡´ 2.5ê¹Œì§€ ì œê±°)
    'trail_start_r': [0.5, 0.7, 1.0, 1.2, 1.5, 2.0],  # [MOD] ë” ì´˜ì´˜í•˜ê²Œ
    'trail_dist_r': [0.1, 0.2, 0.3, 0.4, 0.5],        # [MOD] í‘œì¤€ ë²”ìœ„
    # [NEW] Phase 1.5 - ëˆ„ë½ íŒŒë¼ë¯¸í„° ì¶”ê°€
    'pattern_tolerance': [0.03, 0.04, 0.05],
    'entry_validity_hours': [6.0, 8.0, 12.0],
}


# ==================== Grid ìƒì„± í•¨ìˆ˜ ====================

def generate_full_grid(trend_tf: str, max_mdd: float = 20.0) -> Dict:
    """
    Standard ëª¨ë“œìš© Grid ìƒì„± (~3,000ê°œ)
    """
    tf_range = TF_AUTO_RANGE.get(trend_tf, TF_AUTO_RANGE['1h'])
    
    return {
        'trend_interval': [trend_tf],
        'filter_tf': tf_range['filter_tf'][:3],   # 3ê°œ
        'entry_tf': [tf_range['entry_tf'][0]],    # 1ê°œ (ì¤‘ìš”ë„ê°€ ë‚®ìŒ)
        'leverage': [3, 5, 10],                   # 3ê°œ
        'direction': ['Both', 'Long'],            # 2ê°œ (Core: 3*1*3*2 = 18)
        'max_mdd': [max_mdd],
        'atr_mult': [1.1, 1.2, 1.25, 1.35, 1.5],     # [MOD] ë³´ìˆ˜ì  ë²”ìœ„
        'trail_start_r': [0.7, 1.0, 1.5, 2.0, 3.0], # 5
        'trail_dist_r': [0.15, 0.2, 0.25, 0.35],    # 4
        'pattern_tolerance': [0.05],                # 5%ë¡œ ì™„í™” (ê¸°ë³¸ 3%ëŠ” ë„ˆë¬´ ì—„ê²©í•¨)
        'entry_validity_hours': [6.0, 12.0],        # 2 (Indicator: 5*5*4*1*2 = 200)
        # Total: 18 * 200 = 3,600
    }

def generate_quick_grid(trend_tf: str, max_mdd: float = 20.0) -> Dict:
    """Quick ëª¨ë“œìš© ìµœì†Œ Grid (~100ê°œ)"""
    tf_range = TF_AUTO_RANGE.get(trend_tf, TF_AUTO_RANGE['1h'])
    
    return {
        'trend_interval': [trend_tf],
        'filter_tf': [tf_range['filter_tf'][0]],
        'entry_tf': [tf_range['entry_tf'][0]],
        'leverage': [1, 2, 3, 4, 5],
        'direction': ['Both'],
        'max_mdd': [max_mdd],
        'atr_mult': [1.25, 1.35, 1.5],              # [MOD] ë³´ìˆ˜ì  ë²”ìœ„ë¡œ ìˆ˜ì • (1.5~3.5 -> 1.25~1.5)
        'trail_start_r': [0.7, 1.5, 2.5],            # 3
        'trail_dist_r': [0.2, 0.35],                 # 2
        'pattern_tolerance': [0.04],                 # 1
        'entry_validity_hours': [8.0, 12.0],         # 2
        # Total: 1*1*1*1 * 3*3*2*1*2 = 36ê°œ (ë§¤ìš° ë¹ ë¦„, ìœ ì˜ë¯¸í•œ ìƒ˜í”Œë§)
    }

def generate_standard_grid(trend_tf: str, max_mdd: float = 20.0) -> Dict:
    """Standard ëª¨ë“œìš© Grid (~3,000ê°œ)"""
    return generate_full_grid(trend_tf, max_mdd)

def generate_deep_grid(trend_tf: str, max_mdd: float = 20.0) -> Dict:
    """Deep ëª¨ë“œìš© ì •ë°€ Grid (~12,000ê°œ)"""
    tf_range = TF_AUTO_RANGE.get(trend_tf, TF_AUTO_RANGE['1h'])
    
    return {
        'trend_interval': [trend_tf],
        'filter_tf': tf_range['filter_tf'][:4],      # 4
        'entry_tf': tf_range['entry_tf'][:2],        # 2
        'leverage': [3, 5, 7, 10],                   # 4
        'direction': ['Both', 'Long'],               # 2 (Core: 4*2*4*2 = 64)
        'max_mdd': [max_mdd],
        'atr_mult': [1.0, 1.1, 1.2, 1.25, 1.35, 1.5], # [MOD] ë³´ìˆ˜ì  ë²”ìœ„
        'trail_start_r': [0.5, 0.7, 1.0, 1.2, 1.5, 2.0, 2.5, 3.0], # 8
        'trail_dist_r': [0.1, 0.2, 0.3, 0.4, 0.5],   # 5
        'pattern_tolerance': [0.03],                 # 1
        'entry_validity_hours': [6.0],               # 1 (Indicator: 5*8*5*1*1 = 200)
        # Total: 64 * 200 = 12,800
    }


def generate_fast_grid(trend_tf: str, max_mdd: float = 20.0) -> Dict:
    """
    ë¹ ë¥¸ íƒìƒ‰ìš© ì¶•ì†Œ Grid ìƒì„±
    - INDICATOR_RANGEì—ì„œ ì„±ê¸´(Sparse) í˜•íƒœë¡œ ìƒ˜í”Œë§
    
    Args:
        trend_tf: ì¶”ì„¸ íƒ€ì„í”„ë ˆì„
        max_mdd: ìµœëŒ€ í—ˆìš© MDD (%)
    
    Returns:
        ì¶•ì†Œëœ íŒŒë¼ë¯¸í„° grid dict
    """
    tf_range = TF_AUTO_RANGE.get(trend_tf, TF_AUTO_RANGE['1h'])
    
    # INDICATOR_RANGEì—ì„œ ì§•ê²€ë‹¤ë¦¬ì‹ìœ¼ë¡œ ì„ íƒ (ë°ì´í„° ìˆ˜ ëŒ€í­ ê°ì†Œ)
    grid = {
        'trend_interval': [trend_tf],
        'filter_tf': [tf_range['filter_tf'][0]],      # ìµœì  í›„ë³´ 1ê°œ
        'entry_tf': [tf_range['entry_tf'][0]],        # ìµœì  í›„ë³´ 1ê°œ
        'leverage': [3, 10],                          # 2ë‹¨ê³„ ìƒëµ
        'direction': ['Both'],                         # ê¸°ë³¸ ë°©í–¥
        'max_mdd': [max_mdd],
        'atr_mult': [1.25, 1.35, 1.5],                 # [MOD] ë³´ìˆ˜ì  ë²”ìœ„ë¡œ ì œí•œ
        'trail_start_r': INDICATOR_RANGE['trail_start_r'][::3], # [0.5, 0.8, 1.1]
        'trail_dist_r': INDICATOR_RANGE['trail_dist_r'][::3],   # [0.1, 0.25, 0.4]
    }
    
    return grid


def estimate_combinations(param_grid: Dict) -> tuple:
    """
    íŒŒë¼ë¯¸í„° ì¡°í•© ìˆ˜ ë° ì˜ˆìƒ ì‹œê°„ ê³„ì‚°
    
    Args:
        param_grid: íŒŒë¼ë¯¸í„° grid dict
    
    Returns:
        (ì¡°í•©ìˆ˜, ì˜ˆìƒì‹œê°„ë¶„)
    """
    total = 1
    for key, values in param_grid.items():
        if isinstance(values, list):
            total *= len(values)
    
    # ë°±í…ŒìŠ¤íŠ¸ 1íšŒë‹¹ ì•½ 0.05ì´ˆ ê°€ì •
    estimated_seconds = total * 0.05
    estimated_minutes = estimated_seconds / 60
    
    return (total, round(estimated_minutes, 1))


@dataclass
class OptimizationResult:
    """ìµœì í™” ê²°ê³¼ ë°ì´í„°"""
    params: Dict
    trades: int
    win_rate: float
    total_return: float
    max_drawdown: float
    sharpe_ratio: float
    profit_factor: float
    stability: str = "âš ï¸"        # [NEW] 3êµ¬ê°„ ì•ˆì •ì„± ì§€í‘œ
    strategy_type: str = ""      # [NEW] ì „ëµ ìœ í˜• (ğŸ”¥ê³µê²©, âš–ê· í˜•, ğŸ›¡ë³´ìˆ˜ ë“±)


class BacktestOptimizer:
    """íŒŒë¼ë¯¸í„° ê·¸ë¦¬ë“œ ì„œì¹˜ ìµœì í™”"""
    
    # TF ë§¤í•‘ì€ ìƒë‹¨ì—ì„œ importí•œ TF_MAPPING ì‚¬ìš©
    
    def __init__(self, strategy_class, df: pd.DataFrame = None):
        """
        Args:
            strategy_class: X7PlusStrategy ë“± ì „ëµ í´ë˜ìŠ¤
            df: ë°±í…ŒìŠ¤íŠ¸ìš© ë°ì´í„°í”„ë ˆì„
        """
        self.strategy_class = strategy_class
        self.df = df
        self.results: List[OptimizationResult] = []
        self.progress_callback: Optional[Callable] = None
        self.cancelled = False
    
    def set_data(self, df: pd.DataFrame):
        """ë°ì´í„° ì„¤ì •"""
        self.df = df
    
    def set_progress_callback(self, callback: Callable):
        """ì§„í–‰ë¥  ì½œë°± ì„¤ì •"""
        self.progress_callback = callback
    
    def cancel(self):
        """ìµœì í™” ì·¨ì†Œ"""
        self.cancelled = True
        
    def _resample(self, df: pd.DataFrame, target_tf: str) -> pd.DataFrame:
        """15m â†’ Target TF ë¦¬ìƒ˜í”Œë§ (ê³µìš© í•¨ìˆ˜ ì‚¬ìš©)"""
        # ê³µìš© utils.data_utils.resample_data ì‚¬ìš©
        if shared_resample:
            return shared_resample(df, target_tf, add_indicators=True)
        
        # Fallback: ë¡œì»¬ êµ¬í˜„
        rule = TF_RESAMPLE_MAP.get(target_tf, target_tf)
        df = df.copy()
        if 'datetime' not in df.columns:
            if pd.api.types.is_numeric_dtype(df['timestamp']):
                df['datetime'] = pd.to_datetime(df['timestamp'], unit='ms')
            else:
                df['datetime'] = pd.to_datetime(df['timestamp'])
        df = df.set_index('datetime')
        resampled = df.resample(rule).agg({
            'timestamp': 'first', 'open': 'first', 'high': 'max',
            'low': 'min', 'close': 'last', 'volume': 'sum'
        }).dropna().reset_index()
        try:
            from indicator_generator import IndicatorGenerator
            resampled = IndicatorGenerator.add_all_indicators(resampled)
            if 'rsi' not in resampled.columns and 'rsi_14' in resampled.columns:
                resampled['rsi'] = resampled['rsi_14']
            if 'atr' not in resampled.columns and 'atr_14' in resampled.columns:
                resampled['atr'] = resampled['atr_14']
        except Exception as e:
            print(f"âš ï¸ ì§€í‘œ ì¬ê³„ì‚° ì‹¤íŒ¨: {e}")
        print(f"ğŸ“Š [OPT] ì§€í‘œ ì¬ê³„ì‚°: {target_tf} ({len(resampled)}ìº”ë“¤)")
        return resampled
    
    def optimize(self, param_grid: Dict, metric: str = 'sharpe',
                 slippage: float = 0.0005, fee: float = 0.00055, n_cores=None) -> List[OptimizationResult]:
        """
        ê·¸ë¦¬ë“œ ì„œì¹˜ ìµœì í™” ì‹¤í–‰
        
        Args:
            param_grid: íŒŒë¼ë¯¸í„° ê·¸ë¦¬ë“œ
                ì˜ˆ: {
                    'atr_mult': [1.0, 1.5, 2.0],
                    'trail_start_r': [0.8, 1.0, 1.2],
                    'trail_dist_r': [0.2, 0.3],
                    'rsi_period': [14, 21]
                }
            metric: ì •ë ¬ ê¸°ì¤€ ('sharpe', 'return', 'win_rate', 'profit_factor')
            slippage: ìŠ¬ë¦¬í”¼ì§€ (ê¸°ë³¸ 0.05%)
            fee: ìˆ˜ìˆ˜ë£Œ (ê¸°ë³¸ 0.055%, ì™•ë³µ 0.11%)
            
        Returns:
            ì •ë ¬ëœ OptimizationResult ë¦¬ìŠ¤íŠ¸
        """
        if self.df is None or self.df.empty:
            raise ValueError("ë°ì´í„°ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
        
        # [FIX] df íƒ€ì„ìŠ¤íƒ¬í”„ ë³€í™˜ (í•œ ë²ˆë§Œ ìˆ˜í–‰)
        df = self.df.copy()
        if not pd.api.types.is_datetime64_any_dtype(df['timestamp']):
            first_ts = df['timestamp'].iloc[0]
            if isinstance(first_ts, (int, float, np.number)) and first_ts > 100000000000:
                df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')
            else:
                df['timestamp'] = pd.to_datetime(df['timestamp'])
        self.df = df

        self.cancelled = False
        self.results = []
        
        # ë¦¬ìƒ˜í”Œë§ ìºì‹œ ì´ˆê¸°í™”
        self._resample_cache = {}
        
        # ëª¨ë“  íŒŒë¼ë¯¸í„° ì¡°í•© ìƒì„±
        keys = list(param_grid.keys())
        values = list(param_grid.values())
        combinations = list(itertools.product(*values))
        total = len(combinations)
        
        # [NEW] n_cores ì²˜ë¦¬
        if n_cores is None:
            import multiprocessing
            n_cores = multiprocessing.cpu_count()
        
        print(f"ğŸ”¬ ìµœì í™” ì‹œì‘: {total}ê°œ ì¡°í•©, {n_cores}ì½”ì–´ ì‚¬ìš©")
        
        # ë³‘ë ¬ ì²˜ë¦¬ (n_cores workers)
        from concurrent.futures import ThreadPoolExecutor, as_completed
        
        def run_single_wrapper(combo):
            """ìŠ¤ë ˆë“œ ì•ˆì „í•œ ì‹¤í–‰ ë˜í¼"""
            if self.cancelled:
                return None
            params = dict(zip(keys, combo))
            try:
                return self._run_single(params, slippage, fee)
            except Exception as e:
                print(f"âš ï¸ ì¡°í•© {params} ì‹¤íŒ¨: {e}")
                return None
        
        with ThreadPoolExecutor(max_workers=n_cores) as executor:
            futures = {executor.submit(run_single_wrapper, combo): combo for combo in combinations}
            
            for i, future in enumerate(as_completed(futures)):
                if self.cancelled:
                    print("âŒ ìµœì í™” ì·¨ì†Œë¨")
                    executor.shutdown(wait=False, cancel_futures=True)
                    break
                
                result = future.result()
                if result:
                    self.results.append(result)
                
                # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
                if self.progress_callback:
                    progress = int((i + 1) / total * 100)
                    self.progress_callback(progress)
        
        # ê²°ê³¼ ì •ë ¬ ë° ìƒì„¸ ë¶„ë¥˜ (v2)
        if self.results:
            # 1. ì§€ì •ëœ ë©”íŠ¸ë¦­ìœ¼ë¡œ ì „ì²´ ì •ë ¬
            self.results.sort(key=lambda x: getattr(x, metric, 0), reverse=True)
            
            # 2. [NEW] ì¤‘ë³µ ì œê±° ë° ìœ í˜•ë³„ ëŒ€í‘œê°’ ì„ ì •
            # ë¨¼ì € ìœ ë‹ˆí¬í•œ ì„±ê²©ì˜ ìƒìœ„ ê²°ê³¼ë“¤ì„ ì¶”ì¶œ
            unique_results = self.filter_unique_results(self.results, max_count=100)
            
            # 3. [NEW] 5ê°€ì§€ ëŒ€í‘œ ìœ í˜• ë§¤ì¹­
            self.results = self._classify_results(unique_results)
            
            # ì •ë ¬ ë§ˆë¬´ë¦¬ (ìˆ˜ìµë¥  ìˆœ)
            self.results.sort(key=lambda x: x.total_return, reverse=True)

        # ë¦¬ìƒ˜í”Œë§ ìºì‹œ ì •ë¦¬ (ë©”ëª¨ë¦¬ í•´ì œ)
        self._resample_cache = {}
        
        print(f"âœ… ìµœì í™” ì™„ë£Œ: {len(self.results)}ê°œ ëŒ€í‘œ ê²°ê³¼ ë„ì¶œ")
        return self.results
    
    def _run_single(self, params: Dict, slippage: float, fee: float = 0.00055) -> Optional[OptimizationResult]:
        """ë‹¨ì¼ íŒŒë¼ë¯¸í„° ì¡°í•©ìœ¼ë¡œ ë°±í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        try:
            # íŒŒë¼ë¯¸í„° ì¶”ì¶œ (ë¦¬ìŠ¤íŠ¸ì¼ ê²½ìš° ë‹¨ì¼ ê°’ìœ¼ë¡œ ë³€í™˜)
            filter_tf = params.get('filter_tf', '4h')
            if isinstance(filter_tf, list): filter_tf = filter_tf[0]
            
            trend_tf = params.get('trend_interval', '1h')
            if isinstance(trend_tf, list): trend_tf = trend_tf[0]
            
            # Entry TF: paramsì— ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ TF_MAPPING
            entry_tf = params.get('entry_tf')
            if isinstance(entry_tf, list): entry_tf = entry_tf[0]
            if not entry_tf:
                entry_tf = TF_MAPPING.get(trend_tf, '15min')
            
            # [NEW] ë¦¬ìƒ˜í”Œë§ ìºì‹œ ì‚¬ìš© (ì„±ëŠ¥ ëŒ€í­ í–¥ìƒ)
            if not hasattr(self, '_resample_cache'): self._resample_cache = {}
            
            # df_pattern ìºì‹œ í‚¤
            p_key = f"p_{trend_tf}"
            if p_key not in self._resample_cache:
                self._resample_cache[p_key] = self._resample(self.df, trend_tf)
            df_pattern = self._resample_cache[p_key]
            
            # df_entry ìºì‹œ í‚¤
            e_key = f"e_{entry_tf}"
            if e_key not in self._resample_cache:
                if entry_tf and entry_tf not in ['15min', '15m']:
                    self._resample_cache[e_key] = self._resample(self.df, entry_tf)
                else:
                    self._resample_cache[e_key] = self.df.copy()
            df_entry = self._resample_cache[e_key]
            
            # ë°°ìœ¨/ë°©í–¥ ì²˜ë¦¬
            leverage = params.get('leverage', 3)
            if isinstance(leverage, list): leverage = leverage[0]
            leverage = int(leverage)
            
            direction = params.get('direction', 'Both')
            if isinstance(direction, list): direction = direction[0]
            
            # ì „ëµ ìƒì„± ì‹œ íŒŒë¼ë¯¸í„° ì „ë‹¬
            init_params = {}
            if 'trend_interval' in params:
               init_params['trend_interval'] = params['trend_interval']
            
            # ê³„ì‚°ëœ entry_intervalë„ ì „ë‹¬ (ì „ëµ ë‚´ë¶€ ë¦¬ìƒ˜í”Œë§ìš©)
            init_params['entry_interval'] = entry_tf
            
            # ì „ëµ ì¸ìŠ¤í„´ìŠ¤ ìƒì„± (Core)
            # strategy_classëŠ” AlphaX7Coreë¼ê³  ê°€ì • (ë˜ëŠ” í˜¸í™˜)
            # AlphaX7CoreëŠ” initì— dfë¥¼ ë°›ì§€ ì•ŠìŒ. stateless.
            try:
                strategy = self.strategy_class()
                # paramsì— 'rsi_period'ê°€ ìˆìœ¼ë©´ ì „ë‹¬í•´ì•¼ í•¨
            except Exception:
                # ë ˆê±°ì‹œ í˜¸í™˜ (í˜¹ì‹œ ë‹¤ë¥¸ ì „ëµì„ ì“¸ ê²½ìš°)
                strategy = self.strategy_class(df=df, **init_params)
                if hasattr(strategy, 'prepare_data'):
                    strategy.prepare_data()
            
            # âœ… ì´ ë¹„ìš© ê³„ì‚° (ìŠ¬ë¦¬í”¼ì§€ + ìˆ˜ìˆ˜ë£Œ)
            # AlphaX7CoreëŠ” 'slippage' ì¸ìë¥¼ ì°¨ê°í•  ë•Œ 2ë°°ë¥¼ ì ìš©í•˜ë¯€ë¡œ (pnl - slippage*2)
            # ì™•ë³µ ìˆ˜ìˆ˜ë£Œì™€ ìŠ¬ë¦¬í”¼ì§€ë¥¼ í•©ì‚°í•˜ì—¬ ì „ë‹¬í•˜ë©´ ë¨.
            # ì˜ˆ: ìŠ¬ë¦¬í”¼ì§€ 0.05%, ìˆ˜ìˆ˜ë£Œ 0.05% -> í•© 0.1% -> ë¡œì§ìƒ 2ë°°ì¸ 0.2%(ì™•ë³µ) ë¹„ìš© ì²˜ë¦¬
            total_cost = slippage + fee
            
            # ê¸°ë³¸ íŒŒë¼ë¯¸í„°ì™€ ë³‘í•© (DEFAULT_PARAMS ì°¸ì¡°)
            backtest_params = {
                'slippage': total_cost,  # ì´ ë¹„ìš© ì ìš©
                'atr_mult': params.get('atr_mult', DEFAULT_PARAMS.get('atr_mult', 1.5)),
                'trail_start_r': params.get('trail_start_r', DEFAULT_PARAMS.get('trail_start_r', 0.8)),
                'trail_dist_r': params.get('trail_dist_r', DEFAULT_PARAMS.get('trail_dist_r', 0.5)),
                'pattern_tolerance': params.get('pattern_tolerance', DEFAULT_PARAMS.get('pattern_tolerance', 0.03)),
                'entry_validity_hours': params.get('entry_validity_hours', DEFAULT_PARAMS.get('entry_validity_hours', 12.0)),
                'pullback_rsi_long': params.get('pullback_rsi_long', DEFAULT_PARAMS.get('pullback_rsi_long', 35)),
                'pullback_rsi_short': params.get('pullback_rsi_short', DEFAULT_PARAMS.get('pullback_rsi_short', 65)),
                'max_adds': params.get('max_adds', DEFAULT_PARAMS.get('max_adds', 1))
            }
            
            # ğŸ“Š ë””ë²„ê¹… ë¡œê·¸
            if params.get('trend_interval') == '1d' and params.get('atr_mult') == 1.5:
                print(f"ğŸ“Š [OPT] slippage={total_cost:.4f}, atr_mult={backtest_params['atr_mult']}, trail_start_r={backtest_params['trail_start_r']}, trail_dist_r={backtest_params['trail_dist_r']}")
            
            # ì „ëµ ì‹¤í–‰ ì‹œ ì „ë‹¬í•  íŒŒë¼ë¯¸í„°
            # X7PlusStrategy.run_backtest_plusì— filter_tf ì „ë‹¬
            backtest_params['filter_tf'] = filter_tf
            
            # ë°±í…ŒìŠ¤íŠ¸ ì‹¤í–‰ (Core Interface)
            if hasattr(strategy, 'run_backtest') and not hasattr(strategy, 'run_backtest_plus'):
                # AlphaX7Core
                trades = strategy.run_backtest(
                    df_pattern=df_pattern,
                    df_entry=df_entry,  # [FIX] ì›ë³¸ 15min ë°ì´í„° ì‚¬ìš©
                    slippage=total_cost,  # [FIX] ì´ ë¹„ìš© ì „ë‹¬
                    atr_mult=backtest_params.get('atr_mult'),
                    trail_start_r=backtest_params.get('trail_start_r'),
                    trail_dist_r=backtest_params.get('trail_dist_r'),
                    pattern_tolerance=backtest_params.get('pattern_tolerance'),
                    entry_validity_hours=backtest_params.get('entry_validity_hours'),
                    pullback_rsi_long=backtest_params.get('pullback_rsi_long'),
                    pullback_rsi_short=backtest_params.get('pullback_rsi_short'),
                    max_adds=backtest_params.get('max_adds'),
                    filter_tf=filter_tf,
                    rsi_period=params.get('rsi_period', DEFAULT_PARAMS.get('rsi_period', 14)),
                    atr_period=params.get('atr_period', DEFAULT_PARAMS.get('atr_period', 14)),
                    enable_pullback=params.get('enable_pullback', False)  # [NEW] ë¶ˆíƒ€ê¸° ì˜µì…˜
                )
            else:
                # Legacy Strategy
                backtest_params['filter_tf'] = filter_tf
                trades = strategy.run_backtest_plus(**backtest_params)
            
            # [DEBUG] ê±°ë˜ ìˆ˜ í™•ì¸
            # print(f"[DEBUG-OPT] ê±°ë˜ ìˆ˜: {len(trades) if trades else 0}ê°œ")
            
            if not trades or len(trades) < 3: # [FIX] 10ê°œëŠ” ë„ˆë¬´ ê°€í˜¹í•¨ (3ê°œë¡œ ì™„í™”)
                return None
            
            # 1. ë°©í–¥ í•„í„°ë§
            if direction != 'Both':
                trades = [t for t in trades if t['type'] == direction]
                if len(trades) < 3: return None
            
            # [FIX] Option 2: ë ˆë²„ë¦¬ì§€ ìë™ ìµœì í™” (MDD íƒ€ê²Ÿ ë§ì¶¤)
            # 2. ë ˆë²„ë¦¬ì§€ ì ìš© (ê·¸ë¦¬ë“œì— ì„¤ì •ëœ ì •ìˆ˜ ë°°ìœ¨ ì‚¬ìš©)
            max_mdd_limit = params.get('max_mdd', 20.0)
            if isinstance(max_mdd_limit, list): max_mdd_limit = max_mdd_limit[0]
            
            # ê·¸ë¦¬ë“œì—ì„œ ë„˜ì–´ì˜¨ ë ˆë²„ë¦¬ì§€ (í•­ìƒ ì •ìˆ˜ì—¬ì•¼ í•¨)
            grid_leverage = int(leverage)
            
            # ë ˆë²„ë¦¬ì§€ ì ìš© (PnL ìˆ˜ì •)
            for t in trades:
                t['pnl'] = t['pnl'] * grid_leverage
            
            # ë©”íŠ¸ë¦­ ê³„ì‚° (ë ˆë²„ë¦¬ì§€ ë°˜ì˜ë¨)
            metrics = self._calculate_metrics(trades)
            
            # [FIX] ë ˆë²„ë¦¬ì§€ ì ìš© í›„ MDDê°€ í•œë„ë¥¼ ì´ˆê³¼í•˜ë©´ íƒˆë½ (ì‚¬ìš©ì ìš”ì²­: 20% ì—„ê²© ì œí•œ)
            if abs(metrics['max_drawdown']) > max_mdd_limit:
                return None
            
            return OptimizationResult(
                params=params,
                trades=len(trades),
                win_rate=metrics['win_rate'],
                total_return=metrics['total_return'],
                max_drawdown=metrics['max_drawdown'],
                sharpe_ratio=metrics['sharpe_ratio'],
                profit_factor=metrics['profit_factor'],
                stability=metrics.get('stability', "âš ï¸")
            )
            
        except Exception as e:
            print(f"  âš ï¸ ë°±í…ŒìŠ¤íŠ¸ ì˜¤ë¥˜: {e}")
            return None
    
    def _calculate_metrics(self, trades: List[Dict]) -> Dict:
        """ê±°ë˜ ê²°ê³¼ì—ì„œ ë©”íŠ¸ë¦­ ê³„ì‚°"""
        pnls = [t.get('pnl', 0) for t in trades]
        pnl_series = pd.Series(pnls)
        
        # ê¸°ë³¸ ë©”íŠ¸ë¦­
        win_rate = (pnl_series > 0).mean() * 100
        simple_return = pnl_series.sum()
        
        # 1. ëˆ„ì  ìˆ˜ìµë¥  (Compound/Equity) ê³„ì‚°
        equity = 1.0
        cumulative_equity = []
        for p in pnls:
            # [FIX] íŒŒì‚°(Liquidation) ë°©ì–´: ìì‚°ì´ -100% ì´í•˜ë¡œ ë–¨ì–´ì§€ë©´ 0(íŒŒì‚°)ìœ¼ë¡œ ê°•ì œ
            equity *= (1 + p / 100)
            if equity <= 0:
                equity = 0
            
            cumulative_equity.append(equity)
            
            if equity == 0:
                break # íŒŒì‚°(Liquidation) í›„ì—ëŠ” ì‹œë®¬ë ˆì´ì…˜ ì¤‘ë‹¨
        
        # ìµœì¢… ë³µë¦¬ ìˆ˜ìµë¥ 
        compound_return = (equity - 1) * 100
        
        # 2. ìµœëŒ€ ë‚™í­ (MDD %) ê³„ì‚° - relative to peak equity
        peak = 1.0
        max_drawdown = 0
        for val in cumulative_equity:
            if val > peak:
                peak = val
            
            # peakê°€ 0ì¸ ê²½ìš°ëŠ” ì´ë¯¸ íŒŒì‚°í•œ ìƒíƒœ (ìœ„ ë£¨í”„ì—ì„œ ë¸Œë ˆì´í¬ ë˜ì§€ë§Œ ë°©ì–´ì  ì¶”ê°€)
            if peak > 1e-9:
                drawdown = (peak - val) / peak * 100
            else:
                drawdown = 100.0
                
            if drawdown > max_drawdown:
                max_drawdown = drawdown
        
        # MDD ìƒí•œì„  ê°•ì œ (ë ˆë²„ë¦¬ì§€ 5ë°° ë“±ì—ì„œ ì›ê¸ˆ ì´ˆê³¼ ì†ì‹¤ ë°œìƒ ì‹œ 100%ë¡œ ìº¡)
        max_drawdown = min(max_drawdown, 100.0)
        
        # MDDëŠ” ê´€ë¡€ìƒ ì–‘ìˆ˜ë¡œ ê´€ë¦¬í•˜ê±°ë‚˜ í‘œì‹œ ì‹œ -ë¥¼ ë¶™ì„ (ì—¬ê¸°ì„œëŠ” backtest_widgetê³¼ ë§ì¶¤)
        
        # 3. ìƒ¤í”„ ë¹„ìœ¨ (Sharpe Ratio, ì—°ê°„í™”)
        if pnl_series.std() > 0:
            sharpe_ratio = (pnl_series.mean() / pnl_series.std()) * np.sqrt(252 * 4)  # 15ë¶„ë´‰ ê¸°ì¤€ (í•˜ë£¨ 4ì„¸ì…˜ * 252ì¼)
        else:
            sharpe_ratio = 0
            
        # 4. Profit Factor
        gains = pnl_series[pnl_series > 0].sum()
        losses = abs(pnl_series[pnl_series < 0].sum())
        profit_factor = gains / losses if losses > 0 else float('inf')
        
        # 5. [NEW] 3êµ¬ê°„ ì•ˆì •ì„± ê³„ì‚°
        stability = self._calculate_stability(pnls)

        return {
            'win_rate': round(win_rate, 2),
            'total_return': round(simple_return, 2), # [MOD] ì˜¤ë²„í”Œë¡œìš° ë°©ì§€ë¥¼ ìœ„í•´ ë³µë¦¬ ëŒ€ì‹  ë‹¨ë¦¬(ë‹¨ìˆœ í•©ì‚°) ì‚¬ìš©
            'simple_return': round(simple_return, 2),
            'compound_return': round(compound_return, 2), # ì°¸ê³ ìš©ìœ¼ë¡œ ìœ ì§€
            'max_drawdown': round(max_drawdown, 2), # ì–‘ìˆ˜ê°’ (ì˜ˆ: 15.5%)
            'sharpe_ratio': round(sharpe_ratio, 2),
            'profit_factor': round(profit_factor, 2),
            'stability': stability
        }

    def _calculate_stability(self, pnls: List[float]) -> str:
        """3êµ¬ê°„ ì•ˆì •ì„± ì²´í¬ (ê³¼ê±°/ì¤‘ê°„/ìµœê·¼)"""
        n = len(pnls)
        if n < 3: # ìµœì†Œ ê±°ë˜ ìˆ˜ ë¯¸ë‹¬ ì‹œ
            return "âš ï¸"
        
        # êµ¬ê°„ ë¶„í• 
        p1 = sum(pnls[:n//3])
        p2 = sum(pnls[n//3:2*n//3])
        p3 = sum(pnls[2*n//3:])
        
        score = sum([p1 > 0, p2 > 0, p3 > 0])
        
        if score == 3: return "âœ…âœ…âœ…"
        if score == 2: return "âœ…âœ…âš "
        if score == 1: return "âœ…âš âš "
        return "âš âš âš "

    def _classify_results(self, results: List[OptimizationResult]) -> List[OptimizationResult]:
        """ê²°ê³¼ë¥¼ í´ëŸ¬ìŠ¤í„°ë§í•˜ì—¬ ìœ í˜•ë³„ ëŒ€í‘œê°’ ì„ ì • (v2 í•µì‹¬)"""
        if not results:
            return []
        
        # ê²°ê³¼ ë³µì‚¬ ë° ì •ë ¬ ê¸°ì¤€ë³„ í•„í„°ë§
        representatives = []
        seen_params = set()

        def add_rep(res, label):
            param_key = str(res.params)
            if param_key not in seen_params:
                res.strategy_type = label
                representatives.append(res)
                seen_params.add(param_key)

        # 1. ğŸ”¥ê³µê²©í˜•: ìµœê³  ìˆ˜ìµë¥  (MDD 20% ì´ë‚´ ì¤‘ ìµœê³ )
        aggressive = max(results, key=lambda x: x.total_return)
        add_rep(aggressive, "ğŸ”¥ê³µê²©")

        # 2. âš–ê· í˜•í˜•: ìµœê³  ìƒ¤í”„ ì§€ìˆ˜
        balanced = max(results, key=lambda x: x.sharpe_ratio)
        add_rep(balanced, "âš–ê· í˜•")

        # 3. ğŸ›¡ë³´ìˆ˜í˜•: ìµœì € MDD (ìˆ˜ìµì´ 0ë³´ë‹¤ í° ê²ƒ ì¤‘)
        profitable = [r for r in results if r.total_return > 0]
        if profitable:
            conservative = min(profitable, key=lambda x: abs(x.max_drawdown))
            add_rep(conservative, "ğŸ›¡ë³´ìˆ˜")

        # 4. ğŸ¯ê³ ìŠ¹ë¥ í˜•: ìµœê³  ìŠ¹ë¥ 
        high_wr = max(results, key=lambda x: x.win_rate)
        add_rep(high_wr, "ğŸ¯ê³ ìŠ¹ë¥ ")

        # 5. âš¡ê³ ë¹ˆë„í˜•: ìµœë‹¤ ê±°ë˜ íšŸìˆ˜
        high_freq = max(results, key=lambda x: x.trades)
        add_rep(high_freq, "âš¡ê³ ë¹ˆë„")

        return representatives
    
    def get_best(self, n: int = 10) -> List[OptimizationResult]:
        """ìƒìœ„ Nê°œ ê²°ê³¼ ë°˜í™˜"""
        return self.results[:n]
    
    def analyze_top_results(self, n: int = 100, threshold: float = 0.85) -> Dict:
        """
        ìƒìœ„ ê²°ê³¼ ë¶„ì„ â†’ ì§€ë°°ì  íŒŒë¼ë¯¸í„° ê³ ì • ë° ë²”ìœ„ ì¶•ì†Œ (Iterative Optimizationìš©)
        
        Args:
            n: ë¶„ì„í•  ìƒìœ„ ê²°ê³¼ ìˆ˜
            threshold: ê³ ì • íŒë‹¨ ì„ê³„ê°’ (ì˜ˆ: 0.85 -> 85% ì´ìƒ ê°™ì€ ê°’ì´ë©´ ê³ ì •)
            
        Returns:
            Dict: ì¶•ì†Œëœ íŒŒë¼ë¯¸í„° ê·¸ë¦¬ë“œ
        """
        if not self.results:
            return {}
            
        from collections import Counter
        top_results = sorted(self.results, key=lambda x: getattr(x, 'sharpe_ratio', 0), reverse=True)[:n]
        
        # ë¶„ì„ ëŒ€ìƒ íŒŒë¼ë¯¸í„° (ì§€í‘œ ê´€ë ¨)
        target_params = ['atr_mult', 'trail_start_r', 'trail_dist_r', 'pattern_tolerance', 'entry_validity_hours', 'filter_tf', 'entry_tf', 'leverage']
        
        fixed_params = {}
        reduced_ranges = {}
        
        for param in target_params:
            # í•´ë‹¹ íŒŒë¼ë¯¸í„° ê°’ ì¶”ì¶œ
            values = []
            for res in top_results:
                val = res.params.get(param)
                if val is not None:
                    if isinstance(val, list): val = val[0]
                    values.append(val)
            
            if not values: continue
            
            # ë¹ˆë„ ë¶„ì„
            counts = Counter(values)
            most_common_val, count = counts.most_common(1)[0]
            ratio = count / len(values)
            
            if ratio >= threshold:
                # ì§€ë°°ì ì¸ ê°’ ë°œê²¬ -> ê³ ì •
                fixed_params[param] = [most_common_val]
                print(f"ğŸ“Œ [OPT-ADAPT] '{param}' fixed to {most_common_val} (Dominance: {ratio:.1%})")
            else:
                # ë¶„í¬ ë¶„ì„ -> ë²”ìœ„ ì¶•ì†Œ (ìµœì†Œ~ìµœëŒ€ê°’ ì‚¬ì´ë¥¼ ë‹¤ì‹œ ì´˜ì´˜í•˜ê²Œ)
                min_v = min(values)
                max_v = max(values)
                
                # ê¸°ì¡´ INDICATOR_RANGEë‚˜ ì›ë³¸ ê·¸ë¦¬ë“œì—ì„œ í•´ë‹¹ êµ¬ê°„ì˜ ê°’ë“¤ ì¶”ì¶œ
                # ì—¬ê¸°ì„œëŠ” ê°„ë‹¨íˆ 5ë¶„í• í•˜ì—¬ ì´˜ì´˜í•˜ê²Œ ìƒì„±
                if isinstance(min_v, (int, float)) and not isinstance(min_v, bool):
                     # ìˆ˜ì¹˜í˜• íŒŒë¼ë¯¸í„°
                     step = (max_v - min_v) / 5
                     if step > 0:
                         new_vals = [round(min_v + step * i, 3) for i in range(6)]
                         reduced_ranges[param] = sorted(list(set(new_vals)))
                     else:
                         reduced_ranges[param] = [min_v]
                else:
                    # ì¹´í…Œê³ ë¦¬í˜• (filter_tf ë“±)
                    reduced_ranges[param] = sorted(list(set(values)))
                
                print(f"ğŸ” [OPT-ADAPT] '{param}' range narrowed: {min_v} ~ {max_v}")

        # ìƒˆë¡œìš´ ê·¸ë¦¬ë“œ ìƒì„±
        new_grid = {}
        # 1. ê³ ì •ëœ ê°’ ì ìš©
        new_grid.update(fixed_params)
        # 2. ì¶•ì†Œëœ ë²”ìœ„ ì ìš©
        new_grid.update(reduced_ranges)
        
        # 3. ê³µí†µ í•„ë“œ ìœ ì§€ (trend_interval, max_mdd ë“±)
        if self.results:
            first_params = self.results[0].params
            for k in ['trend_interval', 'max_mdd', 'direction']:
                if k not in new_grid and k in first_params:
                    val = first_params[k]
                    new_grid[k] = val if isinstance(val, list) else [val]
        
        return new_grid

    def filter_unique_results(self, results: List[OptimizationResult] = None, 
                              max_count: int = 30) -> List[OptimizationResult]:
        """
        ì¤‘ë³µ/ìœ ì‚¬ ê²°ê³¼ ì œê±° + ìƒìœ„ Nê°œ ì„ íƒ
        
        ê¸°ì¤€:
        - ìŠ¹ë¥  1% ì´ë‚´ + MDD 2% ì´ë‚´ = ìœ ì‚¬ ê²°ê³¼
        - ìœ ì‚¬ ê·¸ë£¹ ë‚´ â†’ ë³µí•© ìŠ¤ì½”ì–´ ë†’ì€ 1ê°œë§Œ
        - ìµœì¢… max_countê°œ ë°˜í™˜
        """
        if results is None:
            results = self.results
        
        if not results:
            return []
        
        # ë³µí•© ìŠ¤ì½”ì–´ ê³„ì‚° (ìŠ¹ë¥  > MDD > ìƒ¤í”„ > ìˆ˜ìµë¥ )
        def calc_score(r):
            return (
                r.win_rate * 1.0 +                    # ìŠ¹ë¥  88% â†’ 88ì 
                (100 + r.max_drawdown) * 0.5 +        # MDD -17% â†’ 41.5ì 
                r.sharpe_ratio * 2.0 +                # ìƒ¤í”„ 26 â†’ 52ì 
                min(r.total_return / 100, 50) * 0.2   # ìˆ˜ìµë¥  cap 50
            )
        
        # ìŠ¤ì½”ì–´ ìˆœ ì •ë ¬
        scored = sorted(results, key=calc_score, reverse=True)
        
        # ìœ ì‚¬ ê²°ê³¼ ì œê±°
        unique = []
        for r in scored:
            is_duplicate = False
            for u in unique:
                # MDDëŠ” ë³´í†µ ìŒìˆ˜ì´ë¯€ë¡œ abs()ë¡œ ì°¨ì´ í™•ì¸
                if (abs(r.win_rate - u.win_rate) < 1.0 and
                    abs(r.max_drawdown - u.max_drawdown) < 2.0):
                    is_duplicate = True
                    break
            
            if not is_duplicate:
                unique.append(r)
            
            if len(unique) >= max_count:
                break
        
        print(f"ğŸ”„ [FILTER] {len(results)} â†’ {len(unique)} (ì¤‘ë³µ ì œê±°)")
        return unique

    def to_dataframe(self) -> pd.DataFrame:
        """ê²°ê³¼ë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜"""
        if not self.results:
            return pd.DataFrame()
        
        rows = []
        for r in self.results:
            row = {**r.params}
            row['trades'] = r.trades
            row['win_rate'] = r.win_rate
            row['total_return'] = r.total_return
            row['max_drawdown'] = r.max_drawdown
            row['sharpe_ratio'] = r.sharpe_ratio
            row['profit_factor'] = r.profit_factor
            rows.append(row)
        
        return pd.DataFrame(rows)


# í…ŒìŠ¤íŠ¸
if __name__ == "__main__":
    import os
    import sys
    import pandas as pd
    import traceback
    
    try:
        # 1. ê²½ë¡œ ì„¤ì •
        BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
        if BASE_DIR not in sys.path:
            sys.path.append(BASE_DIR)
        
        from core.strategy_core import AlphaX7Core
        
        # ë°ì´í„° ë¡œë“œ (Parquet ìš°ì„  íƒìƒ‰)
        csv_path = os.path.join(BASE_DIR, 'data', 'cache', 'bybit_btcusdt_15m.parquet')
        if not os.path.exists(csv_path):
            csv_path = os.path.join(BASE_DIR, 'data', 'bybit_BTCUSDT_15m.csv') # Fallback
            
        print(f"ğŸ“Š Testing with: {csv_path}")
        
        if os.path.exists(csv_path):
            if csv_path.endswith('.parquet'):
                df = pd.read_parquet(csv_path)
            else:
                df = pd.read_csv(csv_path)
                
            # íƒ€ì„ìŠ¤íƒ¬í”„ ë³€í™˜
            if 'timestamp' in df.columns and not pd.api.types.is_datetime64_any_dtype(df['timestamp']):
                first_ts = df['timestamp'].iloc[0]
                val = float(first_ts)
                if val > 1e12:
                    df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')
                elif val > 1e8:
                    df['timestamp'] = pd.to_datetime(df['timestamp'], unit='s')
                else:
                    df['timestamp'] = pd.to_datetime(df['timestamp'])
            
            # ìµœê·¼ 5000ê°œë§Œ ì‚¬ìš© (í…ŒìŠ¤íŠ¸ìš©)
            df = df.tail(5000).reset_index(drop=True)
            print(f"Loaded {len(df)} candles. Range: {df['timestamp'].iloc[0]} ~ {df['timestamp'].iloc[-1]}")
            
            # 1. ìµœì í™” ì—”ì§„ ì‹œì‘
            optimizer = BacktestOptimizer(AlphaX7Core, df)
            grid = generate_fast_grid('1h')
            
            print(f"ğŸš€ [Stage 1] Fast Grid Search Starting...")
            results = optimizer.optimize(grid, metric='sharpe_ratio')
            print(f"âœ… Found {len(results)} combinations.")
            
            # 2. ë¶„ì„ ë° ë²”ìœ„ ì¶•ì†Œ (ì‹ ê·œ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸)
            refined_grid = optimizer.analyze_top_results(n=10, threshold=0.7)
            
            # 3. 2ë‹¨ê³„ ì •ë°€ ìµœì í™”
            if refined_grid:
                print(f"âœ¨ [Analysis] Refined Grid calculated: {refined_grid}")
                print(f"ğŸš€ [Stage 2] Iterative Scan Starting...")
                refined_results = optimizer.optimize(refined_grid, metric='sharpe_ratio')
                print(f"ğŸ† Final Best Results: {len(refined_results)}")
                
                for res in refined_results[:5]:
                    print(f" - {res.params}: Sharpe={res.sharpe_ratio:.2f}, WR={res.win_rate:.1f}%")
            else:
                print("âœ¨ [Analysis] No dominant patterns found to refine.")
        else:
            print(f"âŒ No test data found at {csv_path}. Please download data first.")
            
    except Exception:
        print("âŒ Test failed with error:")
        traceback.print_exc()
