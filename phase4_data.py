from pathlib import Path
import re

base = Path(r'C:\ë§¤ë§¤ì „ëµ')

print('=' * 70)
print('ğŸ’¾ Phase 4: ë°ì´í„° ì²˜ë¦¬ ì ê²€')
print('=' * 70)

#############################################
# [1] ë°ì´í„° ê´€ë ¨ íŒŒì¼ êµ¬ì¡°
#############################################
print('\nğŸ“ [1] ë°ì´í„° ê´€ë ¨ íŒŒì¼')
print('-' * 70)

data_files = {
    'utils/data_manager.py': 'ë°ì´í„° ë§¤ë‹ˆì €',
    'storage/trade_storage.py': 'ê±°ë˜ ì €ì¥ì†Œ (JSON)',
    'storage/trade_history.py': 'ê±°ë˜ ê¸°ë¡ (SQLite)',
    'core/unified_bot.py': 'ë´‡ ì—”ì§„ (Parquet)',
    'exchanges/ws_handler.py': 'ì›¹ì†Œì¼“ í•¸ë“¤ëŸ¬',
}

for fpath, desc in data_files.items():
    f = base / fpath
    if f.exists():
        try:
            lines = len(f.read_text(encoding='utf-8', errors='ignore').split('\n'))
            print(f'  âœ… {fpath} ({desc}) - {lines:,}ì¤„')
        except:
            print(f'  âœ… {fpath} ({desc})')
    else:
        print(f'  âŒ {fpath} ({desc}) - ì—†ìŒ')

#############################################
# [2] Parquet ì €ì¥/ë¡œë“œ
#############################################
print('\nğŸ“Š [2] Parquet ì €ì¥/ë¡œë“œ')
print('-' * 70)

parquet_features = {
    'pd.read_parquet': 'ë¡œë“œ',
    'to_parquet': 'ì €ì¥',
    'pyarrow': 'ì—”ì§„',
    'timestamp.*int64|int64.*timestamp': 'íƒ€ì„ìŠ¤íƒ¬í”„ ì •ê·œí™”',
    'backfill|ë°±í•„': 'ë°±í•„ë§',
}

for f in base.rglob('*.py'):
    if '__pycache__' in str(f):
        continue
    try:
        code = f.read_text(encoding='utf-8', errors='ignore')
        found = []
        for feat, desc in parquet_features.items():
            if re.search(feat, code, re.I):
                found.append(desc)
        if found and 'parquet' in code.lower():
            print(f'  {f.relative_to(base)}: {", ".join(set(found))}')
    except:
        pass

#############################################
# [3] ìº”ë“¤ ë°ì´í„° ì²˜ë¦¬
#############################################
print('\nğŸ•¯ï¸ [3] ìº”ë“¤ ë°ì´í„° ì²˜ë¦¬')
print('-' * 70)

bot_file = base / 'core' / 'unified_bot.py'
if bot_file.exists():
    code = bot_file.read_text(encoding='utf-8', errors='ignore')
    
    candle_features = {
        '_process_new_candle': 'ìº”ë“¤ ì²˜ë¦¬ í•¨ìˆ˜',
        '_on_candle_close': 'ìº”ë“¤ ë§ˆê° í•¸ë“¤ëŸ¬',
        'df_entry': 'Entry ë°ì´í„°í”„ë ˆì„',
        'df_pattern': 'Pattern ë°ì´í„°í”„ë ˆì„',
        '_save_to_parquet': 'Parquet ì €ì¥',
        'backfill': 'ë°±í•„ë§',
    }
    
    for pattern, desc in candle_features.items():
        if pattern in code:
            # ë¼ì¸ ë²ˆí˜¸ ì°¾ê¸°
            lines = code.split('\n')
            for i, line in enumerate(lines):
                if pattern in line and ('def ' in line or '=' in line):
                    print(f'  âœ… {desc}: L{i+1}')
                    break
            else:
                print(f'  âœ… {desc}: ì¡´ì¬')
        else:
            print(f'  âŒ {desc}: ì—†ìŒ')

#############################################
# [4] ê±°ë˜ ì €ì¥ì†Œ (JSON + SQLite)
#############################################
print('\nğŸ’° [4] ê±°ë˜ ì €ì¥ì†Œ')
print('-' * 70)

# JSON Storage
json_storage = base / 'storage' / 'trade_storage.py'
if json_storage.exists():
    code = json_storage.read_text(encoding='utf-8', errors='ignore')
    json_features = ['add_trade', 'get_trades', 'save', 'load', 'json']
    found = [f for f in json_features if f in code.lower()]
    print(f'  JSON Storage: {", ".join(found)}')

# SQLite Storage
sqlite_storage = base / 'storage' / 'trade_history.py'
if sqlite_storage.exists():
    code = sqlite_storage.read_text(encoding='utf-8', errors='ignore')
    sqlite_features = ['sqlite', 'INSERT', 'SELECT', 'CREATE TABLE', 'connect']
    found = [f for f in sqlite_features if f in code]
    print(f'  SQLite Storage: {", ".join(found)}')

#############################################
# [5] ì‹œê°„ ë™ê¸°í™”
#############################################
print('\nâ° [5] ì‹œê°„ ë™ê¸°í™”')
print('-' * 70)

time_features = {
    'sync_time|time.*sync': 'ì‹œê°„ ë™ê¸°í™” í•¨ìˆ˜',
    'offset': 'ì˜¤í”„ì…‹ ì ìš©',
    'fetchTime|get_server_time': 'ì„œë²„ ì‹œê°„ ì¡°íšŒ',
    'latency': 'ë ˆì´í„´ì‹œ ê³„ì‚°',
}

for f in [base / 'core' / 'unified_bot.py', base / 'exchanges' / 'ws_handler.py']:
    if f.exists():
        code = f.read_text(encoding='utf-8', errors='ignore')
        found = []
        for pattern, desc in time_features.items():
            if re.search(pattern, code, re.I):
                found.append(desc)
        if found:
            print(f'  {f.name}: {", ".join(found)}')

#############################################
# [6] ì›¹ì†Œì¼“ ë°ì´í„° íë¦„
#############################################
print('\nğŸ”Œ [6] ì›¹ì†Œì¼“ ë°ì´í„° íë¦„')
print('-' * 70)

ws_file = base / 'exchanges' / 'ws_handler.py'
if ws_file.exists():
    code = ws_file.read_text(encoding='utf-8', errors='ignore')
    
    ws_features = {
        'connect': 'ì—°ê²°',
        'on_message': 'ë©”ì‹œì§€ ìˆ˜ì‹ ',
        'on_close': 'ì—°ê²° ì¢…ë£Œ',
        'reconnect': 'ì¬ì—°ê²°',
        'ping|pong': 'í•‘í',
        'subscribe': 'êµ¬ë…',
        'kline|candle': 'ìº”ë“¤ ìŠ¤íŠ¸ë¦¼',
    }
    
    for pattern, desc in ws_features.items():
        if re.search(pattern, code, re.I):
            print(f'  âœ… {desc}')
        else:
            print(f'  âŒ {desc}')

#############################################
# [7] ë°ì´í„° ë¬´ê²°ì„± ì²´í¬
#############################################
print('\nğŸ”’ [7] ë°ì´í„° ë¬´ê²°ì„±')
print('-' * 70)

integrity_patterns = {
    'duplicate': 'ì¤‘ë³µ ì œê±°',
    'dropna|fillna': 'NaN ì²˜ë¦¬',
    'sort_values|sort_index': 'ì •ë ¬',
    'reset_index': 'ì¸ë±ìŠ¤ ë¦¬ì…‹',
    'astype.*int64': 'íƒ€ì… ë³€í™˜',
}

bot_file = base / 'core' / 'unified_bot.py'
if bot_file.exists():
    code = bot_file.read_text(encoding='utf-8', errors='ignore')
    for pattern, desc in integrity_patterns.items():
        if re.search(pattern, code, re.I):
            print(f'  âœ… {desc}')
        else:
            print(f'  âš ï¸ {desc}: í™•ì¸ í•„ìš”')

print('\n' + '=' * 70)
