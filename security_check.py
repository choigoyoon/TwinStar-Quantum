from pathlib import Path
import json
import re

base = Path(r'C:\ë§¤ë§¤ì „ëµ')

print('=' * 70)
print('ğŸ”’ ë¹Œë“œ ì‹œ ë¯¼ê° ì •ë³´ ìœ ì¶œ ì ê²€')
print('=' * 70)

issues = []

#############################################
# [1] spec íŒŒì¼ì—ì„œ í¬í•¨ë˜ëŠ” ë°ì´í„° í™•ì¸
#############################################
print('\nğŸ“Œ [1] spec íŒŒì¼ ë¶„ì„')

spec_file = base / 'staru_clean.spec'
if spec_file.exists():
    code = spec_file.read_text(encoding='utf-8', errors='ignore')
    
    # datas í•­ëª© ì°¾ê¸°
    print('\n  [í¬í•¨ë˜ëŠ” ë°ì´í„° (datas)]:')
    datas_match = re.search(r'datas\s*=\s*\[(.*?)\]', code, re.DOTALL)
    if datas_match:
        datas = datas_match.group(1)
        print(f'    {datas[:200]}...')
        
        # ìœ„í—˜ íŒ¨í„´
        dangerous = ['config', 'key', 'secret', 'api', 'credential', 'token'] # removed .json to avoid too many false positives if needed, but original had it
        for d in dangerous:
            if d.lower() in datas.lower():
                issues.append(f'spec datasì— {d} í¬í•¨ ê°€ëŠ¥ì„±')
                print(f'    âš ï¸ {d} ë°œê²¬!')

#############################################
# [2] JSON ì„¤ì • íŒŒì¼ ë‚´ API í‚¤ í™•ì¸
#############################################
print('\nğŸ“Œ [2] JSON íŒŒì¼ ë‚´ ë¯¼ê° ì •ë³´')

sensitive_keys = ['api_key', 'secret', 'password', 'token', 'key', 'credential', 'api-key', 'secret-key']

for f in base.rglob('*.json'):
    if '__pycache__' in str(f) or '.venv' in str(f) or 'node_modules' in str(f):
        continue
    try:
        data = json.loads(f.read_text(encoding='utf-8'))
        fname = f.relative_to(base).as_posix()
        
        def check_dict(d, path=''):
            found = []
            if isinstance(d, dict):
                for k, v in d.items():
                    full_path = f'{path}.{k}' if path else k
                    if any(s in k.lower() for s in sensitive_keys):
                        # Filter out common non-sensitive keys that might match
                        non_sensitive = ['key_type', 'keyboard', 'key_range']
                        if not any(ns in k.lower() for ns in non_sensitive):
                            if v and str(v) != '' and str(v) != 'None' and len(str(v)) > 5:
                                found.append((full_path, str(v)[:20]))
                    if isinstance(v, dict):
                        found.extend(check_dict(v, full_path))
            elif isinstance(d, list):
                for i, item in enumerate(d):
                    found.extend(check_dict(item, f'{path}[{i}]'))
            return found
        
        sensitive = check_dict(data)
        if sensitive:
            print(f'\n  âš ï¸ {fname}:')
            for path, val in sensitive:
                print(f'    {path}: {val}...')
                issues.append(f'{fname} ë‚´ {path}')
    except:
        pass

#############################################
# [3] Python ì½”ë“œ ë‚´ í•˜ë“œì½”ë”©ëœ í‚¤
#############################################
print('\nğŸ“Œ [3] ì½”ë“œ ë‚´ í•˜ë“œì½”ë”©ëœ í‚¤')

api_patterns = [
    r'(?<!_)api_key\s*=\s*["\'][^"\']{15,}["\']',
    r'(?<!_)secret\s*=\s*["\'][^"\']{15,}["\']',
    r'(?<!_)password\s*=\s*["\'][^"\']{8,}["\']',
]

for f in base.rglob('*.py'):
    if '__pycache__' in str(f) or '.venv' in str(f) or 'node_modules' in str(f):
        continue
    try:
        code = f.read_text(encoding='utf-8', errors='ignore')
        fname = f.relative_to(base).as_posix()
        
        for pattern in api_patterns:
            matches = re.findall(pattern, code, re.I)
            if matches:
                # Exclude common test or example code patterns
                clean_matches = [m for m in matches if 'example' not in m.lower() and 'your_' not in m.lower()]
                if clean_matches:
                    print(f'  âš ï¸ {fname}: {clean_matches[0][:50]}...')
                    issues.append(f'{fname} í•˜ë“œì½”ë”© í‚¤')
    except:
        pass

#############################################
# [4] ë¹Œë“œ ì œì™¸ ê¶Œì¥ íŒŒì¼/í´ë”
#############################################
print('\nğŸ“Œ [4] ë¹Œë“œ ì œì™¸ ê¶Œì¥ ëª©ë¡')

exclude_recommend = [
    'config/api_keys.json',
    'config/credentials.json',
    'data/cache/*.parquet',
    '*.log',
    '__pycache__',
    '.env',
    'secrets/',
]

print('  ë¹Œë“œ ì‹œ ì œì™¸í•´ì•¼ í•  í•­ëª©:')
for item in exclude_recommend:
    print(f'    - {item}')

#############################################
# [5] ìš”ì•½
#############################################
print('\n' + '=' * 70)
print('ğŸ“‹ ìš”ì•½')
print('=' * 70)

if issues:
    print(f'\nğŸ”´ ë°œê²¬ëœ ë¬¸ì œ: {len(issues)}ê°œ')
    # Filter unique file-based issues for summary to avoid overwhelming output
    unique_files = sorted(list(set([i.split(' ')[0] for i in issues])))
    for f in unique_files:
        print(f'  - {f}')
    print('\nâš ï¸ ë¹Œë“œ ì „ ìœ„ íŒŒì¼ë“¤ì˜ ë¯¼ê° ì •ë³´ ì œê±° í•„ìš”!')
else:
    print('\nâœ… ë¯¼ê° ì •ë³´ ìœ ì¶œ ìœ„í—˜ ì—†ìŒ')
