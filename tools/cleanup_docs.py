#!/usr/bin/env python3
"""
ë¬¸ì„œ ë° í…ŒìŠ¤íŠ¸ ìë™ ì •ë¦¬ ë„êµ¬

ê¸°ëŠ¥:
1. 30ì¼ ì´ìƒ ë¯¸ìˆ˜ì • íŒŒì¼ ê°ì§€
2. ì¤‘ë³µ íŒŒì¼ íƒì§€ (í•´ì‹œ ê¸°ë°˜)
3. ì½”ë“œ ì°¸ì¡° ì²´í¬ (grep ê¸°ë°˜)
4. í…ŒìŠ¤íŠ¸ íŒŒì¼ import ê²€ì¦
5. ì •ë¦¬ ë¦¬í¬íŠ¸ ìƒì„±

ì‚¬ìš©ë²•:
    python tools/cleanup_docs.py --scan           # ìŠ¤ìº”ë§Œ (ì‚­ì œ ì•ˆ í•¨)
    python tools/cleanup_docs.py --clean          # ìë™ ì •ë¦¬ ì‹¤í–‰
    python tools/cleanup_docs.py --archive        # ì•„ì¹´ì´ë¸Œ ìƒì„±
"""

import os
import sys
import hashlib
import subprocess
from pathlib import Path
from datetime import datetime, timedelta
from typing import List, Dict, Set
import json

# í”„ë¡œì íŠ¸ ë£¨íŠ¸
ROOT = Path(__file__).parent.parent

# ì •ë¦¬ ëŒ€ìƒ ë””ë ‰í† ë¦¬
SCAN_DIRS = [
    ROOT / "docs",
    ROOT / "tests",
]

# ë³´í˜¸ íŒŒì¼ (ì ˆëŒ€ ì‚­ì œ ê¸ˆì§€)
PROTECTED_FILES = {
    "CLAUDE.md",
    "README.md",
    "CHANGELOG.md",
    "LICENSE.txt",
    "requirements.txt",
    "pyrightconfig.json",
    ".gitignore",
}

# ë³´í˜¸ íŒ¨í„´ (ê²½ë¡œ ê¸°ì¤€)
PROTECTED_PATTERNS = [
    "docs/WORK_LOG_*.txt",  # ìµœê·¼ 7ì¼ ì‘ì—… ë¡œê·¸
    "docs/PROJECT_FULL_ARCHITECTURE.md",
    "docs/GUI_LAYOUT_ANALYSIS.md",
    "docs/DATA_FLOW_COMPREHENSIVE_ANALYSIS.md",
    "tests/test_*.py",  # ëª¨ë“  í…ŒìŠ¤íŠ¸ íŒŒì¼
]

# ì¦‰ì‹œ ì‚­ì œ íŒ¨í„´
DELETE_PATTERNS = [
    "**/tmpclaude-*.cwd",
    "**/*.pyc",
    "**/__pycache__",
    "**/output.txt",
    "**/all_out.txt",
    "**/compile_error.txt",
    "**/temp_*.txt",
]

# ì•„ì¹´ì´ë¸Œ ëŒ€ìƒ íŒ¨í„´
ARCHIVE_PATTERNS = [
    "docs/WORK_LOG_*_Session*.txt",  # ì„¸ì…˜ ë¡œê·¸
    "docs/*_report_*.txt",  # ê²€ì¦ ë¦¬í¬íŠ¸
    "docs/CRITICAL_FIXES_*.md",  # ì™„ë£Œëœ ì‘ì—…
]


class FileInfo:
    """íŒŒì¼ ì •ë³´"""
    def __init__(self, path: Path):
        self.path = path
        self.name = path.name
        self.size = path.stat().st_size if path.exists() else 0
        self.mtime = datetime.fromtimestamp(path.stat().st_mtime) if path.exists() else None
        self.hash = self._calculate_hash() if path.exists() else None

    def _calculate_hash(self) -> str:
        """íŒŒì¼ í•´ì‹œ ê³„ì‚° (MD5)"""
        try:
            with open(self.path, 'rb') as f:
                return hashlib.md5(f.read()).hexdigest()
        except:
            return ""

    def is_old(self, days: int = 30) -> bool:
        """ì§€ì • ì¼ìˆ˜ ì´ìƒ ë¯¸ìˆ˜ì • íŒŒì¼ì¸ì§€ í™•ì¸"""
        if not self.mtime:
            return False
        return datetime.now() - self.mtime > timedelta(days=days)

    def is_protected(self) -> bool:
        """ë³´í˜¸ ëŒ€ìƒ íŒŒì¼ì¸ì§€ í™•ì¸"""
        # ì ˆëŒ€ ë³´í˜¸ íŒŒì¼
        if self.name in PROTECTED_FILES:
            return True

        # íŒ¨í„´ ê¸°ë°˜ ë³´í˜¸
        rel_path = self.path.relative_to(ROOT)
        for pattern in PROTECTED_PATTERNS:
            if rel_path.match(pattern):
                return True

        return False

    def should_delete(self) -> bool:
        """ì¦‰ì‹œ ì‚­ì œ ëŒ€ìƒì¸ì§€ í™•ì¸"""
        rel_path = self.path.relative_to(ROOT)
        for pattern in DELETE_PATTERNS:
            if rel_path.match(pattern):
                return True
        return False

    def should_archive(self) -> bool:
        """ì•„ì¹´ì´ë¸Œ ëŒ€ìƒì¸ì§€ í™•ì¸"""
        rel_path = self.path.relative_to(ROOT)
        for pattern in ARCHIVE_PATTERNS:
            if rel_path.match(pattern):
                return True
        return False


class CleanupAnalyzer:
    """ì •ë¦¬ ë¶„ì„ê¸°"""

    def __init__(self):
        self.files: List[FileInfo] = []
        self.duplicates: Dict[str, List[FileInfo]] = {}
        self.orphaned: List[FileInfo] = []
        self.to_delete: List[FileInfo] = []
        self.to_archive: List[FileInfo] = []

    def scan(self):
        """íŒŒì¼ ìŠ¤ìº”"""
        print("ğŸ” Scanning files...")

        for scan_dir in SCAN_DIRS:
            if not scan_dir.exists():
                continue

            for file_path in scan_dir.rglob("*"):
                if file_path.is_file():
                    info = FileInfo(file_path)
                    self.files.append(info)

                    # ì¤‘ë³µ ì²´í¬
                    if info.hash:
                        if info.hash not in self.duplicates:
                            self.duplicates[info.hash] = []
                        self.duplicates[info.hash].append(info)

        print(f"âœ“ Found {len(self.files)} files")

    def analyze(self):
        """íŒŒì¼ ë¶„ì„"""
        print("\nğŸ“Š Analyzing files...")

        for info in self.files:
            # ë³´í˜¸ íŒŒì¼ ìŠ¤í‚µ
            if info.is_protected():
                continue

            # ì¦‰ì‹œ ì‚­ì œ ëŒ€ìƒ
            if info.should_delete():
                self.to_delete.append(info)

            # ì•„ì¹´ì´ë¸Œ ëŒ€ìƒ
            elif info.should_archive():
                self.to_archive.append(info)

            # 30ì¼ ì´ìƒ ë¯¸ìˆ˜ì • íŒŒì¼
            elif info.is_old(30):
                # ì½”ë“œ ì°¸ì¡° ì²´í¬
                if not self._has_code_reference(info):
                    self.to_archive.append(info)

        # ì¤‘ë³µ íŒŒì¼ í•„í„°ë§ (2ê°œ ì´ìƒ)
        for hash_val, files in self.duplicates.items():
            if len(files) > 1:
                # ê°€ì¥ ìµœê·¼ íŒŒì¼ ì œì™¸í•˜ê³  ë‚˜ë¨¸ì§€ ì‚­ì œ ëŒ€ìƒ
                files_sorted = sorted(files, key=lambda f: f.mtime or datetime.min, reverse=True)
                for duplicate in files_sorted[1:]:
                    if not duplicate.is_protected():
                        self.to_delete.append(duplicate)

        print(f"âœ“ Delete candidates: {len(self.to_delete)}")
        print(f"âœ“ Archive candidates: {len(self.to_archive)}")

    def _has_code_reference(self, info: FileInfo) -> bool:
        """ì½”ë“œì—ì„œ ì°¸ì¡°ë˜ëŠ”ì§€ í™•ì¸ (grep ê¸°ë°˜)"""
        try:
            # Python íŒŒì¼ì—ì„œ íŒŒì¼ëª… ê²€ìƒ‰
            result = subprocess.run(
                ["grep", "-r", "--include=*.py", info.name, str(ROOT)],
                capture_output=True,
                text=True,
                timeout=5
            )
            return result.returncode == 0
        except:
            return False

    def generate_report(self) -> str:
        """ì •ë¦¬ ë¦¬í¬íŠ¸ ìƒì„±"""
        report = []
        report.append("=" * 80)
        report.append("ğŸ“‹ CLEANUP REPORT")
        report.append(f"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        report.append("=" * 80)
        report.append("")

        # ìš”ì•½
        report.append("## Summary")
        report.append(f"Total files scanned: {len(self.files)}")
        report.append(f"Delete candidates: {len(self.to_delete)}")
        report.append(f"Archive candidates: {len(self.to_archive)}")
        report.append(f"Duplicate groups: {sum(1 for files in self.duplicates.values() if len(files) > 1)}")
        report.append("")

        # ì‚­ì œ ëŒ€ìƒ
        if self.to_delete:
            report.append("## Delete Candidates")
            report.append("")
            total_size = sum(f.size for f in self.to_delete)
            report.append(f"Total size: {total_size / 1024:.1f} KB")
            report.append("")

            for info in sorted(self.to_delete, key=lambda f: f.size, reverse=True):
                rel_path = info.path.relative_to(ROOT)
                report.append(f"- {rel_path} ({info.size / 1024:.1f} KB)")

        report.append("")

        # ì•„ì¹´ì´ë¸Œ ëŒ€ìƒ
        if self.to_archive:
            report.append("## Archive Candidates")
            report.append("")
            total_size = sum(f.size for f in self.to_archive)
            report.append(f"Total size: {total_size / 1024:.1f} KB")
            report.append("")

            for info in sorted(self.to_archive, key=lambda f: f.size, reverse=True):
                rel_path = info.path.relative_to(ROOT)
                days_old = (datetime.now() - info.mtime).days if info.mtime else 0
                report.append(f"- {rel_path} ({info.size / 1024:.1f} KB, {days_old} days old)")

        report.append("")
        report.append("=" * 80)

        return "\n".join(report)

    def execute_cleanup(self, dry_run: bool = True):
        """ì •ë¦¬ ì‹¤í–‰"""
        if dry_run:
            print("\nğŸ” DRY RUN MODE (no files will be deleted)")
        else:
            print("\nğŸ—‘ï¸  EXECUTING CLEANUP")

        # ì‚­ì œ ì‹¤í–‰
        deleted_count = 0
        for info in self.to_delete:
            rel_path = info.path.relative_to(ROOT)
            if dry_run:
                print(f"Would delete: {rel_path}")
            else:
                try:
                    info.path.unlink()
                    deleted_count += 1
                    print(f"âœ“ Deleted: {rel_path}")
                except Exception as e:
                    print(f"âœ— Failed to delete {rel_path}: {e}")

        # ì•„ì¹´ì´ë¸Œ ì‹¤í–‰
        archived_count = 0
        archive_root = ROOT / "docs" / "archive"

        for info in self.to_archive:
            rel_path = info.path.relative_to(ROOT)

            # ì•„ì¹´ì´ë¸Œ ê²½ë¡œ ê²°ì •
            if "work_logs" in str(rel_path) or "Session" in info.name:
                archive_dir = archive_root / "work_logs"
            elif "report" in info.name.lower():
                archive_dir = archive_root / "validation"
            elif "CRITICAL" in info.name or "FIX" in info.name:
                archive_dir = archive_root / "completed_work"
            else:
                archive_dir = archive_root / "misc"

            if dry_run:
                print(f"Would archive: {rel_path} â†’ {archive_dir}")
            else:
                try:
                    archive_dir.mkdir(parents=True, exist_ok=True)
                    dest = archive_dir / info.name
                    info.path.rename(dest)
                    archived_count += 1
                    print(f"âœ“ Archived: {rel_path} â†’ {dest.relative_to(ROOT)}")
                except Exception as e:
                    print(f"âœ— Failed to archive {rel_path}: {e}")

        print(f"\nâœ“ Deleted: {deleted_count} files")
        print(f"âœ“ Archived: {archived_count} files")


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    import argparse

    parser = argparse.ArgumentParser(description="ìë™ ë¬¸ì„œ/í…ŒìŠ¤íŠ¸ ì •ë¦¬ ë„êµ¬")
    parser.add_argument("--scan", action="store_true", help="ìŠ¤ìº”ë§Œ ìˆ˜í–‰ (ì‚­ì œ ì•ˆ í•¨)")
    parser.add_argument("--clean", action="store_true", help="ìë™ ì •ë¦¬ ì‹¤í–‰")
    parser.add_argument("--archive", action="store_true", help="ì•„ì¹´ì´ë¸Œë§Œ ì‹¤í–‰")
    parser.add_argument("--report", type=str, help="ë¦¬í¬íŠ¸ ì €ì¥ ê²½ë¡œ")

    args = parser.parse_args()

    analyzer = CleanupAnalyzer()
    analyzer.scan()
    analyzer.analyze()

    # ë¦¬í¬íŠ¸ ìƒì„±
    report = analyzer.generate_report()
    print("\n" + report)

    # ë¦¬í¬íŠ¸ ì €ì¥
    if args.report:
        report_path = Path(args.report)
        report_path.write_text(report, encoding='utf-8')
        print(f"\nâœ“ Report saved: {report_path}")

    # ì •ë¦¬ ì‹¤í–‰
    if args.clean:
        response = input("\nâš ï¸  Are you sure you want to execute cleanup? (yes/no): ")
        if response.lower() == 'yes':
            analyzer.execute_cleanup(dry_run=False)
        else:
            print("âœ— Cleanup cancelled")
    elif args.archive:
        response = input("\nâš ï¸  Are you sure you want to archive files? (yes/no): ")
        if response.lower() == 'yes':
            # ì•„ì¹´ì´ë¸Œë§Œ ì‹¤í–‰ (ì‚­ì œ ì•ˆ í•¨)
            analyzer.to_delete = []
            analyzer.execute_cleanup(dry_run=False)
        else:
            print("âœ— Archive cancelled")
    else:
        # ê¸°ë³¸ ë™ì‘: dry run
        analyzer.execute_cleanup(dry_run=True)


if __name__ == "__main__":
    main()
