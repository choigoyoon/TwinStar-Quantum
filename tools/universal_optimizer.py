"""
Universal Parameter Optimizer (v2.2 - Fine-Tuning)

ëª©ì : ë²”ìš©ì„± ê²€ì¦ - ëª¨ë“  ì½”ì¸ì—ì„œ ì˜ ì‘ë™í•˜ëŠ” íŒŒë¼ë¯¸í„° ì°¾ê¸°

v2.2 ì—…ë°ì´íŠ¸ (Coarse-to-Fine):
  Step 1: Coarse íƒìƒ‰ (ë„“ì€ ë²”ìœ„, ëœë¤ ìƒ˜í”Œë§)
    - META_PARAM_RANGESì—ì„œ 1,000ê°œ ëœë¤ ìƒ˜í”Œ
    - ë¹ ë¥¸ 1ì°¨ íƒìƒ‰ (~30ì´ˆ)

  Step 2: Fine íƒìƒ‰ (ì¢ì€ ë²”ìœ„, ì •ë°€ ê·¸ë¦¬ë“œ)
    - Coarse ìµœê³  ê²°ê³¼ ì£¼ë³€ Â±1 ê°„ê²©
    - ì„¸ë°€í•œ 2ì°¨ íƒìƒ‰ (~1ë¶„)

  ë²”ìš©ì„± ì ìˆ˜:
    - í‰ê·  50% + ìµœì†Œê°’ 40% + ì•ˆì •ì„± 10%
    - TF ë³´ì •: ë†’ì€ TFì¼ìˆ˜ë¡ ë†’ì€ ìŠ¹ë¥  ê¸°ëŒ€

íƒ€ì„í”„ë ˆì„ ë³´ì •:
  ì§„ì… TF + í•„í„° TF ì¡°í•©ìœ¼ë¡œ ê¸°ëŒ€ ìŠ¹ë¥  ê³„ì‚°

  ê¸°ë³¸ ìŠ¹ë¥  (ì§„ì… TF):
  - 1h: 68%, 4h: 72%, 1d: 76%

  TF ê°„ê²© ë³´ë„ˆìŠ¤ (+2%p/ë‹¨ê³„):
  - 1h ì§„ì… + 4h í•„í„° (ê°„ê²© 2) = 68% + 4% = 72% ê¸°ëŒ€
  - 1h ì§„ì… + 1d í•„í„° (ê°„ê²© 6) = 68% + 12% = 80% ê¸°ëŒ€

ì˜ˆì‹œ:
  Coarse: 1,000ê°œ ì¤‘ ìµœê³  â†’ atr_mult=1.5, filter_tf='4h' (ì ìˆ˜ 98.5)
  Fine: [1.25, 1.5, 1.75] Ã— ['2h', '4h', '6h'] = 9ê°œ ì¡°í•© â†’ ìµœì¢… 1.25, '4h' (ì ìˆ˜ 99.2)
"""

import sys
from pathlib import Path
import pandas as pd
import numpy as np
from typing import List, Dict, Optional
from dataclasses import dataclass, field
import json
import logging
from datetime import datetime

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì¶”ê°€
ROOT = Path(__file__).parent.parent
sys.path.insert(0, str(ROOT))

from core.data_manager import BotDataManager
from core.strategy_core import AlphaX7Core
from config.parameters import DEFAULT_PARAMS
from utils.metrics import calculate_backtest_metrics
from utils.logger import get_module_logger

logger = get_module_logger(__name__)


@dataclass
class UniversalResult:
    """ë²”ìš© ìµœì í™” ê²°ê³¼"""
    params: dict
    symbol_results: Dict[str, dict]  # ì‹¬ë³¼ë³„ ê²°ê³¼

    # í†µê³„
    avg_win_rate: float
    min_win_rate: float
    max_win_rate: float
    win_rate_std: float

    avg_sharpe: float
    avg_mdd: float
    avg_pnl: float
    total_trades: int

    # ë²”ìš©ì„± ì ìˆ˜
    universality_score: float

    # í¬íŠ¸í´ë¦¬ì˜¤ ëª¨ë“œ (ì„ íƒ)
    portfolio_result: Optional[dict] = None

    def summary(self) -> str:
        """ê²°ê³¼ ìš”ì•½"""
        base = (
            f"ë²”ìš©ì„± ì ìˆ˜: {self.universality_score:.2f}\n"
            f"í‰ê·  ìŠ¹ë¥ : {self.avg_win_rate:.2f}%\n"
            f"ìµœì†Œ ìŠ¹ë¥ : {self.min_win_rate:.2f}% (ì¤‘ìš”!)\n"
            f"ìµœëŒ€ ìŠ¹ë¥ : {self.max_win_rate:.2f}%\n"
            f"í‘œì¤€í¸ì°¨: {self.win_rate_std:.2f}%\n"
            f"í‰ê·  MDD: {self.avg_mdd:.2f}%"
        )

        # í¬íŠ¸í´ë¦¬ì˜¤ ê²°ê³¼ ì¶”ê°€
        if self.portfolio_result:
            p = self.portfolio_result
            base += (
                f"\n\n[í¬íŠ¸í´ë¦¬ì˜¤ ëª¨ë“œ - ë™ì‹œ ë§¤ë§¤ ê²€ì¦]\n"
                f"ì‹¤í–‰ëœ ê±°ë˜: {p['total_trades']:,}ê°œ\n"
                f"ê±´ë„ˆë›´ ì‹ í˜¸: {p['skipped_signals']:,}ê°œ\n"
                f"ì‹ í˜¸ ì‹¤í–‰ë¥ : {p['execution_rate']:.1f}%\n"
                f"í‰ê·  ë™ì‹œ í¬ì§€ì…˜: {p['avg_concurrent_positions']:.1f}ê°œ\n"
                f"ìµœëŒ€ ë™ì‹œ í¬ì§€ì…˜: {p['max_concurrent_positions']}ê°œ\n"
                f"ì‹¤ì œ ìŠ¹ë¥ : {p['win_rate']:.1f}% (ê°œë³„ í‰ê°€ ëŒ€ë¹„ {p['win_rate'] - self.avg_win_rate:+.1f}%p)\n"
                f"ì‹¤ì œ MDD: {p['mdd']:.2f}% (ê°œë³„ í‰ê°€ ëŒ€ë¹„ {p['mdd'] - self.avg_mdd:+.2f}%p)"
            )

        return base


class UniversalOptimizer:
    """ë²”ìš©ì„± ê²€ì¦ ìµœì í™”"""

    def __init__(
        self,
        exchange: str = 'bybit',
        symbols: Optional[List[str]] = None,
        timeframe: str = '1h',
        mode: str = 'quick',
        portfolio_mode: bool = False,
        portfolio_config: Optional[dict] = None
    ):
        self.exchange = exchange
        self.symbols = symbols or ['BTCUSDT', 'ETHUSDT', 'BNBUSDT']
        self.timeframe = timeframe
        self.mode = mode
        self.portfolio_mode = portfolio_mode
        self.portfolio_config = portfolio_config

        logger.info("=" * 60)
        logger.info("Universal Optimizer ì´ˆê¸°í™”")
        logger.info(f"  ëª©í‘œ: ëª¨ë“  ì½”ì¸ì—ì„œ ì•ˆì •ì ìœ¼ë¡œ ì‘ë™í•˜ëŠ” ë²”ìš© íŒŒë¼ë¯¸í„°")
        logger.info(f"  Exchange: {exchange}")
        logger.info(f"  Symbols: {len(self.symbols)}ê°œ")
        logger.info(f"  Timeframe: {timeframe}")
        logger.info(f"  Mode: {mode}")
        if portfolio_mode:
            logger.info(f"  í¬íŠ¸í´ë¦¬ì˜¤ ëª¨ë“œ: ON (ë™ì‹œ ë§¤ë§¤ ê²€ì¦)")
            if portfolio_config:
                logger.info(f"    ì´ˆê¸° ìë³¸: ${portfolio_config.get('initial_capital', 10000):,.0f}")
                logger.info(f"    ìµœëŒ€ í¬ì§€ì…˜: {portfolio_config.get('max_positions', 5)}ê°œ")
                logger.info(f"    ê±°ë˜ë‹¹ ìë³¸: ${portfolio_config.get('capital_per_trade', 2000):,.0f}")
        logger.info("=" * 60)

        # ë°ì´í„° ë¡œë“œ
        self.data_cache: Dict[str, pd.DataFrame] = {}
        self._load_all_data()

    def _load_all_data(self):
        """ëª¨ë“  ì‹¬ë³¼ ë°ì´í„° ë¡œë“œ"""
        logger.info("ë°ì´í„° ë¡œë“œ ì‹œì‘...")

        for symbol in self.symbols:
            try:
                dm = BotDataManager(
                    exchange_name=self.exchange,
                    symbol=symbol,
                    strategy_params={'entry_tf': self.timeframe}
                )

                dm.load_historical()
                df = dm.df_entry_full

                if df is None:
                    logger.warning(f"  âš ï¸ {symbol}: ë°ì´í„° ì—†ìŒ")
                    continue

                df_copy = df.copy()

                if len(df_copy) < 1000:
                    logger.warning(f"  âš ï¸ {symbol}: ë°ì´í„° ë¶€ì¡± ({len(df_copy)}ê°œ)")
                    continue

                self.data_cache[symbol] = df_copy
                logger.info(f"  âœ… {symbol}: {len(df_copy):,}ê°œ ìº”ë“¤")

            except Exception as e:
                logger.error(f"  âŒ {symbol}: {e}")

        logger.info(f"âœ… ë¡œë“œ ì™„ë£Œ: {len(self.data_cache)}/{len(self.symbols)}ê°œ")

    def _run_single_backtest(self, symbol: str, params: dict) -> Optional[dict]:
        """ë‹¨ì¼ ì‹¬ë³¼ ë°±í…ŒìŠ¤íŠ¸"""
        df = self.data_cache.get(symbol)
        if df is None:
            return None

        try:
            strategy = AlphaX7Core()

            result = strategy.run_backtest(
                df_entry=df,
                df_pattern=df,
                df_filter=df,
                params=params
            )

            if not result or 'trades' not in result:
                return None

            trades = result['trades']
            if len(trades) < 5:
                return None

            # ë©”íŠ¸ë¦­ ê³„ì‚°
            metrics = calculate_backtest_metrics(trades, leverage=1, capital=100.0)

            return {
                'win_rate': metrics['win_rate'],
                'sharpe_ratio': metrics['sharpe_ratio'],
                'mdd': metrics['mdd'],
                'total_pnl': metrics['total_pnl'],
                'total_trades': metrics['total_trades']
            }

        except Exception as e:
            return None

    def _get_tf_hierarchy_value(self, tf: str) -> int:
        """íƒ€ì„í”„ë ˆì„ ê³„ì¸µ ê°’ ë°˜í™˜

        Args:
            tf: íƒ€ì„í”„ë ˆì„ ('1h', '4h', '1d' ë“±)

        Returns:
            ê³„ì¸µ ê°’ (ë†’ì„ìˆ˜ë¡ ê¸´ íƒ€ì„í”„ë ˆì„)
        """
        hierarchy = {
            '15m': 1,
            '30m': 2,
            '1h': 3,
            '2h': 4,
            '4h': 5,
            '6h': 6,
            '8h': 7,
            '12h': 8,
            '1d': 9
        }
        return hierarchy.get(tf, 5)  # ê¸°ë³¸ê°’: 4h

    def _get_tf_baseline_winrate(self, entry_tf: str, filter_tf: str) -> float:
        """íƒ€ì„í”„ë ˆì„ ì¡°í•©ë³„ ê¸°ëŒ€ ìŠ¹ë¥  ê³„ì‚°

        ì›ì¹™:
        1. í•„í„° TFê°€ ì§„ì… TFë³´ë‹¤ ë†’ì•„ì•¼ í•¨ (ê³„ì¸µ ê²€ì¦)
        2. TF ê°„ê²©ì´ í´ìˆ˜ë¡ ë” ê°•í•œ ì¶”ì„¸ í•„í„° â†’ ë” ë†’ì€ ìŠ¹ë¥  ê¸°ëŒ€

        Args:
            entry_tf: ì§„ì… íƒ€ì„í”„ë ˆì„ ('1h', '4h' ë“±)
            filter_tf: í•„í„° íƒ€ì„í”„ë ˆì„ ('4h', '12h', '1d' ë“±)

        Returns:
            ê¸°ëŒ€ ìŠ¹ë¥  (%) - ì´ ê°’ë³´ë‹¤ ë†’ìœ¼ë©´ ì¢‹ì€ ì„±ëŠ¥
        """
        entry_val = self._get_tf_hierarchy_value(entry_tf)
        filter_val = self._get_tf_hierarchy_value(filter_tf)

        # TF ê°„ê²© (í•„í„°ê°€ ì§„ì…ë³´ë‹¤ ì–¼ë§ˆë‚˜ ë†’ì€ì§€)
        tf_gap = filter_val - entry_val

        # ê¸°ë³¸ ìŠ¹ë¥  (ì§„ì… TF ê¸°ì¤€)
        base_winrate = {
            '15m': 62.0,
            '30m': 65.0,
            '1h': 68.0,
            '2h': 70.0,
            '4h': 72.0,
            '6h': 73.0,
            '8h': 74.0,
            '12h': 75.0,
            '1d': 76.0
        }.get(entry_tf, 68.0)

        # TF ê°„ê²©ì— ë”°ë¥¸ ë³´ë„ˆìŠ¤ (ê°„ê²© 1ë‹¨ê³„ë‹¹ +2%p)
        # ì˜ˆ: 1h ì§„ì… + 4h í•„í„° (ê°„ê²© 2) = 68 + 4 = 72%
        # ì˜ˆ: 1h ì§„ì… + 1d í•„í„° (ê°„ê²© 6) = 68 + 12 = 80%
        gap_bonus = max(0, tf_gap) * 2.0

        expected_wr = base_winrate + gap_bonus

        # ìƒí•œì„ : 85% (ë¹„í˜„ì‹¤ì  ê¸°ëŒ€ ë°©ì§€)
        return min(expected_wr, 85.0)

    def _calculate_universality_score(self, symbol_results: Dict[str, dict], entry_tf: str, filter_tf: str) -> tuple:
        """ë²”ìš©ì„± ì ìˆ˜ ê³„ì‚° (íƒ€ì„í”„ë ˆì„ ë³´ì • ì ìš©)

        v2.1 ì—…ë°ì´íŠ¸:
        - ì§„ì… TF + í•„í„° TF ì¡°í•©ë³„ ê¸°ëŒ€ ìŠ¹ë¥  ëŒ€ë¹„ ì •ê·œí™”
        - TF ê°„ê²©ì´ í´ìˆ˜ë¡ ë” ë†’ì€ ìŠ¹ë¥  ê¸°ëŒ€

        Args:
            symbol_results: ì‹¬ë³¼ë³„ ë°±í…ŒìŠ¤íŠ¸ ê²°ê³¼
            entry_tf: ì§„ì… íƒ€ì„í”„ë ˆì„
            filter_tf: í•„í„° íƒ€ì„í”„ë ˆì„

        Returns:
            (ë²”ìš©ì„± ì ìˆ˜, í‰ê·  ìŠ¹ë¥ , ìµœì†Œ ìŠ¹ë¥ , ìµœëŒ€ ìŠ¹ë¥ , í‘œì¤€í¸ì°¨)
        """
        win_rates = [r['win_rate'] for r in symbol_results.values()]

        # ì›ì‹œ í†µê³„
        raw_avg_wr = np.mean(win_rates)
        raw_min_wr = np.min(win_rates)
        raw_max_wr = np.max(win_rates)
        win_rate_std = np.std(win_rates)

        # íƒ€ì„í”„ë ˆì„ ì¡°í•© ê¸°ëŒ€ ìŠ¹ë¥ 
        expected_wr = self._get_tf_baseline_winrate(entry_tf, filter_tf)

        # ì •ê·œí™”ëœ ìŠ¹ë¥  (ê¸°ëŒ€ ëŒ€ë¹„ ì„±ëŠ¥)
        # 100 = ê¸°ëŒ€ì¹˜ ì •í™•íˆ ë‹¬ì„±, >100 = ê¸°ëŒ€ ì´ˆê³¼, <100 = ê¸°ëŒ€ ë¯¸ë‹¬
        normalized_avg = (raw_avg_wr / expected_wr) * 100
        normalized_min = (raw_min_wr / expected_wr) * 100

        # ë²”ìš©ì„± ì ìˆ˜ = ì •ê·œí™”ëœ í‰ê·  50% + ì •ê·œí™”ëœ ìµœì†Œê°’ 40% + ì•ˆì •ì„± 10%
        # í•µì‹¬ ê°œì„ :
        # 1. ë‚®ì€ TF(1h)ì—ì„œ 75% ìŠ¹ë¥  = ë†’ì€ ì ìˆ˜ (ê¸°ëŒ€ 68% ëŒ€ë¹„ +10%)
        # 2. ë†’ì€ TF(1d)ì—ì„œ 75% ìŠ¹ë¥  = ë‚®ì€ ì ìˆ˜ (ê¸°ëŒ€ 80% ëŒ€ë¹„ -6%)
        # â†’ TFë¥¼ ì˜¬ë ¸ëŠ”ë° ìŠ¹ë¥ ì´ ì•ˆ ì˜¬ë¼ê°€ë©´ ë²Œì !
        universality_score = (
            normalized_avg * 0.5 +
            normalized_min * 0.4 +
            (100 - win_rate_std) * 0.1
        )

        return universality_score, raw_avg_wr, raw_min_wr, raw_max_wr, win_rate_std

    def _evaluate_params(self, params: dict) -> Optional[UniversalResult]:
        """íŒŒë¼ë¯¸í„° í‰ê°€ (í¬íŠ¸í´ë¦¬ì˜¤ ëª¨ë“œ ì§€ì›)"""
        symbol_results = {}

        for symbol in self.data_cache.keys():
            result = self._run_single_backtest(symbol, params)
            if result:
                symbol_results[symbol] = result

        if not symbol_results:
            return None

        # ë²”ìš©ì„± ì ìˆ˜ ê³„ì‚° (íƒ€ì„í”„ë ˆì„ ë³´ì • ì ìš©)
        entry_tf = self.timeframe  # ì´ˆê¸°í™” ì‹œ ì„¤ì •í•œ ì§„ì… TF
        filter_tf = params.get('filter_tf', '4h')
        score, avg_wr, min_wr, max_wr, std_wr = self._calculate_universality_score(symbol_results, entry_tf, filter_tf)

        # ê¸°íƒ€ í‰ê· 
        avg_sharpe = float(np.mean([r['sharpe_ratio'] for r in symbol_results.values()]))
        avg_mdd = float(np.mean([r['mdd'] for r in symbol_results.values()]))
        avg_pnl = float(np.mean([r['total_pnl'] for r in symbol_results.values()]))
        total_trades = sum([r['total_trades'] for r in symbol_results.values()])

        # í¬íŠ¸í´ë¦¬ì˜¤ ëª¨ë“œ í‰ê°€ (ì„ íƒ)
        portfolio_result_dict: Optional[dict] = None
        if self.portfolio_mode:
            try:
                from tools.portfolio_backtest import PortfolioBacktestEngine, PortfolioConfig

                # ì„¤ì • ìƒì„±
                if self.portfolio_config:
                    config = PortfolioConfig(**self.portfolio_config)
                else:
                    config = PortfolioConfig()  # ê¸°ë³¸ê°’ ì‚¬ìš©

                # ì—”ì§„ ìƒì„± ë° ì‹¤í–‰
                engine = PortfolioBacktestEngine(self.data_cache, config)
                portfolio_result = engine.run_backtest(params)

                # dictë¡œ ë³€í™˜ (íƒ€ì… ì•ˆì „ì„±)
                if portfolio_result is not None:
                    portfolio_result_dict = {
                        'total_trades': portfolio_result.total_trades,
                        'skipped_signals': portfolio_result.skipped_signals,
                        'execution_rate': portfolio_result.execution_rate,
                        'avg_concurrent_positions': portfolio_result.avg_concurrent_positions,
                        'max_concurrent_positions': portfolio_result.max_concurrent_positions,
                        'win_rate': portfolio_result.win_rate,
                        'profit_factor': portfolio_result.profit_factor,
                        'sharpe_ratio': portfolio_result.sharpe_ratio,
                        'mdd': portfolio_result.mdd,
                        'total_pnl': portfolio_result.total_pnl,
                        'final_capital': portfolio_result.final_capital,
                        'symbol_stats': portfolio_result.symbol_stats,
                        'skipped_by_time': portfolio_result.skipped_by_time
                    }

            except Exception as e:
                logger.warning(f"í¬íŠ¸í´ë¦¬ì˜¤ ëª¨ë“œ í‰ê°€ ì‹¤íŒ¨: {e}")
                portfolio_result_dict = None

        return UniversalResult(
            params=params,
            symbol_results=symbol_results,
            avg_win_rate=avg_wr,
            min_win_rate=min_wr,
            max_win_rate=max_wr,
            win_rate_std=std_wr,
            avg_sharpe=avg_sharpe,
            avg_mdd=avg_mdd,
            avg_pnl=avg_pnl,
            total_trades=total_trades,
            universality_score=score,
            portfolio_result=portfolio_result_dict
        )

    def _generate_fine_ranges(
        self,
        coarse_best_params: dict,
        meta_ranges: dict
    ) -> dict:
        """Coarse ìµœê³  íŒŒë¼ë¯¸í„° ì£¼ë³€ Â±1 ê°„ê²©ìœ¼ë¡œ Fine ë²”ìœ„ ìƒì„±

        Args:
            coarse_best_params: Coarse ë‹¨ê³„ ìµœê³  íŒŒë¼ë¯¸í„°
            meta_ranges: ì „ì²´ ë©”íƒ€ ë²”ìœ„

        Returns:
            Fine ë²”ìœ„ ë”•ì…”ë„ˆë¦¬ (ê° íŒŒë¼ë¯¸í„°ë‹¹ ìµœëŒ€ 3ê°œ ê°’)
        """
        fine_ranges = {}

        # ìˆ˜ì¹˜í˜• íŒŒë¼ë¯¸í„° (Â±1 ì¸ë±ìŠ¤)
        for param in ['atr_mult', 'trail_start_r', 'trail_dist_r', 'entry_validity_hours']:
            coarse_val = coarse_best_params[param]
            all_values = meta_ranges[param]

            try:
                idx = all_values.index(coarse_val)
            except ValueError:
                # Coarse ê°’ì´ ë©”íƒ€ ë²”ìœ„ì— ì—†ìœ¼ë©´ ê·¸ëƒ¥ í•´ë‹¹ ê°’ë§Œ
                fine_ranges[param] = [coarse_val]
                continue

            # Â±1 ì¸ë±ìŠ¤ (ê²½ê³„ ì²˜ë¦¬)
            start_idx = max(0, idx - 1)
            end_idx = min(len(all_values) - 1, idx + 1)

            fine_ranges[param] = all_values[start_idx:end_idx + 1]

        # ì¹´í…Œê³ ë¦¬í˜• íŒŒë¼ë¯¸í„° (filter_tf: Â±1 ê³„ì¸µ)
        coarse_tf = coarse_best_params['filter_tf']
        tf_hierarchy = ['2h', '4h', '6h', '12h', '1d']

        try:
            tf_idx = tf_hierarchy.index(coarse_tf)
        except ValueError:
            fine_ranges['filter_tf'] = [coarse_tf]
        else:
            start_idx = max(0, tf_idx - 1)
            end_idx = min(len(tf_hierarchy) - 1, tf_idx + 1)
            fine_ranges['filter_tf'] = tf_hierarchy[start_idx:end_idx + 1]

        return fine_ranges

    def optimize(self) -> Optional[UniversalResult]:
        """ìµœì í™” ì‹¤í–‰ (v2.2 - Coarse-to-Fine)

        Step 1: Coarse (ë„“ì€ ë²”ìœ„, ëœë¤ ìƒ˜í”Œë§ 1,000ê°œ)
        Step 2: Fine (ì¢ì€ ë²”ìœ„, ì •ë°€ ê·¸ë¦¬ë“œ Coarse ìµœê³  Â±1)
        """
        logger.info("=" * 60)
        logger.info("ë²”ìš©ì„± ìµœì í™” ì‹œì‘ (v2.2 - Coarse-to-Fine)")
        logger.info(f"  í‰ê°€ ê¸°ì¤€: ì •ê·œí™”ëœ í‰ê·  50% + ì •ê·œí™”ëœ ìµœì†Œê°’ 40% + ì•ˆì •ì„± 10%")
        logger.info(f"  íƒ€ì„í”„ë ˆì„ ë³´ì •: ë†’ì€ TFì¼ìˆ˜ë¡ ë†’ì€ ìŠ¹ë¥  ê¸°ëŒ€")
        logger.info("=" * 60)

        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # Stage 1: Coarse (ë„“ì€ ë²”ìœ„ ëœë¤ ìƒ˜í”Œë§)
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        logger.info("ğŸ” Stage 1: Coarse íƒìƒ‰ (ëœë¤ ìƒ˜í”Œë§ 1,000ê°œ)")
        logger.info("-" * 60)

        # âŒ DEPRECATED: Meta ìµœì í™” ì‚¬ìš© ì•ˆ í•¨ (Fine-Tuningì´ ìµœê³  ì„±ëŠ¥)
        # ì¬í™œì„±í™” í•„ìš” ì‹œ: dev_future/optimization_modes/README.md ì°¸ì¡°
        logger.warning("âš ï¸ Meta ë²”ìœ„ëŠ” í˜„ì¬ ì‚¬ìš© ì•ˆ í•¨. ëŒ€ì‹  FINE_TUNING_RANGES ì‚¬ìš©ì„ ê¶Œì¥í•©ë‹ˆë‹¤.")
        logger.warning("ì¬í™œì„±í™”: from dev_future.optimization_modes.meta_ranges import load_meta_param_ranges")

        # í´ë°±: FINE_TUNING_RANGES ì‚¬ìš©
        from config.parameters import FINE_TUNING_RANGES
        import random

        meta_ranges = FINE_TUNING_RANGES  # í´ë°±

        # ëœë¤ ìƒ˜í”Œ 1,000ê°œ ìƒì„±
        coarse_samples = []
        for _ in range(1000):
            params = DEFAULT_PARAMS.copy()
            params.update({
                'atr_mult': random.choice(meta_ranges['atr_mult']),
                'filter_tf': random.choice(meta_ranges['filter_tf']),
                'trail_start_r': random.choice(meta_ranges['trail_start_r']),
                'trail_dist_r': random.choice(meta_ranges['trail_dist_r']),
                'entry_validity_hours': random.choice(meta_ranges['entry_validity_hours'])
            })
            coarse_samples.append(params)

        # Coarse ìµœì í™”
        coarse_best: Optional[UniversalResult] = None
        coarse_best_score = -1

        for idx, params in enumerate(coarse_samples, 1):
            # ì§„í–‰ ìƒí™© (100ê°œë§ˆë‹¤)
            if idx % 100 == 0 or idx == 1:
                logger.info(f"  [{idx}/1000] í…ŒìŠ¤íŠ¸ ì¤‘... (ìµœê³ : {coarse_best_score:.2f})")

            # í‰ê°€
            result = self._evaluate_params(params)
            if result and result.universality_score > coarse_best_score:
                coarse_best_score = result.universality_score
                coarse_best = result

        if coarse_best is None:
            logger.warning("Coarse ë‹¨ê³„ ì‹¤íŒ¨: ìœ íš¨í•œ ê²°ê³¼ ì—†ìŒ")
            return None

        logger.info(f"âœ… Coarse ì™„ë£Œ! ìµœê³  ì ìˆ˜: {coarse_best_score:.2f}")
        logger.info(f"   ìµœê³  íŒŒë¼ë¯¸í„°: atr={coarse_best.params['atr_mult']}, "
                   f"filter_tf={coarse_best.params['filter_tf']}, "
                   f"trail_start={coarse_best.params['trail_start_r']}, "
                   f"trail_dist={coarse_best.params['trail_dist_r']}, "
                   f"entry_validity={coarse_best.params['entry_validity_hours']}")

        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # Stage 2: Fine (Coarse ìµœê³  ì£¼ë³€ Â±1 ê°„ê²©)
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        logger.info("=" * 60)
        logger.info("ğŸ¯ Stage 2: Fine íƒìƒ‰ (Coarse ìµœê³  Â±1 ê°„ê²©)")
        logger.info("-" * 60)

        # Fine ë²”ìœ„ ìƒì„± (Coarse ìµœê³  Â±1)
        fine_ranges = self._generate_fine_ranges(coarse_best.params, meta_ranges)

        from itertools import product
        fine_combinations = list(product(
            fine_ranges['atr_mult'],
            fine_ranges['filter_tf'],
            fine_ranges['trail_start_r'],
            fine_ranges['trail_dist_r'],
            fine_ranges['entry_validity_hours']
        ))

        logger.info(f"  Fine ì¡°í•©: {len(fine_combinations):,}ê°œ")

        # Fine ìµœì í™”
        fine_best: Optional[UniversalResult] = None
        fine_best_score = coarse_best_score  # Coarseë³´ë‹¤ ë‚˜ë¹ ì§€ë©´ ì•ˆ ë¨

        for idx, combo in enumerate(fine_combinations, 1):
            atr_mult, filter_tf, trail_start_r, trail_dist_r, entry_validity = combo

            params = DEFAULT_PARAMS.copy()
            params.update({
                'atr_mult': atr_mult,
                'filter_tf': filter_tf,
                'trail_start_r': trail_start_r,
                'trail_dist_r': trail_dist_r,
                'entry_validity_hours': entry_validity
            })

            # ì§„í–‰ ìƒí™©
            if idx % 5 == 0 or idx == 1:
                logger.info(f"  [{idx}/{len(fine_combinations)}] í…ŒìŠ¤íŠ¸ ì¤‘... (ìµœê³ : {fine_best_score:.2f})")

            # í‰ê°€
            result = self._evaluate_params(params)
            if result and result.universality_score > fine_best_score:
                fine_best_score = result.universality_score
                fine_best = result

                # TF ê¸°ëŒ€ ìŠ¹ë¥  ê³„ì‚°
                expected_wr = self._get_tf_baseline_winrate(self.timeframe, filter_tf)

                # TF ê°„ê²© ê³„ì‚°
                entry_val = self._get_tf_hierarchy_value(self.timeframe)
                filter_val = self._get_tf_hierarchy_value(filter_tf)
                tf_gap = filter_val - entry_val

                logger.info(f"    âœ¨ ì‹ ê¸°ë¡!")
                logger.info(f"       ë²”ìš©ì„±: {result.universality_score:.2f}")
                logger.info(f"       í‰ê· : {result.avg_win_rate:.1f}%, ìµœì†Œ: {result.min_win_rate:.1f}%, í‘œì¤€í¸ì°¨: {result.win_rate_std:.1f}%")
                logger.info(f"       TF ì¡°í•©: {self.timeframe} â†’ {filter_tf} (ê°„ê²© {tf_gap}, ê¸°ëŒ€ {expected_wr:.0f}% ëŒ€ë¹„ {result.avg_win_rate - expected_wr:+.1f}%p)")

        # Fine ê²°ê³¼ê°€ ì—†ìœ¼ë©´ Coarse ê²°ê³¼ ì‚¬ìš©
        if fine_best is None:
            fine_best = coarse_best
            logger.info(f"âš ï¸ Fine ê°œì„  ì—†ìŒ, Coarse ê²°ê³¼ ì‚¬ìš© (ì ìˆ˜: {coarse_best_score:.2f})")

        logger.info("=" * 60)
        logger.info("ìµœì í™” ì™„ë£Œ!")
        logger.info(fine_best.summary())
        logger.info("=" * 60)

        return fine_best

    def save_preset(self, result: UniversalResult, filename: Optional[str] = None):
        """í”„ë¦¬ì…‹ ì €ì¥"""
        if filename is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"universal_{self.exchange}_{self.timeframe}_{timestamp}.json"

        preset_path = ROOT / 'presets' / filename
        preset_path.parent.mkdir(parents=True, exist_ok=True)

        preset_data = {
            "meta_info": {
                "type": "universal_multi_symbol",
                "exchange": self.exchange,
                "timeframe": self.timeframe,
                "symbols": list(result.symbol_results.keys()),
                "optimization_mode": self.mode,
                "created_at": datetime.now().isoformat()
            },
            "best_params": result.params,
            "universality_metrics": {
                "universality_score": result.universality_score,
                "avg_win_rate": result.avg_win_rate,
                "min_win_rate": result.min_win_rate,
                "max_win_rate": result.max_win_rate,
                "win_rate_std": result.win_rate_std,
                "avg_sharpe_ratio": result.avg_sharpe,
                "avg_mdd": result.avg_mdd,
                "avg_pnl": result.avg_pnl,
                "total_trades": result.total_trades
            },
            "symbol_results": result.symbol_results
        }

        with open(preset_path, 'w', encoding='utf-8') as f:
            json.dump(preset_data, f, indent=2, ensure_ascii=False)

        logger.info(f"âœ… í”„ë¦¬ì…‹ ì €ì¥: {preset_path}")
        return preset_path


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    import argparse

    parser = argparse.ArgumentParser(description='Universal Parameter Optimizer')
    parser.add_argument('--exchange', default='bybit')
    parser.add_argument('--symbols', default='BTCUSDT,ETHUSDT,BNBUSDT')
    parser.add_argument('--timeframe', default='1h')
    parser.add_argument('--mode', default='quick', choices=['quick', 'standard', 'deep'])
    parser.add_argument('--output', help='ì¶œë ¥ íŒŒì¼ëª…')

    args = parser.parse_args()

    # ì‹¬ë³¼ íŒŒì‹±
    symbols = [s.strip() for s in args.symbols.split(',')]

    # ìµœì í™”
    optimizer = UniversalOptimizer(
        exchange=args.exchange,
        symbols=symbols,
        timeframe=args.timeframe,
        mode=args.mode
    )

    result = optimizer.optimize()

    if result:
        # í”„ë¦¬ì…‹ ì €ì¥
        preset_path = optimizer.save_preset(result, args.output)

        print("\n" + "=" * 60)
        print("âœ… ë²”ìš© ìµœì í™” ì™„ë£Œ!")
        print("=" * 60)
        print(result.summary())
        print(f"\nğŸ“ í”„ë¦¬ì…‹: {preset_path}")
        print("=" * 60)

        print("\nğŸ“Š ì‹¬ë³¼ë³„ ìŠ¹ë¥ :")
        for symbol, metrics in sorted(result.symbol_results.items(), key=lambda x: x[1]['win_rate'], reverse=True):
            print(f"  {symbol:12s}: {metrics['win_rate']:.1f}%")
    else:
        print("âŒ ìµœì í™” ì‹¤íŒ¨")


if __name__ == '__main__':
    main()
